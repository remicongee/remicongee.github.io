<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="I&apos;m description.">
<meta property="og:type" content="website">
<meta property="og:title" content="Remi&#39;s Hexo">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Remi&#39;s Hexo">
<meta property="og:description" content="I&apos;m description.">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Remi&#39;s Hexo">
<meta name="twitter:description" content="I&apos;m description.">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>

<script>
    (function(){
        if(''){
            if (prompt('Password required') !== ''){
                alert('Wrong!');
                history.back();
            }
        }
    })();
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title>Remi's Hexo</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Remi's Hexo</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
		
			

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/Computer-Vision/Object-Detection/YOLO/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="RemiC">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Remi's Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Computer-Vision/Object-Detection/YOLO/" itemprop="url">YOLO</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-12-25T17:30:42+08:00">
                2018-12-25
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Computer-Vision/" itemprop="url" rel="index">
                    <span itemprop="name">Computer Vision</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Computer-Vision/Object-Detection/" itemprop="url" rel="index">
                    <span itemprop="name">Object Detection</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>This text refers to the paper <strong>You Only Look Once: Unified, Real-Time Object Detection</strong> <a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Redmon_You_Only_Look_CVPR_2016_paper.pdf" target="_blank" rel="noopener">[1]</a>, which proposes to detect objects by solving a designed regression problem. The YOLO contains only a single network as in the unified framework, instead of multi-part components, such as RPN.</p>
<h2 id="Grid"><a href="#Grid" class="headerlink" title="Grid"></a>Grid</h2><p>To avoid region proposal based methods, the bounding-box coordinates should be directly learned from features. For CNN features that keep location information, each point or vector across channels represents certain property of a region mapped to the original image. This property varies from the objective function designed. For instance, in Faster R-CNN <a href="Computer-Vision/Object-Detection/Faster-R-CNN">[2]</a>, features are assigned to be whether to contain objects, corresponding class if positive. Similarly, YOLO does bounding-box coordinates, corresponding class and confidence. Thus if the final features form a $S\times S$ map, each point or vector across channels maps to a grid of the original image, which is divided into $S\times S$ grids. In this case, each grid is supposed to predict the property expected. Particularly, the author doubles this prediction and select the most “confident” one as result. Then say $C$ classes, $(x,y,w,h)$ the coordinates, the channel number of the final features is $2\times5+C$.</p>
<blockquote>
<p>$\texttt{Notes}:$ The last $C$ channels consist the conditioned distribution of classification, $\mathbb{P}(\texttt{class}|\texttt{object})$, i.e. the probability of $\texttt{class}$ knowing the existance of $\texttt{object}$.</p>
</blockquote>
<h2 id="Confidence"><a href="#Confidence" class="headerlink" title="Confidence"></a>Confidence</h2><p>The confidence indicates how confident the grid admits the existance of an object, designed as $\mathbb{P}(\texttt{object})\cdot \texttt{IOU}^\texttt{T}_\texttt{P}$, where $\mathbb{P}(\texttt{object})$ is the probability of existance of $\texttt{object}$ and $\texttt{IOU}^\texttt{T}_\texttt{P}$ is the intersection over union between ground truth and bounding-box prediction computed as</p>
<script type="math/tex; mode=display">
\texttt{IOU}^\texttt{T}_\texttt{P} = \frac{\texttt{Area of overlap}}{\texttt{Area of union}}.</script><p>The confidence becomes null when there is no object. At training time, it should be equal to $\texttt{IOU}^\texttt{T}_\texttt{P}$. At test time, the author multiplies the conditional class probabilities and the individual box conﬁdence predictions:</p>
<script type="math/tex; mode=display">
\mathbb{P}(\texttt{class}|\texttt{object})\cdot\mathbb{P}(\texttt{object})\cdot \texttt{IOU}^\texttt{T}_\texttt{P} = \mathbb{P}(\texttt{class})\cdot\texttt{IOU}^\texttt{T}_\texttt{P}.</script><h2 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h2><p>To this point, there remains a problem when training: how to match prediction and ground truth, because each grid does not predict which object is concerned. Given that, the author proposes to make the grid containing the center of an object responsible for its prediction. But it is still confusing since each grid predicts multiple (two) bounding-boxes. The author then matches the one of the highest $\texttt{IOU}$ with the ground truth.</p>
<p>However, this kind of design supposes <em>a priori</em> that each grid contains at most the center of one object, which may lead to a poor recall ratio for small and close objects.</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] Redmon, J., Divvala, S., Girshick, R., &amp; Farhadi, A. (2016). You only look once: Unified, real-time object detection. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 779-788).</p>
<p>[2] Ren, S., He, K., Girshick, R., &amp; Sun, J. (2015). Faster r-cnn: Towards real-time object detection with region proposal networks. In Advances in neural information processing systems (pp. 91-99).</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


		
    
		
			

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/Computer-Vision/Object-Detection/Faster-R-CNN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="RemiC">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Remi's Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Computer-Vision/Object-Detection/Faster-R-CNN/" itemprop="url">Faster R-CNN</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-12-18T16:54:31+08:00">
                2018-12-18
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Computer-Vision/" itemprop="url" rel="index">
                    <span itemprop="name">Computer Vision</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Computer-Vision/Object-Detection/" itemprop="url" rel="index">
                    <span itemprop="name">Object Detection</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>This text refers to the paper Faster R-CNN <a href="http://papers.nips.cc/paper/5638-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks" target="_blank" rel="noopener">[1]</a>, which embeds region proposing in the CNN, namely region proposal network (RPN), thus allowing real-time detection.</p>
<h2 id="Region-Proposal-Network"><a href="#Region-Proposal-Network" class="headerlink" title="Region Proposal Network"></a>Region Proposal Network</h2><p>In the previous studies on object detection as R-CNN and Fast R-CNN, region proposals are generated by the algorithms (e.g. selective search) independent of the CNN used, which incites promising but costly results. However, this computation complexity is not necessary due to the repetition of feature extracting. To this end, one natural solution is embedding the region proposing in the CNN. Faster R-CNN implements this idea by filtering region proposals that containing foreground based on the feature maps given by the CNN.</p>
<h3 id="To-Feature-Maps"><a href="#To-Feature-Maps" class="headerlink" title="To Feature Maps"></a>To Feature Maps</h3><p>The feature maps computed by a fully convolutional network keep the relative location relationships, region features are extracted into a channel-dimensioned vector and stacked in the order as the original image. For instance, say an image of size $H\times W$ maps to a feature map of size $h\times w\times c$, generally each region grid of size $\lceil H/h\rceil\times\lceil W/w\rceil$ maps to a feature vector of size $1\times1\times c$ in the feature maps. Therefore, by supposing that containing objects is a property of the corresponding region and available in the feature maps, each feature vector should be further operated for a classification result (foreground or background).</p>
<h3 id="Multi-scale-Proposals"><a href="#Multi-scale-Proposals" class="headerlink" title="Multi-scale Proposals"></a>Multi-scale Proposals</h3><p>Based on the idea mentioned above, only regions of size $\lceil H/h\rceil\times\lceil W/w\rceil$ can be proposed, which raises at least two problems:</p>
<ul>
<li>Given the depth of CNN, this size is normally too large as a bounding-box.</li>
<li>Considering that obejcts may appear in any scale or direction, the scale and shape should vary for different cases.</li>
</ul>
<p>The author thus proposes a multi-scale solution. For the object in the region of the original image, it is expected to be contained in 9 different bounding-boxes, with shapes $[1:1,1:2,2:1]$ and scales $[128^2,256^2,512^2]$. In this case, the feature vectors are no longer used to predict whether the corresponding region contains objects, but moreover to define in which proposal an object exists. These multi-scale proposals are named <em>anchors</em> in Fast R-CNN.</p>
<h3 id="Fine-Convolution"><a href="#Fine-Convolution" class="headerlink" title="Fine Convolution"></a>Fine Convolution</h3><p>Since the existance of object is inferred from the feature vector, a $1\times1$ convolutional layer is stacked afterward. The problem is how to set the number of filters, i.e. the number of output channels. To generalize the situation, say there are $k$ anchors for each feature vector, then classification of foreground or background requires $2k$-demensioned vector, which are coupled and further passed to a Softmax function. Given that, there should be $2k$ filters in this $1\times1$ convolutional layer.</p>
<blockquote>
<p>$\texttt{Note}:$ Starting from the feature maps of the fully CNN, Fast R-CNN adds a $3\times3$ convolutional layer without channel number changed, followed by a $1\times1\times18$ convolutional layer. To further computed Softmax result, the $18$-channeled feature maps should be reshaped into $9\times h\times w$ $2$-dimensioned vector. The cross-entropy loss is included for training this part.</p>
</blockquote>
<h3 id="Regression"><a href="#Regression" class="headerlink" title="Regression"></a>Regression</h3><p>Filtering region proposals containing objects is not enough, to generate rather accurate proposals, a bounding-box regression is used for those filtered. The regression is similar to that of R-CNN or Fast R-CNN, where the coarse coordinates are tuned based on certain parameters computed from feature maps extracted from the fully CNN. Another similar regression will be conducted by the final detector.</p>
<h2 id="Detector"><a href="#Detector" class="headerlink" title="Detector"></a>Detector</h2><p>For detection, a Fast R-CNN structure is stacked afterward. Refer to the <a href="Computer-Vision/Object-Detection/Fast-R-CNN">Fast R-CNN</a> for more details.</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] Ren, S., He, K., Girshick, R., &amp; Sun, J. (2015). Faster r-cnn: Towards real-time object detection with region proposal networks. In Advances in neural information processing systems (pp. 91-99).</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


		
    
		
			

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/Computer-Vision/Object-Detection/Fast-R-CNN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="RemiC">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Remi's Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Computer-Vision/Object-Detection/Fast-R-CNN/" itemprop="url">Fast R-CNN</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-12-18T14:04:50+08:00">
                2018-12-18
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Computer-Vision/" itemprop="url" rel="index">
                    <span itemprop="name">Computer Vision</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Computer-Vision/Object-Detection/" itemprop="url" rel="index">
                    <span itemprop="name">Object Detection</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>This text refers to the paper Fast R-CNN <a href="https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Girshick_Fast_R-CNN_ICCV_2015_paper.html" target="_blank" rel="noopener">[1]</a>,which improves the <a href="Computer-Vision/Object-Detection/R-CNN">R-CNN</a> in that region proposals of the same image share feature maps.</p>
<h2 id="Feature-Sharing"><a href="#Feature-Sharing" class="headerlink" title="Feature Sharing"></a>Feature Sharing</h2><p>Still using selective search for region proposals, fast R-CNN does not crops regions and has it enter the CNN model, but instead, allows sharing feature maps afterward. In fact, fully CNN model normally extracts feature maps with location relationships kept. For instance, one pixel of the origin image can be simply mapped to the output feature maps via a simple dilation. Thus, the region proposals occupy the same regions of feature maps as they do in the original image. Given that, compared with R-CNN, this model must save much computation cost for feature extraction part.</p>
<h2 id="RoI-Pooling"><a href="#RoI-Pooling" class="headerlink" title="RoI Pooling"></a>RoI Pooling</h2><p>One challenge is that shapes of region proposals vary from time to time, and hence the fully-connected (FC) layers can not be adopted directly. To this end, the author proposes region of interest (RoI) pooling layer, embedded between CNN and FC. This pooling layer fixes the spatial extent, e.g. $(H, W)$, and vary the sliding window by dividing the $(h, w)$ RoI window into an $H\times W$ grid of sub-window of approximate size $h/H\times w/W$ and then max-pooling the values in each sub-window into the corresponding output grid cell.</p>
<blockquote>
<p>$\texttt{Note}:$ RoI pooling is actually a special case of spatial pyramid pooling used in SPPNet <a href="https://arxiv.org/abs/1406.4729" target="_blank" rel="noopener">[2]</a>.</p>
</blockquote>
<h2 id="Multi-task-Training"><a href="#Multi-task-Training" class="headerlink" title="Multi-task Training"></a>Multi-task Training</h2><p>Aside classifer, another barnch of FC is aligned, for bounding box regression, after a feature vector extracted. Instead of using multiple SVMs, here Softmax is utilized for classification:</p>
<script type="math/tex; mode=display">
\mathcal{L}_c(u) = -\log p_u,</script><p>cooperating with a regression loss as</p>
<script type="math/tex; mode=display">
\mathcal{L}_l(t^u, v) = \sum_{*\in\{x, y, w, h\}} f(t^u_* - v_*),</script><p>where</p>
<script type="math/tex; mode=display">
f(x) = \left\{
\begin{aligned}
    &\,0.5x^2,\;\;\text{if}\;|x| \lt 1 \\
    &\,|x| - 0.5,\;\;\text{otherwise}
\end{aligned}
\right.</script><p>$t^u$ is the ground truth of bouding box for class $u$.</p>
<blockquote>
<p>$\texttt{Note}:$ The metric $f(.)$ is a smooth version of $l_1$ norm, which is easy to compute gradient and meanwhile not sensitive to the outliers as $l_2$ norm is.</p>
</blockquote>
<p>Therefore, the result loss function is a linear combination of these sub two above:</p>
<script type="math/tex; mode=display">
\mathcal{L}(u, t^u, v) = \mathcal{L}_c(u) + \lambda[u\ge1]\mathcal{L}_l(t^u, v),</script><p>where $\lambda$ controls the balance.</p>
<h2 id="Fast-Detection"><a href="#Fast-Detection" class="headerlink" title="Fast Detection"></a>Fast Detection</h2><p>At test-time, an image is passed to the model, along with its region proposals $(\sim2000)$. The output is a class posterior probability distribution $p$ and a set of predicted boundind-box. For each proposal, a confidence is assigned to each class $k$ as $\mathbb{P}(k)$. A greedy non-maximum suppression is then adopted as R-CNN.</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] Girshick, R. (2015). Fast r-cnn. In Proceedings of the IEEE international conference on computer vision (pp. 1440-1448).</p>
<p>[2] He, K., Zhang, X., Ren, S., &amp; Sun, J. (2014, September). Spatial pyramid pooling in deep convolutional networks for visual recognition. In European conference on computer vision (pp. 346-361). Springer, Cham.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


		
    
		
			

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/Computer-Vision/Object-Detection/R-CNN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="RemiC">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Remi's Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Computer-Vision/Object-Detection/R-CNN/" itemprop="url">R-CNN</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-12-16T01:01:32+08:00">
                2018-12-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Computer-Vision/" itemprop="url" rel="index">
                    <span itemprop="name">Computer Vision</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Computer-Vision/Object-Detection/" itemprop="url" rel="index">
                    <span itemprop="name">Object Detection</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>This text refers to the paper Rich Feature Hierarchical for Accurate Object Detection and Semantic Segmentation <a href="https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Girshick_Rich_Feature_Hierarchies_2014_CVPR_paper.pdf" target="_blank" rel="noopener">[1]</a>, which proposes to detect objects via feature maps extracted by fully convolutional neural network (CNN), based on the <a href="Computer-Vision/Object-Detection/Selective-Search">selective search</a> algorithm for region proposals.</p>
<h2 id="Feature-Extraction"><a href="#Feature-Extraction" class="headerlink" title="Feature Extraction"></a>Feature Extraction</h2><p>R-CNN extracts feature maps of all region proposals from a CNN ended with a pooling layer. Given that the input size of CNN is fixed and region proposals vary from sizes, the author proposes to warp the proposals to the size of the input by a simple dilation. The region proposals here are given by selective search.</p>
<h2 id="Detector"><a href="#Detector" class="headerlink" title="Detector"></a>Detector</h2><h3 id="Classifier"><a href="#Classifier" class="headerlink" title="Classifier"></a>Classifier</h3><p>An SVM is set for each class, including background. When the feature vector of certain proposal enters SVMs, it is equally assigned a score, which is further used to rank proposals. Given all score regions, a greedy non-maximum suppression that rejects a region if it has an intersection-over-union (IoU) overlap with a higher scoring selected region larger than a <em>learned</em> threshold.</p>
<blockquote>
<p>$\texttt{Question}:$ How to learn this threshold?</p>
</blockquote>
<h3 id="Bounding-box-Regressor"><a href="#Bounding-box-Regressor" class="headerlink" title="Bounding-box Regressor"></a>Bounding-box Regressor</h3><p>To predict a more accurate bounding-box, a regression is stacked, trained for mapping proposals’ CNN features to locations and scales. Note $\{\left(P^i,G^i\right)\}_{i=1,…,N}$ the training samples, $P^i=\left(P^i_x,P^i_y,P^i_w,P^i_h \right)$ the proposal, $G^i=\left(G^i_x,G^i_y,G^i_w,G^i_h \right)$ the ground truth. The bounding-box regressed is thus</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \hat{G}_x =&\, P_w d_x(P) + P_x \\
    \hat{G}_y =&\, P_h d_y(P) + P_y \\
    \hat{G}_w =&\, P_w \exp(d_w(P)) \\
    \hat{G}_h =&\, P_h \exp(d_h(P)),
\end{aligned}</script><p>where $d_*(.)$ is a linear function operating on the CNN feature maps.</p>
<blockquote>
<p>$\texttt{Note}:$ For regression from $P_<em>$ to $\hat{G}_</em>$, the scale multiplier $P_w$ or $P_h$ is reasonable if the base units are supposed to be coherent across the equality.</p>
</blockquote>
<p>Note $W_<em>$ the weight of $d_</em>(.)$, its optimal solution is</p>
<script type="math/tex; mode=display">
\hat{W}_* = \arg_{W_*}\min \sum_{i=1}^N \left(t^i_* - W_*^T P^i \right)^2 + \lambda \|W_* \|^2,</script><p>where $\lambda$ controls the regularization, which is found to be important.</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] Girshick, R., Donahue, J., Darrell, T., &amp; Malik, J. (2014). Rich feature hierarchies for accurate object detection and semantic segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 580-587).</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


		
    
		
			

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/Computer-Vision/Object-Detection/Selective-Search/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="RemiC">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Remi's Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Computer-Vision/Object-Detection/Selective-Search/" itemprop="url">Selective Search</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-12-15T22:56:36+08:00">
                2018-12-15
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Computer-Vision/" itemprop="url" rel="index">
                    <span itemprop="name">Computer Vision</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Computer-Vision/Object-Detection/" itemprop="url" rel="index">
                    <span itemprop="name">Object Detection</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>This text refers to the paper Selective Search for Object Recognition <a href="https://staff.fnwi.uva.nl/th.gevers/pub/GeversIJCV2013.pdf" target="_blank" rel="noopener">[1]</a>, which propose a unified framework for object recognition/detection. The most important contribution, which will be discussed here, is a diversified sampling strategy for region proposal, namely selective search. It combines the strength of both exhaustive search and segmentation and is still widely used in object detection field.</p>
<h2 id="Region-Proposal"><a href="#Region-Proposal" class="headerlink" title="Region Proposal"></a>Region Proposal</h2><p>For detecting or recognizing a certain object in an image, it includes not only classification knowledge but also geometry information, i.e. location and scale. A straight solution is thus traversing all possible locations and scales and outputting the ones classified to the object required. These locations and scales are called <em>region proposal</em>, commonly in form of rectangle with a corner, length and width defined. However, given the huge visual search space, this kind of exhaustive search becomes computationally expensive. This is why the previous studies generally adopt coarse grid search, but still blind and costly, which forces to equip weak feature extractors and classifers to make up computation complexity.</p>
<h2 id="Reviews"><a href="#Reviews" class="headerlink" title="Reviews"></a>Reviews</h2><p>Although exhaustive search is costly, it holds several advantages which should be kept:</p>
<ul>
<li>Class-independence, which ensures a unified and general framework.</li>
<li>Not leaky, which returns all location and scale possibilities.</li>
<li>…</li>
</ul>
<p>Note that the huge search space arises because the locations and scales are sampled without any visual knowledge. Segmentaion is one method to provide a coarse but reliable proposals, which enables the sampling strategy not blind any more. But a class-independent segmentation may lead to a excessively fine proposals, and thus requires a strong algorithm forming good regions.</p>
<h2 id="Selective-Search"><a href="#Selective-Search" class="headerlink" title="Selective Search"></a>Selective Search</h2><p>Selective search is a region sampling strategy which combines the strength of exhaustive seach and segmentation. It initalize with a segmentation result and form good regions based on regions’ hierarchical relationships, without class knowledge. A fine to coarse “pyramid” can be thus generated via the greedy algorithm, where on each level a set of regions are proposed. The final region proposal contains about 2000 regions, which is much less than that exhaustive search but still covers reliable locations and scales. Details are discussed below.</p>
<h3 id="Hierarchical-Grouping"><a href="#Hierarchical-Grouping" class="headerlink" title="Hierarchical Grouping"></a>Hierarchical Grouping</h3><p>The objects in visual field as images are normally included in a hierarchical relationships. For instance, on a table there may be a bowl of eggs, and recognition of the table should upstream from the eggs. From this point, the author starts from rather fine segmentation results [2], then use a greedy algorithm to iteratively group pairs of neighbouring regions together based on a similarity ranked, i.e. the most similar pair of neighbouring regions are merged for each iteration. The similarity here is computed by a function proposed by the author, which combines various standards as described below.</p>
<h3 id="Diversification-for-Similarity"><a href="#Diversification-for-Similarity" class="headerlink" title="Diversification for Similarity"></a>Diversification for Similarity</h3><p>The author propose to compute the final similarity between neghbouring regions $(r_i, r_j)$ by summing up four weighted sub-similarity functions $s_*(.,.)$:</p>
<ul>
<li>Colour</li>
</ul>
<script type="math/tex; mode=display">
s_c(r_i, r_j) = \sum_{k=1}^n \min(c_i^k, c_j^k),</script><p>where $c_i^k$ denotes the colour normalized of $r_i$ in $k$-th colour bin.</p>
<ul>
<li>Texture</li>
</ul>
<script type="math/tex; mode=display">
s_t(r_i, r_j) = \sum_{k=1}^n \min(t_i^k, t_j^k),</script><p>where $t_i^k$ denotes the texture histogram value of $r_i$ in $k$-th histogram bin.</p>
<ul>
<li>Size</li>
</ul>
<script type="math/tex; mode=display">
s_s(r_i, r_j) = 1 - \frac{size(r_i) + size(r_j)}{size(im)},</script><p>which requires the regions left to be in similar sizes and will be updated by $size(r_t)=size(r_i)+size(r_j)$.</p>
<ul>
<li>Fitness</li>
</ul>
<script type="math/tex; mode=display">
s_f(r_i, r_j) = 1 - \frac{B_{ij} - size(r_i) - size(r_j)}{size(im)},</script><p>where $B_{ij}$ is the tight bounding box containing $r_i$ and $r_j$, encouraging to merge regions with large parts touched.</p>
<p>Finally, the similarity is</p>
<script type="math/tex; mode=display">
s(r_i, r_j) = \sum_{*\in E} a_* s_*(r_i, r_j),\;\; E = \{c, t, s, f \},</script><p>where $a_*\in\{0,1 \}$ indicates whether to use the corresponding similarity.</p>
<h2 id="Combining-Locations"><a href="#Combining-Locations" class="headerlink" title="Combining Locations"></a>Combining Locations</h2><p>Once region proposals are given by the selective search, it should be noted that they are not equi-possible to be an object and those not likely tend to be removed for computation efficiency. To this end, the authot assigns for each region $r_i$ a value $v_i=\delta\cdot i$ and rank based on this all the regions, where $\delta$ is a random number to prevent over emphasize on large regions. The regions with the largest $v$ will be retained, and the others are filtered by thresholding.</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] Uijlings, J. R., Van De Sande, K. E., Gevers, T., &amp; Smeulders, A. W. (2013). Selective search for object recognition. International journal of computer vision, 104(2), 154-171.</p>
<p>[2] Felzenszwalb, P. F., &amp; Huttenlocher, D. P. (2004). Efficient graph-based image segmentation. International journal of computer vision, 59(2), 167-181.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


		
    
		
			

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/Machine-Learning/Basic-Method/On-Gradients-of-Stochastic-Neurons/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="RemiC">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Remi's Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Machine-Learning/Basic-Method/On-Gradients-of-Stochastic-Neurons/" itemprop="url">On Gradients of Stochastic Neurons</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-12-06T21:06:26+08:00">
                2018-12-06
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Machine Learning</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/Basic-Method/" itemprop="url" rel="index">
                    <span itemprop="name">Basic Method</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>This text mainly refers to the paper <a href="https://arxiv.org/abs/1308.3432" target="_blank" rel="noopener">Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation</a> [1]. Regardless of Stochastic Times Smooth (STS) units and Straight-Through Estimator (STE), the technique detail of an unbiased estimator of gradient for stochastic binary neurons is discussed in this text.</p>
<h2 id="Stochastic-Binary-Neurons"><a href="#Stochastic-Binary-Neurons" class="headerlink" title="Stochastic Binary Neurons"></a>Stochastic Binary Neurons</h2><p>Considering hard non-linearity as activation function in neural networks, the gradients are normaly incomputable, but can be estimated with the help of stochaistic pertubation, which is actually a random noise multiplied on neurons, e.g. dropout. These kind of neurons are referred as stochastic neurons in this text, and become more insteresting in binary case, i.e. the output activated of neurons is either 0 or 1, namely stochastic binary neurons. One may ask for the strategy to binarize the outputs, which is proposed to be based on a sigmoid probability. For illustration, say a fully-connected layer with input $x$, weight $W$, bias $b$ and output activated $h$, then</p>
<script type="math/tex; mode=display">
h_i = f(a_i, z_i) = \mathbb{I}_{z_i \lt \sigma(a_i)},\;\; a_i = b_i + \sum_j W_{ij}x_j,</script><p>where $z_i\sim \mathcal{U}[0,1]$ is uniform and $\sigma(u)=1/(1+\exp(-u))$ is sigmoid function.</p>
<h2 id="Unbiased-Estimator-for-Gradient"><a href="#Unbiased-Estimator-for-Gradient" class="headerlink" title="Unbiased Estimator for Gradient"></a>Unbiased Estimator for Gradient</h2><p>Let $\mathcal{L}$ be the objective function, then computing directly the gradient of $\mathcal{L}$ with regard to parameters are intractable. However, an unbiases estimator is still feasible. Note that accordint to the chain rule, i.e.</p>
<script type="math/tex; mode=display">
\frac{\partial\mathcal{L}}{\partial W_{ij}} = \frac{\partial\mathcal{L}}{\partial a_i}\cdot \frac{\partial a_i}{\partial W_{ij}},</script><p>the first term on the right is the only one in need to estimate, whose expectation is thus in need if the estimation is supposed to be unbiased. </p>
<p>Additionally, among advances of recent network designs, dropout is commonly included, which is stochastic as well as $z$. In this case, these random parameters should also be considered during the estimation for gradient. Note that this dropout noise does not require updates and is viewed as fixed once sampled when forwarding. Therefore, the expectation is conditionned on the random parameters if they influence $a$. For clarity, let $\Gamma=\{z_i\}\bigcup\ c_i\bigcup c_{-i}$ be the set of all random variables divided according to whether they influence $a_i$ as $c_i$ does. Note $\mathcal{L}=\mathcal{L}(h_i,c_i,c_{-i})$.</p>
<p>Now compute the expectation of $L$ conditioned on $c_i$,</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \mathbb{E}\left[\mathcal{L} | c_i \right] =&\, \mathbb{E}_{c_{-i}}\left[\mathbb{E}_{z_i}\left[L | c_i \right] \right] \\
                                    =&\, \mathbb{E}_{c_{-i}}\left[\mathbb{E}_{z_i}\left[h_i\mathcal{L}\left(1, c_i, c_{-i} \right) + (1 - h_i)\mathcal{L}\left(0, c_i, c_{-i} \right) \right] \right] \\
                                    =&\, \mathbb{E}_{c_{-i}}\left[\mathbb{P}\left(h_i=1 | a_i \right)\mathcal{L}\left(1, c_i, c_{-i} \right) + \mathbb{P}\left(h_i=0 | a_i \right)\mathcal{L}\left(0, c_i, c_{-i} \right) \right] \\
                                    =&\, \mathbb{E}_{c_{-i}}\left[\sigma(a_i)\mathcal{L}\left(1, c_i, c_{-i} \right) + \left(1 - \sigma(a_i) \right)\mathcal{L}\left(0, c_i, c_{-i} \right) \right].
\end{aligned}</script><p>Further derive the average gradient,</p>
<script type="math/tex; mode=display">
\begin{aligned}
    g_i = \mathbb{E}\left[\frac{\partial\mathcal{L}}{\partial a_i} | c_i \right] =&\, \frac{\partial\mathbb{E}\left[\mathcal{L} | c_i\right]}{\partial a_i} \\
                                                                     =&\, \mathbb{E}_{c_{-i}}\left[\sigma'(a_i)\mathcal{L}\left(1, c_i, c_{-i} \right) - \sigma'(a_i)\mathcal{L}\left(0, c_i, c_{-i} \right) \right] \\
                                                                     =&\, \mathbb{E}_{c_{-i}}\left[\sigma(a_i)\left(1 - \sigma(a_i) \right)\left(\mathcal{L}\left(1, c_i, c_{-i} \right) - \mathcal{L}\left(0, c_i, c_{-i} \right) \right) \right].
\end{aligned}</script><p>Now consider the estimator</p>
<script type="math/tex; mode=display">
\hat{g}_i = \left(h_i - \sigma(a_i) \right)\mathcal{L}(h_i, c_i, c_{-i}) = h_i\left(1 - \sigma(a_i) \right)\mathcal{L}(1, c_i, c_{-i}) - \sigma(a_i)(1 - h_i)\mathcal{L}(0, c_i, c_{-i}),</script><p>whose expectation is</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \mathbb{E}[\hat{g}_i | c_i] =&\, \mathbb{E}_{c_{-i}, z_i}\left[h_i\left(1 - \sigma(a_i) \right)\mathcal{L}(1, c_i, c_{-i}) - \sigma(a_i)(1 - h_i)\mathcal{L}(0, c_i, c_{-i})\right] \\
                                =&\, \mathbb{E}_{c_{-i}}\left[\sigma(a_i)\left(1 - \sigma(a_i) \right)\mathcal{L}(1, c_i, c_{-i}) - \sigma(a_i)(1 - \sigma(a_i))\mathcal{L}(0, c_i, c_{-i}) \right] \\
                                =&\, \mathbb{E}_{c_{-i}}\left[\sigma(a_i)\left(1 - \sigma(a_i) \right)\left(\mathcal{L}(1, c_i, c_{-i}) - \mathcal{L}(0, c_i, c_{-i}) \right) \right],
\end{aligned}</script><p>which is the same as that of the gradient. Thus $\hat{g}_i$ is an unbiased estimator for gradient.</p>
<h2 id="Low-Variance-Choice"><a href="#Low-Variance-Choice" class="headerlink" title="Low Variance Choice"></a>Low Variance Choice</h2><p>The very estimator is actually a special case of <a href="https://link.springer.com/article/10.1007/BF00992696" target="_blank" rel="noopener">policy gradient</a> [2] widely used in reinforcement learning. Consider the binarization as a random action sampled from $\mathcal{B}(\sigma(a_i))$, the objective $\mathcal{L}$ as reward $R$, and suppose trajectory $\tau$ to be unitary. The common choice for optimization is policy gradient method,</p>
<script type="math/tex; mode=display">
\frac{\partial\mathbb{E}_\tau[R]}{\partial a_i} = \mathbb{E}_\tau\left[R\cdot \frac{\partial \log p_{a_i}(h_i)}{\partial a_i} \right].</script><blockquote>
<p>$\texttt{Proof}:$<br>Suppose $p_{a_i}(h_i)$ is derivable on $0$ with regard to $a_i$, then</p>
<script type="math/tex; mode=display">
\frac{\partial \log p_{a_i}(h_i)}{\partial a_i} = \frac{1}{p_{a_i}(h_i)}\frac{\partial p_{a_i}(h_i)}{\partial a_i}.</script><p>After discretization, </p>
<script type="math/tex; mode=display">
\begin{aligned}
   \mathbb{E}_\tau\left[R\cdot \frac{\partial \log p_{a_i}(h_i)}{\partial a_i} \right] =&\, R_1\cdot \mathbb{P}\left(h_i=1 | a_i \right) \frac{1}{\mathbb{P}\left(h_i=1 | a_i \right)}\frac{\partial \mathbb{P}\left(h_i=1 | a_i \right)}{\partial a_i} \\
+&\, R_0\cdot \mathbb{P}\left(h_i=0 | a_i \right)\frac{1}{\mathbb{P}\left(h_i=0 | a_i \right)}\frac{\partial \mathbb{P}\left(h_i=0 | a_i \right)}{\partial a_i} \\
=&\, R_1\cdot \frac{\partial \mathbb{P}\left(h_i=1 | a_i \right)}{\partial a_i} + R_0\cdot \frac{\partial \mathbb{P}\left(h_i=0 | a_i \right)}{\partial a_i} \\
=&\, \frac{\partial}{\partial a_i}\left(R_1\cdot \mathbb{P}\left(h_i=1 | a_i \right) + R_0\cdot \mathbb{P}\left(h_i=0 | a_i \right) \right) \\
=&\, \frac{\partial\mathbb{E}_{h_i}[R]}{\partial a_i} \\
=&\, \frac{\partial\mathbb{E}_\tau[R]}{\partial a_i}.
\end{aligned}</script></blockquote>
<p>Given that, it is natural to extract $R\cdot \partial_{a_i} \log p_{a_i}(h_i)$ for gradient estimator, which in this case, is</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \mathcal{L}\cdot \frac{\partial \log \mathbb{P}(h_i | a_i)}{\partial a_i} =&\, h_i\mathcal{L}\cdot \left(1 + \exp(-a_i) \right) \frac{\exp(-a_i)}{\left(1 + \exp(-a_i) \right)^2} \\
                                                                              +&\, (1 - h_i)\mathcal{L}\cdot \left(1 + \exp(a_i) \right) \frac{-\exp(a_i)}{\left(1 + \exp(a_i) \right)^2}  \\
                                                                              =&\, h_i\mathcal{L}\cdot \left(1 - \sigma(a_i) \right) - (1 - h_i)\mathcal{L} \cdot \sigma(a_i) \\
                                                                              =&\, h_i\mathcal{L} - \sigma(a_i)\mathcal{L} - h_i\mathcal{L}\cdot \sigma(a_i) + h_i\mathcal{L}\cdot \sigma(a_i) \\
                                                                              =&\, \left(h_i - \sigma(a_i) \right)\mathcal{L},
\end{aligned}</script><p>which is exactly the estimator proposed.</p>
<p>Furthermore, in reinforcement learning, normaly a baseline is assigned for reward so that the gradient is of low variance. Similarly, this baseline is also necessary in the estimator, denoted by $\bar{\mathcal{L}}_i$. Then reformulate the estimator</p>
<script type="math/tex; mode=display">
\hat{g}_i = \left(h_i - \sigma(a_i) \right)\left(\mathcal{L} - \bar{\mathcal{L}}_i \right).</script><p>To minmize its variance, which is</p>
<script type="math/tex; mode=display">
\mathbb{V}ar\left[\hat{g}_i \right] = \mathbb{V}ar\left[\left(h_i - \sigma(a_i) \right)\mathcal{L} \right] - \Delta,</script><p>where</p>
<script type="math/tex; mode=display">
\Delta = \mathbb{E}\left[\left(h_i - \sigma(a_i) \right)^2\left(\mathcal{L}^2 - \left(\mathcal{L} - \bar{\mathcal{L}}_i\right)^2 \right) \right]</script><p>should be maximized by minimizing $\mathbb{E}\left[\left(h_i - \sigma(a_i) \right)^2\left(\mathcal{L} - \bar{\mathcal{L}}_i\right)^2 \right]$. Then by derivating with regrad to $\bar{\mathcal{L}}_i$,</p>
<script type="math/tex; mode=display">
\mathbb{E}\left[\left(h_i - \sigma(a_i) \right)^2\left(\mathcal{L} - \bar{\mathcal{L}}_i\right) \right] = 0,</script><p>thus</p>
<script type="math/tex; mode=display">
\bar{\mathcal{L}}_i = \frac{\mathbb{E}\left[\left(h_i - \sigma(a_i) \right)^2\mathcal{L} \right]}{\mathbb{E}\left[\left(h_i - \sigma(a_i) \right)^2 \right]}.</script><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] Bengio, Y., Léonard, N., &amp; Courville, A. (2013). Estimating or propagating gradients through stochastic neurons for conditional computation. arXiv preprint arXiv:1308.3432.</p>
<p>[2] Williams, R. J. (1992). Simple statistical gradient-following algorithms for connectionist reinforcement learning. Machine learning, 8(3-4), 229-256.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


		
    
		
			

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/Machine-Learning/Basic-Method/Deep-Neural-Networks-as-Gaussian-Processes/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="RemiC">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Remi's Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Machine-Learning/Basic-Method/Deep-Neural-Networks-as-Gaussian-Processes/" itemprop="url">Deep Neural Networks as Gaussian Processes</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-09-24T18:57:22+08:00">
                2018-09-24
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Machine Learning</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/Basic-Method/" itemprop="url" rel="index">
                    <span itemprop="name">Basic Method</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>This text refers to the paper <a href="https://arxiv.org/abs/1711.00165" target="_blank" rel="noopener">DEEP NEURAL NETWORKS AS GAUSSIAN PROCESSES</a> published at ICLR 2018, mainly revealing the equivalence between infinitely wide deep neural networks (NN) and Gaussian processes (GP).</p>
<h2 id="Notation"><a href="#Notation" class="headerlink" title="Notation"></a>Notation</h2><ul>
<li><p>$L$: depth of NN</p>
</li>
<li><p>$N_l$: width of layer $l$</p>
</li>
<li><p>$\phi$: activation function (nonlinearities)</p>
</li>
<li><p>$x^l_i$: $i$-th post-nonlinearity of $l$-th layer</p>
</li>
<li><p>$z^l_i$: $i$-th post-affine of $l$-th layer</p>
</li>
<li><p>$x^\alpha$: input data $\alpha$ in $\mathbb{R}^D$</p>
</li>
<li><p>$W^l_{ij}$: weight element of $l$-th layer</p>
</li>
<li><p>$b^l_i$: bias element of $l$-th layer</p>
</li>
<li><p>$\mathcal{GP}(\mu, K)$: Gaussian process with expectation $\mu(.)$ and covariance $K(.,.)$</p>
</li>
</ul>
<h2 id="GP-and-Single-layer-NN"><a href="#GP-and-Single-layer-NN" class="headerlink" title="GP and Single-layer NN"></a>GP and Single-layer NN</h2><p>As for a single-layer NN, the $i$-th output is computed as</p>
<script type="math/tex; mode=display">
z^1_i(x) = b^1_i + \sum_{j=1}^{N_1} W^1_{ij}x^1_j(x),\;\;\;\; x^1_j(x) = \phi\left(b^0_j + \sum_{k=1}^D W^0_{jk}x_k \right).</script><p>According to the Central Limit Theorem, when $N_1\rightarrow\infty$, $z^1_i(x)$ will be Gaussian distributed. Given that, $\{z^1_i(x^{\alpha=1}),…,z^1_i(x^{\alpha=k}) \}$ will have a joint multivariate Gaussian distribution, i.e. $z^1_i\sim\mathcal{GP}(\mu^1,K^1)$.</p>
<blockquote>
<p>$\texttt{Note}:$ The expectation and the covariance are independent of $i$, because <em>a priori</em> there is no knowledge that the output varies from the position of neurons. The same for $\sigma^2_b$ and $\sigma^2_w$.</p>
</blockquote>
<p>Moreover, because the expectation of parameters ($W$ and $b$) is null <em>a priori</em>, $\mu^1$ is then null as well and</p>
<script type="math/tex; mode=display">
\begin{aligned}
    K^1(x, x') =&\, \mathbb{E}\left[z^1_i(x) z^1_i(x') \right] \\
               =&\, \sigma^2_b + \sigma^2_w \mathbb{E}\left[x^1_i(x) x^1_i(x') \right] \\
               =&\, \sigma^2_b + \sigma^2_w \mathbb{C}(x, x'),
\end{aligned}</script><p>where $\mathbb{C}(x,x’)$ is an integral against $W^0$ and $b^0$, as seen in <a href="http://www.cs.toronto.edu/~radford/bnn.book.html" target="_blank" rel="noopener">Bayesian Learning for Neural Networks</a>.</p>
<h2 id="GP-and-Deep-NN"><a href="#GP-and-Deep-NN" class="headerlink" title="GP and Deep NN"></a>GP and Deep NN</h2><p>Generalize the post-nonlinearity and the post-affine in a deep NN as</p>
<script type="math/tex; mode=display">
z^l_i(x) = b^l_i + \sum_{j=1}^{N_1} W^l_{ij}x^l_j(x),\;\;\;\; x^l_j(x) = \phi\left(z^{l-1}_j(x) \right).</script><p>Similar with the single-layer case, $z^l_i\sim\mathcal{GP}(0,K^l)$, with</p>
<script type="math/tex; mode=display">
\begin{aligned}
    K^l(x, x') =&\, \mathbb{E}\left[z^l_i(x) z^l_i(x') \right] \\
               =&\, \sigma^2_b + \sigma^2_w \mathbb{E}\left[x^l_i(x) x^l_i(x') \right] \\
               =&\, \sigma^2_b + \sigma^2_w \mathbb{E}_{z^{l-1}_i\sim \mathcal{GP}(0, K^{l-1})}\left[\phi(z^{l-1}_i(x) z^{l-1}_i(x')) \right].
\end{aligned}</script><p>As the joint Gaussian distribution is described with $K^l(x,x)$, $K^l(x,x’)$ and $K^l(x’,x’)$, the covariance can be rewritten as</p>
<script type="math/tex; mode=display">
K^l(x, x') = \sigma^2_b + \sigma^2_w F_\phi \left(K^{l-1}(x, x), K^{l-1}(x, x'), K^{l-1}(x', x') \right).</script><p>For the beginning of this iterative series of GP, note $W_{ij}^0$, $b^0_j$ and $K^0$, and then</p>
<script type="math/tex; mode=display">
K^0(x, x') = \mathbb{E}\left[z^0_j(x) z^0_j(x') \right] = \sigma^2_b + \sigma^2_w \cdot \frac{\langle x, x' \rangle}{N^D}.</script><p>Therefore, the each layer (with infinity of neurons) of the deep NN is equivalent to a Gaussian Process.</p>
<h2 id="Bayesian-Training"><a href="#Bayesian-Training" class="headerlink" title="Bayesian Training"></a>Bayesian Training</h2><p>Given a dataset $\mathcal{D}=\{(x^1,t^1),…,(x^n,t^n) \}$, the model $z(.)$ is supposed to make prediction for a test sample $x^*$. In Bayesian training process, the prediction is over a distribution as</p>
<script type="math/tex; mode=display">
\begin{aligned}
    p(z^* | x^*, \mathcal{D}) =&\, \int p(z^* | x^*, z, x) p(z | \mathcal{D}) dz \\
                              =&\, \int \frac{p(z^*, z | x^*, x)}{p(z | x^*, x)} p(z | \mathcal{D}) dz \\
                              =&\, \int p(z^*, z | x^*, x)\frac{p(z | t, x)}{p(z | x)}  dz \\
                              =&\, \int p(z^*, z | x^*, x)\frac{p(z, t | x)}{p(z | x) p(t | x)}  dz \\
                              =&\, \int p(z^*, z | x^*, x)\frac{p(t | z, x)}{p(t | x)}  dz \\
                              =&\, \frac{1}{p(t)} \int p(z^*, z | x^*, x)p(t | z) dz,
\end{aligned}</script><p>where $t|z\sim\mathcal{N}(0, \sigma^2_\epsilon)$ due to a noise effect added to the prediction.</p>
<p>Since</p>
<script type="math/tex; mode=display">
z^*, z | x^*, x \sim \mathcal{GP}(0,K),</script><p>where</p>
<script type="math/tex; mode=display">
K = \left[
\begin{matrix}
    K_{\mathcal{D},\mathcal{D}} & K^T_{x^*, \mathcal{D}} \\
    K_{x^*, \mathcal{D}} & K_{x^*, x^*}
\end{matrix} \right],</script><p>the integral can be calculated analytically, resulting in </p>
<script type="math/tex; mode=display">
z* | \mathcal{D}, x^* \sim \mathcal{N}(\bar{\mu}, \bar{K}),</script><p>where</p>
<script type="math/tex; mode=display">
\bar{\mu} = K_{x^*, \mathcal{D}} \left(K_{\mathcal{D},\mathcal{D}} + \sigma^2_\epsilon \mathbb{I}_n \right)^{-1} t,</script><script type="math/tex; mode=display">
\bar{K} = K_{x^*, x^*} - K_{x^*, \mathcal{D}} \left(K_{\mathcal{D},\mathcal{D}} + \sigma^2_\epsilon \mathbb{I}_n \right)^{-1} K^T_{x^*, \mathcal{D}}.</script><p>Therefore, the prediction can be done with any decision function over $z$ <em>a posterior</em>.</p>
<blockquote>
<p>$\texttt{Note}:$ To achieve a high performance, various methods can be applied to optimize the parameters, e.g. cross-validation, gradiant ascent.</p>
</blockquote>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] Lee, J., Bahri, Y., Novak, R., Schoenholz, S. S., Pennington, J., &amp; Sohl-Dickstein, J. (2017). Deep neural networks as gaussian processes.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


		
    
		
			

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/Machine-Learning/Training-Trick/Noise-and-Tikhonov-Regularization/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="RemiC">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Remi's Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Machine-Learning/Training-Trick/Noise-and-Tikhonov-Regularization/" itemprop="url">Noise and Tikhonov Regularization</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-09-10T19:15:24+08:00">
                2018-09-10
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Machine Learning</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/Training-Trick/" itemprop="url" rel="index">
                    <span itemprop="name">Training Trick</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>This text refers to <a href="https://ieeexplore.ieee.org/document/6796505/" target="_blank" rel="noopener">Training with Noise is Equivalent to Tikhonov Regularization</a>.</p>
<h2 id="Preliminary"><a href="#Preliminary" class="headerlink" title="Preliminary"></a>Preliminary</h2><p>Consider a feed-forward neural network mapping input data $\mathbf{x}=(x_1,…,x_D)$ to output $f(\mathbf{x})=(f_1(\mathbf{x}),…,f_C(\mathbf{x}))$, associated with ground truth $\mathbf{t}=(t_1,…,t_C)$. A common choice of loss function is</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \mathcal{L} =&\, \frac{1}{2}\int\int \left\|f(\mathbf{x}) - \mathbf{t} \right\|^2 p(\mathbf{x}, \mathbf{t}) d\mathbf{x}d\mathbf{t} \\
                =&\, \frac{1}{2} \int\int \sum_{k=1}^C \left(f_k(\mathbf{x}) - t_k \right)^2 p(t_k | \mathbf{x})p(\mathbf{x})d\mathbf{x}dt_k.
\end{aligned}</script><blockquote>
<p>$\texttt{Note}:$ Especially, for a finit discrete dataset,</p>
<script type="math/tex; mode=display">
p(\mathbf{x}, \mathbf{t}) = \frac{1}{n}\sum_q (\mathbf{x} - \mathbf{x}^q)(\mathbf{t} - \mathbf{t}^q).</script><p>Then the loss function becomes</p>
<script type="math/tex; mode=display">
\mathcal{L} = \frac{1}{2n}\sum_q \left\|f(\mathbf{x}^q) - \mathbf{t}^q \right\|^2.</script></blockquote>
<h2 id="Tikhonov-Regularization"><a href="#Tikhonov-Regularization" class="headerlink" title="Tikhonov Regularization"></a>Tikhonov Regularization</h2><p>One common way to prevend model $f$ from overfitting is regularizing the original loss function as</p>
<script type="math/tex; mode=display">
\tilde{\mathcal{L}} = \mathcal{L} + \lambda \Omega(f),</script><p>where $\lambda$ is a hyper-parameter balance the bias and variance of the model. For the case of one input $x$ and one output $f(x)$, the class of Tikhonov regularizers takes the form as</p>
<script type="math/tex; mode=display">
\Omega(f) = \sum_{r=0}^R \int_a^b h_r(x) \left(\frac{d^rf}{dx^r} \right)^2 dx,</script><p>where $h_r(.)\ge 0$ for $r=0,…,R-1$ and $h_R(.)&gt;0$.</p>
<h2 id="Noise-Injection"><a href="#Noise-Injection" class="headerlink" title="Noise Injection"></a>Noise Injection</h2><p>Apart from regularized loss function, adding noise to the input data is another well-known approach. In this case, the loss function is</p>
<script type="math/tex; mode=display">
\tilde{\mathcal{L}} = \frac{1}{2}\int\int\int \sum_{k=1}^C \left(f_k(\mathbf{x} + \mathbf{n}) - t_k \right)^2 p(t_k | \mathbf{x})p(\mathbf{x})p(\mathbf{n}) d\mathbf{x}dt_kd\mathbf{n}.</script><p>Expand the model function $f$ <em>w.r.t</em> $\mathbf{n}$,</p>
<script type="math/tex; mode=display">
f_k(\mathbf{x} + \mathbf{n}) = f_k(\mathbf{x}) + \sum_{i=1}^D n_i\frac{\partial f_k}{\partial x_i} + \frac{1}{2}\sum_{i=1}^D\sum_{j=1}^D n_in_j \frac{\partial^2 f_k}{\partial{x_i}\partial{x_j}} + \mathcal{O}(\|\mathbf{n} \|^3).</script><p>The noise distribution is generally chosen to be null on average and uncorrelated between different input elements. Hence,</p>
<script type="math/tex; mode=display">
\int n_i p(\mathbf{n})d\mathbf{n} = 0,</script><script type="math/tex; mode=display">
\int n_i n_j p(\mathbf{n})d\mathbf{n} = \eta^2\delta_{ij},</script><p>where $\eta^2$ is the amplitude of the noise injected.</p>
<p>By using these two properties and assuming small noise, the loss function can be written as</p>
<script type="math/tex; mode=display">
\tilde{\mathcal{L}} = \mathcal{L} + \eta^2\mathcal{L}_r,</script><p>where</p>
<script type="math/tex; mode=display">
\mathcal{L}_r = \frac{1}{2}\int\int \sum_{k=1}^C\sum_{i=1}^D \left(\left(\frac{\partial f_k}{\partial x_i} \right)^2 + \left(f_k(\mathbf{x}) - t_k \right)\frac{\partial^2 f_k}{\partial x_i^2} \right) p(t_k | \mathbf{x})p(\mathbf{x})d\mathbf{x}dt_k.</script><blockquote>
<p>$\texttt{Note}:$ In fact,</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \tilde{\mathcal{L}} =&\, \frac{1}{2}\int \sum_{k=1}^C \left(f_k(\mathbf{x}) + \sum_{i=1}^D n_i\frac{\partial f_k}{\partial x_i} + \frac{1}{2}\sum_{i=1}^D\sum_{j=1}^D n_in_j \frac{\partial^2 f_k}{\partial{x_i}\partial{x_j}} - t_k \right)^2 p(t_k, \mathbf{x}, \mathbf{n}) d(t_k, \mathbf{x}, \mathbf{n}) \\
                        =&\, \frac{1}{2}\int \sum_{k=1}^C \left(f_k(\mathbf{x}) - t_k \right)^2 p(t_k, \mathbf{x}) d(t_k, \mathbf{x}) \\
                         &\,+ \frac{1}{2}\int \sum_{k=1}^C 2\left(f_k(\mathbf{x}) - t_k \right)\left(\sum_{i=1}^D n_i\frac{\partial f_k}{\partial x_i} + \frac{1}{2}\sum_{i=1}^D\sum_{j=1}^D n_in_j \frac{\partial^2 f_k}{\partial{x_i}\partial{x_j}} \right) p(t_k, \mathbf{x}, \mathbf{n}) d(t_k, \mathbf{x}, \mathbf{n}) \\
                         &\,+  \frac{1}{2}\int \sum_{k=1}^C \left(\sum_{i=1}^D n_i\frac{\partial f_k}{\partial x_i} + \frac{1}{2}\sum_{i=1}^D\sum_{j=1}^D n_in_j \frac{\partial^2 f_k}{\partial{x_i}\partial{x_j}} \right)^2 p(t_k, \mathbf{x}, \mathbf{n}) d(t_k, \mathbf{x}, \mathbf{n}) \\
                        =&\, \mathcal{L} \\
                         &\,+ \frac{1}{2}\int \sum_{k=1}^C \left(f_k(\mathbf{x}) - t_k \right)\sum_{i=1}^D\sum_{j=1}^D n_in_j \frac{\partial^2 f_k}{\partial{x_i}\partial{x_j}} p(t_k, \mathbf{x}, \mathbf{n}) d(t_k, \mathbf{x}, \mathbf{n}) \\
                         &\,+ \frac{1}{2}\int \sum_{k=1}^C \left(\sum_{i=1}^D n_i\frac{\partial f_k}{\partial x_i} + \frac{1}{2}\sum_{i=1}^D\sum_{j=1}^D n_in_j \frac{\partial^2 f_k}{\partial{x_i}\partial{x_j}} \right)^2 p(t_k, \mathbf{x}, \mathbf{n}) d(t_k, \mathbf{x}, \mathbf{n}) \\
                        =&\, \mathcal{L} \\
                         &\, + \frac{\eta^2}{2}\int \sum_{k=1}^C \left(f_k(\mathbf{x}) - t_k \right)\sum_{i=1}^D \frac{\partial^2 f_k}{\partial{x_i}\partial{x_j}} p(t_k, \mathbf{x}) d(t_k, \mathbf{x}) \\
                         &\, + \frac{\eta^2}{2} \int \sum_{k=1}^C \sum_{i=1}^D \left(\frac{\partial f_k}{\partial x_i} \right)^2 p(t_k, \mathbf{x}) d(t_k, \mathbf{x}) + \mathcal{O}(\|n\|^3) \\
                        =&\, \mathcal{L} + \eta^2\mathcal{L}_r,
\end{aligned}</script></blockquote>
<h2 id="Equivalence"><a href="#Equivalence" class="headerlink" title="Equivalence"></a>Equivalence</h2><p>To simplify the expressions, define</p>
<script type="math/tex; mode=display">
\langle t_k | \mathbf{x} \rangle = \int t_k p(t_k | \mathbf{x}) dt_k,</script><script type="math/tex; mode=display">
\langle t_k^2 | \mathbf{x} \rangle = \int t_k^2 p(t_k | \mathbf{x}) dt_k.</script><p>Then the original loss can be rewritten as</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \mathcal{L} =&\, \frac{1}{2}\sum_{k=1}^C\int \left(f_k(\mathbf{x}) - \langle t_k | \mathbf{x} \rangle \right)^2 p(\mathbf{x}) d\mathbf{x} \\
                 &\,+ \frac{1}{2}\sum_{k=1}^C\int \langle t_k^2 | \mathbf{x} \rangle - \langle t_k | \mathbf{x} \rangle^2 p(\mathbf{x}) d(\mathbf{x}).
\end{aligned}</script><p>The minimum is reached when $f_k(\mathbf{x})=\langle t_k | \mathbf{x} \rangle$. Therefore, the optimal for the total loss will have the form as</p>
<script type="math/tex; mode=display">
f^*_k(\mathbf{x}) = \langle t_k | \mathbf{x} \rangle + \mathcal{O}(\eta^2).</script><p>Note that the regularization term becomes</p>
<script type="math/tex; mode=display">
\mathcal{L}_r = \frac{1}{2}\int\sum_{k=1}^C\sum_{i=1}^D \left(\left(\frac{\partial f_k}{\partial x_i} \right)^2 + \left(f_k(\mathbf{x}) - \langle t_k | \mathbf{x} \rangle \right)\frac{\partial^2 f_k}{\partial x_i^2} \right)p(\mathbf{x})d\mathbf{x},</script><p>where the second term vanishes to the order of $\eta^2$. Given that the noise is small, indicating small $\eta^2$, the second term can be removed. Then the regularization term becomes</p>
<script type="math/tex; mode=display">
\mathcal{L}_r = \frac{1}{2}\int\sum_{k=1}^C\sum_{i=1}^D \left(\frac{\partial f_k}{\partial x_i} \right)^2 p(\mathbf{x})d\mathbf{x}.</script><blockquote>
<p>$\texttt{Note}:$ For the discrete dataset, the regularization can be written as</p>
<script type="math/tex; mode=display">
\mathcal{L}_r = \frac{1}{2}\sum_q\sum_{k=1}^C\sum_{i=1}^D \left(\frac{\partial f_k}{\partial x_i^q} \right)^2.</script></blockquote>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] Bishop, C. M. (1995). Training with noise is equivalent to tikhonov regularization. Neural Computation, 7(1), 108-116.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


		
    
		
			

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/Machine-Learning/Training-Trick/Use-of-Noise-in-Training/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="RemiC">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Remi's Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Machine-Learning/Training-Trick/Use-of-Noise-in-Training/" itemprop="url">Use of Noise in Training</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-08-07T15:50:41+08:00">
                2018-08-07
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Machine Learning</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/Training-Trick/" itemprop="url" rel="index">
                    <span itemprop="name">Training Trick</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>This text refers to the paper <a href="https://ieeexplore.ieee.org/document/155944/" target="_blank" rel="noopener">Noise injection into inputs in back-propagation learning</a>, mainly discussing about the use of noise in training networks.</p>
<h2 id="Noise-Sensitivity"><a href="#Noise-Sensitivity" class="headerlink" title="Noise Sensitivity"></a>Noise Sensitivity</h2><p>In literature of machine learning, generalization capacity is among the most important metrics. In short words, this metric refers to similar predictions for test samples that are not seen before but similar to certain ones are. Let $s_i$ be an input sample, $\tilde{s_i}$ a sample similar to the formal</p>
<script type="math/tex; mode=display">
\tilde{s_i} = s_i + d,</script><p>where $d$ is a small distance. The corresponding distance of outputs are hence</p>
<script type="math/tex; mode=display">
\delta y_i = f(\tilde{s_i}) - f(s_i) \approx \frac{\partial f}{\partial s}(s_i)d.</script><p>Assume that $d$ is a random variable independent of $s$ with the expectation and variance as</p>
<script type="math/tex; mode=display">
\mathbb{E}[d] = O,\;\; \mathbb{C}ov[d] = \sigma^2I_{N_I},</script><p>where $I_{N_I}\in M_{N_I,N_I}$ is the identity matrix and $N_I$ the dimension of input samples.</p>
<p>Define the sensitivity $R$ to the distance $d$ as the mean ratio of the variances of $|\delta y_i|$ and $|d|$:</p>
<script type="math/tex; mode=display">
\begin{aligned}
    R(w) =&\, \sum_i \frac{\mathbb{V}ar[|\delta y_i|]}{\mathbb{V}ar[|d|]} \\
         =&\, \sum_i \frac{\mathbb{E}[|\delta y_i|^2]}{\mathbb{E}[|d|^2]} \\
         =&\, \sum_i \frac{\mathbb{E}[\delta y_i^T \delta y_i]}{\mathbb{E}[d^Td]}.
\end{aligned}</script><p>Approximate this equation with the ones above,</p>
<script type="math/tex; mode=display">
\begin{aligned}
    R(w) \approx&\, \sum_i \frac{\mathbb{E}\left[d^T\frac{\partial f(s_i)}{\partial s}^T\cdot \frac{\partial f(s_i)}{\partial s}d\right]}{\mathbb{E}[d^Td]} \\
         =&\, \sum_i \frac{\mathbb{E}\left[\text{trace}\{\frac{\partial f(s_i)}{\partial s}d\cdot d^T\frac{\partial f(s_i)}{\partial s}^T \}\right]}{\mathbb{E}\left[\text{trace}\{dd^T \} \right]} \\
         =&\, \sum_i \frac{\sigma^2\mathbb{E}\left[\text{trace}\{\frac{\partial f(s_i)}{\partial s}\cdot \frac{\partial f(s_i)}{\partial s}^T \}\right]}{\sigma^2N_I} \\
         =&\, \sum_i \frac{\mathbb{E}\left[\frac{\partial f(s_i)}{\partial s}^T\cdot \frac{\partial f(s_i)}{\partial s} \right]}{N_I} \\
         =&\, \sum_i \frac{\left\|\frac{\partial f}{\partial s}(s_i) \right\|^2}{N_I}.
\end{aligned}</script><p>To make the model less sensitive to the disturbance of input pattern, $R(w)$ is preferred to be smaller, i.e. minimize the objective</p>
<script type="math/tex; mode=display">
\mathcal{L}(w) = \sum_i \left\|y_i - f(s_i) \right\|^2 + \frac{\tau}{N_I}\left\|\frac{\partial f}{\partial s}(s_i) \right\|^2,</script><p>where $\tau\in\mathbb{R}^*_+$ controls the balance.</p>
<p>This optimization problem is not difficult, but calculating $\frac{\partial R}{\partial w}$ could be avoided via an interesting alternative. By introducing a noise</p>
<script type="math/tex; mode=display">
n\in R^{N_I},\;\; \mathbb{E}[n] = O,\;\; \mathbb{C}ov[n] = \frac{\tau}{N_I} I_{N_I},</script><p>the objective can be approximated as</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \mathcal{L}(w) =&\, \sum_i \left\|y_i - f(s_i) \right\|^2 + \mathbb{E}\left[\left\|\frac{\partial f}{\partial s}(s_i)n \right\|^2 \right] \\
                   =&\, \sum_i \mathbb{E}\left[\left\|y_i - f(s_i)  + \frac{\partial f}{\partial s}(s_i)n \right\|^2 \right] \\
                   \approx&\, \sum_i \mathbb{E}\left[\left\|y_i - f(s_i + n) \right\|^2 \right].
\end{aligned}</script><p>The variance $\frac{\tau}{N_I} I_{N_I}$ can be viewed as a parameter controlling the regularization. A large variance fits the model to be robust to the noise, leading to a good generalization capacity.</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] K. Matsuoka. 1992. Noise injection into inputs in back-propagation learning. IEEE Transactions on Systems, Man, and Cybernetics 22, 3 (1992), 436–440.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


		
    
		
			

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/Deep-Compression/Bayesian-View/Keeping-Neural-Networks-Simple-by-MDL/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="RemiC">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Remi's Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Deep-Compression/Bayesian-View/Keeping-Neural-Networks-Simple-by-MDL/" itemprop="url">Keeping Neural Networks Simple by MDL</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-07-10T18:50:00+08:00">
                2018-07-10
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-Compression/" itemprop="url" rel="index">
                    <span itemprop="name">Deep Compression</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-Compression/Bayesian-View/" itemprop="url" rel="index">
                    <span itemprop="name">Bayesian View</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>This text refers to the paper <a href="https://dl.acm.org/citation.cfm?doid=168304.168306" target="_blank" rel="noopener">Keeping Neural Networks Simple by Minimizing the Description Length of the Weights</a> published on COLT 1993, which mainly proposes a view of MDL over simplifying neural networks.</p>
<h2 id="MDL"><a href="#MDL" class="headerlink" title="MDL"></a>MDL</h2><p>When fitting data models to some data, a more complex model often performs better on training data but may be overfitting. So it is in need of methods to decide when extra complexity of the model is not worth the improvement in the data-fit. Minimum Description Length (<em>MDL</em>) Principle is proposed in [2], asserting that the best model is the one that minimizes the combined cost of decribing the model and the misfit between the model and the data. For example, in a supervised classification task, the model cost is the number of bits describing the model, and the data misfit cost is the number of bits describing the descrepency between model output and the ground truth.</p>
<blockquote>
<p>$\texttt{Note}:$ The principle could be viewed in a simple communication model as</p>
<script type="math/tex; mode=display">
input\;\; X = x</script><script type="math/tex; mode=display">
sender (W = w, Y = y)\;\;\;\; \xrightarrow{\Delta y,\, w}\;\;\;\; receiver</script></blockquote>
<h3 id="Coding"><a href="#Coding" class="headerlink" title="Coding"></a>Coding</h3><p>In order to compute communication cost, the first question is how to define the number of bits in need. For simplification, data misfit cost is discussed as an example for illustration.</p>
<p>Clearly, if the data misfits are real numbers, an inifinite amount of information is needed to convey them. Hence, a simple quantization is included so that the real numbers within a width of $t$ will be degraded to one number.</p>
<p>After quantization, the misfits $\Delta y$ are further coded into bits with length $-\log\mathbb{P}(\Delta Y=\Delta y)$. For example, let the misfit follow a Gaussian centralized:</p>
<script type="math/tex; mode=display">
\Delta Y \sim \mathcal{N}(0,\sigma^2)\;\; \iff\;\; \hat{Y}|Y \sim \mathcal{N}(y,\sigma^2).</script><p>Therefore,</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \mathbb{P}(\Delta Y = \Delta y|Y = y) =&\, \mathbb{P}(\hat{Y} = \hat{y}, \hat{y} = y + \Delta y|Y = y) \\
                                          =&\, \int_{\hat{Y}\in\mathcal{B}(\hat{y},t)} \frac{1}{\sigma\sqrt{2\pi}}\exp\left(-\frac{(\hat{Y} - y)^2}{2\sigma^2} \right)d\hat{Y} \\
                       \approx&\, \frac{t}{\sigma\sqrt{2\pi}}\exp\left(-\frac{(\hat{y} - y)^2}{2\sigma^2} \right),
\end{aligned}</script><p>where the approximation is valid if $t\ll\sigma$. Then the misfit cost (on average), i.e. the number of descrepency bits, becomes</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \mathcal{C}^D =&\, \mathbb{E}_Y\left[-\log\mathbb{P}(\Delta Y = \Delta y|Y = y) \right] \\
                  \approx&\, -\frac{1}{N}\sum_{i=1}^N \left(\log t -\frac{(\hat{y_i} - y_i)^2}{2\sigma^2} \right) + \log\sigma,
\end{aligned}</script><p>where the approximation is induced by Monte Carlo Sampling.</p>
<h2 id="Bits-Back-Argument"><a href="#Bits-Back-Argument" class="headerlink" title="Bits-Back Argument"></a>Bits-Back Argument</h2><p>The sender trains the model with data so that it learns the posterior distribution of weights, $q$. However, for sending precise weights to the receiver, the sender may need some random bits (e.g. random seeds) to collapse $q$ to a number. But note that, since the receiver receives the misfits, weights and shares the input with the sender, it is able to train the model itself, which means the receiver can know $q$ as well. In other words, the knowledge of $q$ does mainly come from $w$ once it has received misfits. Furthermore, the information given by $w$ may be rebundant, leading to unnecessary cost. Hence, for computing the necessary cost, it suffers to substract the cost of sending $w$ by the unnecessary cost.</p>
<h3 id="Weight-Cost"><a href="#Weight-Cost" class="headerlink" title="Weight Cost"></a>Weight Cost</h3><p>Different from data, when model is fixed, weights are often preferred to be certain settings. This refers to, in fact, the prior of weight, $p(w)$. In this case, the sender and the receiver will share this knowledge. Given that, the sender can send $w$ by coding according to this prior (seen the section above). Hence, the cost of sending weights will be</p>
<script type="math/tex; mode=display">
\mathcal{C}^W = -\log\left(tp(w) \right) = -\log t - \log p(w).</script><h3 id="Random-Bits"><a href="#Random-Bits" class="headerlink" title="Random Bits"></a>Random Bits</h3><p>Actually, to sample $w$ from $q$, the sender needs some random bits (e.g. random seeds). On the other hand, the receiver can know these bits by computing inversely, i.e. from $w$ and $q$ to the random bits.</p>
<blockquote>
<p>$\texttt{Note}:$ In computer literature, there is no, as so far, real but <strong>pseudo</strong> random numbers. In most case, the “random” numbers is generated by certain iterative algorithm and based on a real random number, which is often given by hand, namely random seed.</p>
<p><a href="https://en.wikipedia.org/wiki/Random_seed" target="_blank" rel="noopener">&gt;GO TO WIKI&lt;</a></p>
</blockquote>
<p>However, these random bits are not necessary, because 1) they are not features of the model; 2) they can be generated on the receiver side as well. Therfore, we can conclude that the unncessary information is exactly the random bits. Given that these bits can be restored from $q$ and $w$, the cost of sending them will be the number of bits coded according to $q$:</p>
<script type="math/tex; mode=display">
\mathcal{C}^R = -\log\left(tq(w) \right) = -\log t - \log q(w).</script><h3 id="Substraction"><a href="#Substraction" class="headerlink" title="Substraction"></a>Substraction</h3><p>Therefore, by computing the expected value, the necessary cost to describe the model is</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \mathcal{C}^M =&\, \mathbb{E}_q\left[\mathcal{C}^W - \mathcal{C}^R \right] \\
                =&\, \int q(w) \left(\log q(w) - \log p(w) \right)dw \\
                =&\, -\int q(w) \log\frac{p(w)}{q(w)}dw \\
                =&\, KL(q(w)||p(w))
\end{aligned}</script><p>This process can be compared as a special transaction between the sender and the receiver:</p>
<script type="math/tex; mode=display">
input\;\; X = x,\;\; prior\;\; p(w)</script><script type="math/tex; mode=display">
sender (W \sim q, Y = y)\;\;\;\; \xrightarrow[w\,=\,g(r,\,q)]{\Delta y}\;\;\;\; receiver</script><script type="math/tex; mode=display">
sender (W \sim q, Y = y)\;\;\;\; \xleftarrow{r}\;\;\;\; receiver(W \sim q, Y = f(w,x) + \Delta y)</script><p>where $g(.)$ is some random number generation algorithm, $r$ random bits. </p>
<blockquote>
<p>$\texttt{Note}:$ The receiver sends random bits $r$ back to the sender, because they are not necessary for description of the model. Hence, this argument is named by “<em>bits back</em>“.</p>
</blockquote>
<h2 id="With-Bayesian-Inference"><a href="#With-Bayesian-Inference" class="headerlink" title="With Bayesian Inference"></a>With Bayesian Inference</h2><p>Combine the cost of data misfits and model description, the total cost is</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \mathcal{C} =&\, \mathcal{C}^D + \mathcal{C}^M \\
                =&\, \mathbb{E}_Y\left[-\log\mathbb{P}(\Delta Y|Y) \right] + KL(q(w)||p(w)).
\end{aligned}</script><p>To minimize the misfit term, it suffers that $\Delta Y = \hat{y} - y$ happens as frequently as possible, no matter how large it is. However, since it is always expected that $\Delta Y\rightarrow 0$, the first term can be further transformed:</p>
<script type="math/tex; mode=display">
\mathbb{E}_Y\left[-\log\mathbb{P}(\Delta Y|Y) \right] \xrightarrow{\Delta Y\, \rightarrow\, 0} \mathbb{E}_Y\left[-\log\mathbb{P}(\hat{Y} = Y|W,X) \right] \equiv \mathbb{E}_Y\left[-\log\mathbb{P}(Y|W = w,X) \right].</script><p>Hence,</p>
<script type="math/tex; mode=display">
\mathcal{C} = -\left(\mathbb{E}_Y\left[\log\mathbb{P}(Y|W = w,X) \right] - KL(q(w)||p(w)) \right).</script><p>To minimize the cost, it is equivalent to maximize</p>
<script type="math/tex; mode=display">
\mathcal{L} = \mathbb{E}_Y\left[\log\mathbb{P}(Y|W = w,X) \right] - KL(q(w)||p(w)),</script><p>which is exactly the <strong>evidence lower bound</strong> of Bayesian inference.</p>
<blockquote>
<p>$\texttt{Note}:$ In most case, the first term is approximated by Monte Carlo Sampling so that</p>
<script type="math/tex; mode=display">
\mathcal{L} \approx \frac{1}{N}\sum_{i=1}^N \log\mathbb{P}(\hat{Y} = y_i|W = w,X = x_i) - KL(q(w)||p(w))</script></blockquote>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] Hinton, G. E., &amp; van Camp, D. Keeping neural networks simple by minimising the description length of weights. 1993. In Proceedings of COLT-93 (pp. 5-13).</p>
<p>[2] Rissanen, J. (1986). Stochastic complexity and modeling. The annals of statistics, 1080-1100.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


		
    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">RemiC</p>
              <p class="site-description motion-element" itemprop="description">I'm description.</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">15</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">7</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">19</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/remicongee" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">RemiC</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
  


  

  

</body>
</html>
