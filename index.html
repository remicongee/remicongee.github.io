<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="I&apos;m description.">
<meta property="og:type" content="website">
<meta property="og:title" content="Remi&#39;s Hexo">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Remi&#39;s Hexo">
<meta property="og:description" content="I&apos;m description.">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Remi&#39;s Hexo">
<meta name="twitter:description" content="I&apos;m description.">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>

<script>
    (function(){
        if(''){
            if (prompt('Password required') !== ''){
                alert('Wrong!');
                history.back();
            }
        }
    })();
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title>Remi's Hexo</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Remi's Hexo</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
		
			

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/Computer-Vision/Object-Detection/Selective-Search/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="RemiC">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Remi's Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Computer-Vision/Object-Detection/Selective-Search/" itemprop="url">Selective Search</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-12-15T22:56:36+08:00">
                2018-12-15
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Computer-Vision/" itemprop="url" rel="index">
                    <span itemprop="name">Computer Vision</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Computer-Vision/Object-Detection/" itemprop="url" rel="index">
                    <span itemprop="name">Object Detection</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>This text refers to the paper Selective Search for Object Recognition <a href="https://staff.fnwi.uva.nl/th.gevers/pub/GeversIJCV2013.pdf" target="_blank" rel="noopener">1</a>, which propose a unified framework for object recognition/detection. The most important contribution, which will be discussed here, is a diversified sampling strategy for region proposal, namely selective search. It combines the strength of both exhaustive search and segmentation and is still widely used in object detection field.</p>
<h2 id="Region-Proposal"><a href="#Region-Proposal" class="headerlink" title="Region Proposal"></a>Region Proposal</h2><p>For detecting or recognizing a certain object in an image, it includes not only classification knowledge but also geometry information, i.e. location and scale. A straight solution is thus traversing all possible locations and scales and outputting the ones classified to the object required. These locations and scales are called <em>region proposal</em>, commonly in form of rectangle with a corner, length and width defined. However, given the huge visual search space, this kind of exhaustive search becomes computationally expensive. This is why the previous studies generally adopt coarse grid search, but still blind and costly, which forces to equip weak feature extractors and classifers to make up computation complexity.</p>
<h2 id="Reviews"><a href="#Reviews" class="headerlink" title="Reviews"></a>Reviews</h2><p>Although exhaustive search is costly, it holds several advantages which should be kept:</p>
<ul>
<li>Class-independence, which ensures a unified and general framework.</li>
<li>Not leaky, which returns all location and scale possibilities.</li>
<li>…</li>
</ul>
<p>Note that the huge search space arises because the locations and scales are sampled without any visual knowledge. Segmentaion is one method to provide a coarse but reliable proposals, which enables the sampling strategy not blind any more. But a class-independent segmentation may lead to a excessively fine proposals, and thus requires a strong algorithm forming good regions.</p>
<h2 id="Selective-Search"><a href="#Selective-Search" class="headerlink" title="Selective Search"></a>Selective Search</h2><p>Selective search is a region sampling strategy which combines the strength of exhaustive seach and segmentation. It initalize with a segmentation result and form good regions based on regions’ hierarchical relationships, without class knowledge. A fine to coarse “pyramid” can be thus generated via the greedy algorithm, where on each level a set of regions are proposed. The final region proposal contains about 2000 regions, which is much less than that exhaustive search but still covers reliable locations and scales. Details are discussed below.</p>
<h3 id="Hierarchical-Grouping"><a href="#Hierarchical-Grouping" class="headerlink" title="Hierarchical Grouping"></a>Hierarchical Grouping</h3><p>The objects in visual field as images are normally included in a hierarchical relationships. For instance, on a table there may be a bowl of eggs, and recognition of the table should upstream from the eggs. From this point, the author starts from rather fine segmentation results [2], then use a greedy algorithm to iteratively group pairs of neighbouring regions together based on a similarity ranked, i.e. the most similar pair of neighbouring regions are merged for each iteration. The similarity here is computed by a function proposed by the author, which combines various standards as described below.</p>
<h3 id="Diversification-for-Similarity"><a href="#Diversification-for-Similarity" class="headerlink" title="Diversification for Similarity"></a>Diversification for Similarity</h3><p>The author propose to compute the final similarity between neghbouring regions $(r_i, r_j)$ by summing up four weighted sub-similarity functions $s_*(.,.)$:</p>
<ul>
<li>Colour</li>
</ul>
<script type="math/tex; mode=display">
s_c(r_i, r_j) = \sum_{k=1}^n \min(c_i^k, c_j^k),</script><p>where $c_i^k$ denotes the colour normalized of $r_i$ in $k$-th colour bin.</p>
<ul>
<li>Texture</li>
</ul>
<script type="math/tex; mode=display">
s_t(r_i, r_j) = \sum_{k=1}^n \min(t_i^k, t_j^k),</script><p>where $t_i^k$ denotes the texture histogram value of $r_i$ in $k$-th histogram bin.</p>
<ul>
<li>Size</li>
</ul>
<script type="math/tex; mode=display">
s_s(r_i, r_j) = 1 - \frac{size(r_i) + size(r_j)}{size(im)},</script><p>which requires the regions left to be in similar sizes and will be updated by $size(r_t)=size(r_i)+size(r_j)$.</p>
<ul>
<li>Fitness</li>
</ul>
<script type="math/tex; mode=display">
s_f(r_i, r_j) = 1 - \frac{B_{ij} - size(r_i) - size(r_j)}{size(im)},</script><p>where $B_{ij}$ is the tight bounding box containing $r_i$ and $r_j$, encouraging to merge regions with large parts touched.</p>
<p>Finally, the similarity is</p>
<script type="math/tex; mode=display">
s(r_i, r_j) = \sum_{*\in E} a_* s_*(r_i, r_j),\;\; E = \{c, t, s, f \},</script><p>where $a_*\in\{0,1 \}$ indicates whether to use the corresponding similarity.</p>
<h2 id="Combining-Locations"><a href="#Combining-Locations" class="headerlink" title="Combining Locations"></a>Combining Locations</h2><p>Once region proposals are given by the selective search, it should be noted that they are not equi-possible to be an object and those not likely tend to be removed for computation efficiency. To this end, the authot assigns for each region $r_i$ a value $v_i=\delta\cdot i$ and rank based on this all the regions, where $\delta$ is a random number to prevent over emphasize on large regions. The regions with the largest $v$ will be retained, and the others are filtered by thresholding.</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] Uijlings, J. R., Van De Sande, K. E., Gevers, T., &amp; Smeulders, A. W. (2013). Selective search for object recognition. International journal of computer vision, 104(2), 154-171.</p>
<p>[2] Felzenszwalb, P. F., &amp; Huttenlocher, D. P. (2004). Efficient graph-based image segmentation. International journal of computer vision, 59(2), 167-181.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


		
    
		
			

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/Machine-Learning/Basic-Method/On-Gradients-of-Stochastic-Neurons/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="RemiC">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Remi's Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Machine-Learning/Basic-Method/On-Gradients-of-Stochastic-Neurons/" itemprop="url">On Gradients of Stochastic Neurons</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-12-06T21:06:26+08:00">
                2018-12-06
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Machine Learning</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/Basic-Method/" itemprop="url" rel="index">
                    <span itemprop="name">Basic Method</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>This text mainly refers to the paper <a href="https://arxiv.org/abs/1308.3432" target="_blank" rel="noopener">Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation</a> [1]. Regardless of Stochastic Times Smooth (STS) units and Straight-Through Estimator (STE), the technique detail of an unbiased estimator of gradient for stochastic binary neurons is discussed in this text.</p>
<h2 id="Stochastic-Binary-Neurons"><a href="#Stochastic-Binary-Neurons" class="headerlink" title="Stochastic Binary Neurons"></a>Stochastic Binary Neurons</h2><p>Considering hard non-linearity as activation function in neural networks, the gradients are normaly incomputable, but can be estimated with the help of stochaistic pertubation, which is actually a random noise multiplied on neurons, e.g. dropout. These kind of neurons are referred as stochastic neurons in this text, and become more insteresting in binary case, i.e. the output activated of neurons is either 0 or 1, namely stochastic binary neurons. One may ask for the strategy to binarize the outputs, which is proposed to be based on a sigmoid probability. For illustration, say a fully-connected layer with input $x$, weight $W$, bias $b$ and output activated $h$, then</p>
<script type="math/tex; mode=display">
h_i = f(a_i, z_i) = \mathbb{I}_{z_i \lt \sigma(a_i)},\;\; a_i = b_i + \sum_j W_{ij}x_j,</script><p>where $z_i\sim \mathcal{U}[0,1]$ is uniform and $\sigma(u)=1/(1+\exp(-u))$ is sigmoid function.</p>
<h2 id="Unbiased-Estimator-for-Gradient"><a href="#Unbiased-Estimator-for-Gradient" class="headerlink" title="Unbiased Estimator for Gradient"></a>Unbiased Estimator for Gradient</h2><p>Let $\mathcal{L}$ be the objective function, then computing directly the gradient of $\mathcal{L}$ with regard to parameters are intractable. However, an unbiases estimator is still feasible. Note that accordint to the chain rule, i.e.</p>
<script type="math/tex; mode=display">
\frac{\partial\mathcal{L}}{\partial W_{ij}} = \frac{\partial\mathcal{L}}{\partial a_i}\cdot \frac{\partial a_i}{\partial W_{ij}},</script><p>the first term on the right is the only one in need to estimate, whose expectation is thus in need if the estimation is supposed to be unbiased. </p>
<p>Additionally, among advances of recent network designs, dropout is commonly included, which is stochastic as well as $z$. In this case, these random parameters should also be considered during the estimation for gradient. Note that this dropout noise does not require updates and is viewed as fixed once sampled when forwarding. Therefore, the expectation is conditionned on the random parameters if they influence $a$. For clarity, let $\Gamma=\{z_i\}\bigcup\ c_i\bigcup c_{-i}$ be the set of all random variables divided according to whether they influence $a_i$ as $c_i$ does. Note $\mathcal{L}=\mathcal{L}(h_i,c_i,c_{-i})$.</p>
<p>Now compute the expectation of $L$ conditioned on $c_i$,</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \mathbb{E}\left[\mathcal{L} | c_i \right] =&\, \mathbb{E}_{c_{-i}}\left[\mathbb{E}_{z_i}\left[L | c_i \right] \right] \\
                                    =&\, \mathbb{E}_{c_{-i}}\left[\mathbb{E}_{z_i}\left[h_i\mathcal{L}\left(1, c_i, c_{-i} \right) + (1 - h_i)\mathcal{L}\left(0, c_i, c_{-i} \right) \right] \right] \\
                                    =&\, \mathbb{E}_{c_{-i}}\left[\mathbb{P}\left(h_i=1 | a_i \right)\mathcal{L}\left(1, c_i, c_{-i} \right) + \mathbb{P}\left(h_i=0 | a_i \right)\mathcal{L}\left(0, c_i, c_{-i} \right) \right] \\
                                    =&\, \mathbb{E}_{c_{-i}}\left[\sigma(a_i)\mathcal{L}\left(1, c_i, c_{-i} \right) + \left(1 - \sigma(a_i) \right)\mathcal{L}\left(0, c_i, c_{-i} \right) \right].
\end{aligned}</script><p>Further derive the average gradient,</p>
<script type="math/tex; mode=display">
\begin{aligned}
    g_i = \mathbb{E}\left[\frac{\partial\mathcal{L}}{\partial a_i} | c_i \right] =&\, \frac{\partial\mathbb{E}\left[\mathcal{L} | c_i\right]}{\partial a_i} \\
                                                                     =&\, \mathbb{E}_{c_{-i}}\left[\sigma'(a_i)\mathcal{L}\left(1, c_i, c_{-i} \right) - \sigma'(a_i)\mathcal{L}\left(0, c_i, c_{-i} \right) \right] \\
                                                                     =&\, \mathbb{E}_{c_{-i}}\left[\sigma(a_i)\left(1 - \sigma(a_i) \right)\left(\mathcal{L}\left(1, c_i, c_{-i} \right) - \mathcal{L}\left(0, c_i, c_{-i} \right) \right) \right].
\end{aligned}</script><p>Now consider the estimator</p>
<script type="math/tex; mode=display">
\hat{g}_i = \left(h_i - \sigma(a_i) \right)\mathcal{L}(h_i, c_i, c_{-i}) = h_i\left(1 - \sigma(a_i) \right)\mathcal{L}(1, c_i, c_{-i}) - \sigma(a_i)(1 - h_i)\mathcal{L}(0, c_i, c_{-i}),</script><p>whose expectation is</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \mathbb{E}[\hat{g}_i | c_i] =&\, \mathbb{E}_{c_{-i}, z_i}\left[h_i\left(1 - \sigma(a_i) \right)\mathcal{L}(1, c_i, c_{-i}) - \sigma(a_i)(1 - h_i)\mathcal{L}(0, c_i, c_{-i})\right] \\
                                =&\, \mathbb{E}_{c_{-i}}\left[\sigma(a_i)\left(1 - \sigma(a_i) \right)\mathcal{L}(1, c_i, c_{-i}) - \sigma(a_i)(1 - \sigma(a_i))\mathcal{L}(0, c_i, c_{-i}) \right] \\
                                =&\, \mathbb{E}_{c_{-i}}\left[\sigma(a_i)\left(1 - \sigma(a_i) \right)\left(\mathcal{L}(1, c_i, c_{-i}) - \mathcal{L}(0, c_i, c_{-i}) \right) \right],
\end{aligned}</script><p>which is the same as that of the gradient. Thus $\hat{g}_i$ is an unbiased estimator for gradient.</p>
<h2 id="Low-Variance-Choice"><a href="#Low-Variance-Choice" class="headerlink" title="Low Variance Choice"></a>Low Variance Choice</h2><p>The very estimator is actually a special case of <a href="https://link.springer.com/article/10.1007/BF00992696" target="_blank" rel="noopener">policy gradient</a> [2] widely used in reinforcement learning. Consider the binarization as a random action sampled from $\mathcal{B}(\sigma(a_i))$, the objective $\mathcal{L}$ as reward $R$, and suppose trajectory $\tau$ to be unitary. The common choice for optimization is policy gradient method,</p>
<script type="math/tex; mode=display">
\frac{\partial\mathbb{E}_\tau[R]}{\partial a_i} = \mathbb{E}_\tau\left[R\cdot \frac{\partial \log p_{a_i}(h_i)}{\partial a_i} \right].</script><blockquote>
<p>$\texttt{Proof}:$<br>Suppose $p_{a_i}(h_i)$ is derivable on $0$ with regard to $a_i$, then</p>
<script type="math/tex; mode=display">
\frac{\partial \log p_{a_i}(h_i)}{\partial a_i} = \frac{1}{p_{a_i}(h_i)}\frac{\partial p_{a_i}(h_i)}{\partial a_i}.</script><p>After discretization, </p>
<script type="math/tex; mode=display">
\begin{aligned}
   \mathbb{E}_\tau\left[R\cdot \frac{\partial \log p_{a_i}(h_i)}{\partial a_i} \right] =&\, R_1\cdot \mathbb{P}\left(h_i=1 | a_i \right) \frac{1}{\mathbb{P}\left(h_i=1 | a_i \right)}\frac{\partial \mathbb{P}\left(h_i=1 | a_i \right)}{\partial a_i} \\
+&\, R_0\cdot \mathbb{P}\left(h_i=0 | a_i \right)\frac{1}{\mathbb{P}\left(h_i=0 | a_i \right)}\frac{\partial \mathbb{P}\left(h_i=0 | a_i \right)}{\partial a_i} \\
=&\, R_1\cdot \frac{\partial \mathbb{P}\left(h_i=1 | a_i \right)}{\partial a_i} + R_0\cdot \frac{\partial \mathbb{P}\left(h_i=0 | a_i \right)}{\partial a_i} \\
=&\, \frac{\partial}{\partial a_i}\left(R_1\cdot \mathbb{P}\left(h_i=1 | a_i \right) + R_0\cdot \mathbb{P}\left(h_i=0 | a_i \right) \right) \\
=&\, \frac{\partial\mathbb{E}_{h_i}[R]}{\partial a_i} \\
=&\, \frac{\partial\mathbb{E}_\tau[R]}{\partial a_i}.
\end{aligned}</script></blockquote>
<p>Given that, it is natural to extract $R\cdot \partial_{a_i} \log p_{a_i}(h_i)$ for gradient estimator, which in this case, is</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \mathcal{L}\cdot \frac{\partial \log \mathbb{P}(h_i | a_i)}{\partial a_i} =&\, h_i\mathcal{L}\cdot \left(1 + \exp(-a_i) \right) \frac{\exp(-a_i)}{\left(1 + \exp(-a_i) \right)^2} \\
                                                                              +&\, (1 - h_i)\mathcal{L}\cdot \left(1 + \exp(a_i) \right) \frac{-\exp(a_i)}{\left(1 + \exp(a_i) \right)^2}  \\
                                                                              =&\, h_i\mathcal{L}\cdot \left(1 - \sigma(a_i) \right) - (1 - h_i)\mathcal{L} \cdot \sigma(a_i) \\
                                                                              =&\, h_i\mathcal{L} - \sigma(a_i)\mathcal{L} - h_i\mathcal{L}\cdot \sigma(a_i) + h_i\mathcal{L}\cdot \sigma(a_i) \\
                                                                              =&\, \left(h_i - \sigma(a_i) \right)\mathcal{L},
\end{aligned}</script><p>which is exactly the estimator proposed.</p>
<p>Furthermore, in reinforcement learning, normaly a baseline is assigned for reward so that the gradient is of low variance. Similarly, this baseline is also necessary in the estimator, denoted by $\bar{\mathcal{L}}_i$. Then reformulate the estimator</p>
<script type="math/tex; mode=display">
\hat{g}_i = \left(h_i - \sigma(a_i) \right)\left(\mathcal{L} - \bar{\mathcal{L}}_i \right).</script><p>To minmize its variance, which is</p>
<script type="math/tex; mode=display">
\mathbb{V}ar\left[\hat{g}_i \right] = \mathbb{V}ar\left[\left(h_i - \sigma(a_i) \right)\mathcal{L} \right] - \Delta,</script><p>where</p>
<script type="math/tex; mode=display">
\Delta = \mathbb{E}\left[\left(h_i - \sigma(a_i) \right)^2\left(\mathcal{L}^2 - \left(\mathcal{L} - \bar{\mathcal{L}}_i\right)^2 \right) \right]</script><p>should be maximized by minimizing $\mathbb{E}\left[\left(h_i - \sigma(a_i) \right)^2\left(\mathcal{L} - \bar{\mathcal{L}}_i\right)^2 \right]$. Then by derivating with regrad to $\bar{\mathcal{L}}_i$,</p>
<script type="math/tex; mode=display">
\mathbb{E}\left[\left(h_i - \sigma(a_i) \right)^2\left(\mathcal{L} - \bar{\mathcal{L}}_i\right) \right] = 0,</script><p>thus</p>
<script type="math/tex; mode=display">
\bar{\mathcal{L}}_i = \frac{\mathbb{E}\left[\left(h_i - \sigma(a_i) \right)^2\mathcal{L} \right]}{\mathbb{E}\left[\left(h_i - \sigma(a_i) \right)^2 \right]}.</script><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] Bengio, Y., Léonard, N., &amp; Courville, A. (2013). Estimating or propagating gradients through stochastic neurons for conditional computation. arXiv preprint arXiv:1308.3432.</p>
<p>[2] Williams, R. J. (1992). Simple statistical gradient-following algorithms for connectionist reinforcement learning. Machine learning, 8(3-4), 229-256.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


		
    
		
			

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/Machine-Learning/Basic-Method/Deep-Neural-Networks-as-Gaussian-Processes/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="RemiC">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Remi's Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Machine-Learning/Basic-Method/Deep-Neural-Networks-as-Gaussian-Processes/" itemprop="url">Deep Neural Networks as Gaussian Processes</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-09-24T18:57:22+08:00">
                2018-09-24
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Machine Learning</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/Basic-Method/" itemprop="url" rel="index">
                    <span itemprop="name">Basic Method</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>This text refers to the paper <a href="https://arxiv.org/abs/1711.00165" target="_blank" rel="noopener">DEEP NEURAL NETWORKS AS GAUSSIAN PROCESSES</a> published at ICLR 2018, mainly revealing the equivalence between infinitely wide deep neural networks (NN) and Gaussian processes (GP).</p>
<h2 id="Notation"><a href="#Notation" class="headerlink" title="Notation"></a>Notation</h2><ul>
<li><p>$L$: depth of NN</p>
</li>
<li><p>$N_l$: width of layer $l$</p>
</li>
<li><p>$\phi$: activation function (nonlinearities)</p>
</li>
<li><p>$x^l_i$: $i$-th post-nonlinearity of $l$-th layer</p>
</li>
<li><p>$z^l_i$: $i$-th post-affine of $l$-th layer</p>
</li>
<li><p>$x^\alpha$: input data $\alpha$ in $\mathbb{R}^D$</p>
</li>
<li><p>$W^l_{ij}$: weight element of $l$-th layer</p>
</li>
<li><p>$b^l_i$: bias element of $l$-th layer</p>
</li>
<li><p>$\mathcal{GP}(\mu, K)$: Gaussian process with expectation $\mu(.)$ and covariance $K(.,.)$</p>
</li>
</ul>
<h2 id="GP-and-Single-layer-NN"><a href="#GP-and-Single-layer-NN" class="headerlink" title="GP and Single-layer NN"></a>GP and Single-layer NN</h2><p>As for a single-layer NN, the $i$-th output is computed as</p>
<script type="math/tex; mode=display">
z^1_i(x) = b^1_i + \sum_{j=1}^{N_1} W^1_{ij}x^1_j(x),\;\;\;\; x^1_j(x) = \phi\left(b^0_j + \sum_{k=1}^D W^0_{jk}x_k \right).</script><p>According to the Central Limit Theorem, when $N_1\rightarrow\infty$, $z^1_i(x)$ will be Gaussian distributed. Given that, $\{z^1_i(x^{\alpha=1}),…,z^1_i(x^{\alpha=k}) \}$ will have a joint multivariate Gaussian distribution, i.e. $z^1_i\sim\mathcal{GP}(\mu^1,K^1)$.</p>
<blockquote>
<p>$\texttt{Note}:$ The expectation and the covariance are independent of $i$, because <em>a priori</em> there is no knowledge that the output varies from the position of neurons. The same for $\sigma^2_b$ and $\sigma^2_w$.</p>
</blockquote>
<p>Moreover, because the expectation of parameters ($W$ and $b$) is null <em>a priori</em>, $\mu^1$ is then null as well and</p>
<script type="math/tex; mode=display">
\begin{aligned}
    K^1(x, x') =&\, \mathbb{E}\left[z^1_i(x) z^1_i(x') \right] \\
               =&\, \sigma^2_b + \sigma^2_w \mathbb{E}\left[x^1_i(x) x^1_i(x') \right] \\
               =&\, \sigma^2_b + \sigma^2_w \mathbb{C}(x, x'),
\end{aligned}</script><p>where $\mathbb{C}(x,x’)$ is an integral against $W^0$ and $b^0$, as seen in <a href="http://www.cs.toronto.edu/~radford/bnn.book.html" target="_blank" rel="noopener">Bayesian Learning for Neural Networks</a>.</p>
<h2 id="GP-and-Deep-NN"><a href="#GP-and-Deep-NN" class="headerlink" title="GP and Deep NN"></a>GP and Deep NN</h2><p>Generalize the post-nonlinearity and the post-affine in a deep NN as</p>
<script type="math/tex; mode=display">
z^l_i(x) = b^l_i + \sum_{j=1}^{N_1} W^l_{ij}x^l_j(x),\;\;\;\; x^l_j(x) = \phi\left(z^{l-1}_j(x) \right).</script><p>Similar with the single-layer case, $z^l_i\sim\mathcal{GP}(0,K^l)$, with</p>
<script type="math/tex; mode=display">
\begin{aligned}
    K^l(x, x') =&\, \mathbb{E}\left[z^l_i(x) z^l_i(x') \right] \\
               =&\, \sigma^2_b + \sigma^2_w \mathbb{E}\left[x^l_i(x) x^l_i(x') \right] \\
               =&\, \sigma^2_b + \sigma^2_w \mathbb{E}_{z^{l-1}_i\sim \mathcal{GP}(0, K^{l-1})}\left[\phi(z^{l-1}_i(x) z^{l-1}_i(x')) \right].
\end{aligned}</script><p>As the joint Gaussian distribution is described with $K^l(x,x)$, $K^l(x,x’)$ and $K^l(x’,x’)$, the covariance can be rewritten as</p>
<script type="math/tex; mode=display">
K^l(x, x') = \sigma^2_b + \sigma^2_w F_\phi \left(K^{l-1}(x, x), K^{l-1}(x, x'), K^{l-1}(x', x') \right).</script><p>For the beginning of this iterative series of GP, note $W_{ij}^0$, $b^0_j$ and $K^0$, and then</p>
<script type="math/tex; mode=display">
K^0(x, x') = \mathbb{E}\left[z^0_j(x) z^0_j(x') \right] = \sigma^2_b + \sigma^2_w \cdot \frac{\langle x, x' \rangle}{N^D}.</script><p>Therefore, the each layer (with infinity of neurons) of the deep NN is equivalent to a Gaussian Process.</p>
<h2 id="Bayesian-Training"><a href="#Bayesian-Training" class="headerlink" title="Bayesian Training"></a>Bayesian Training</h2><p>Given a dataset $\mathcal{D}=\{(x^1,t^1),…,(x^n,t^n) \}$, the model $z(.)$ is supposed to make prediction for a test sample $x^*$. In Bayesian training process, the prediction is over a distribution as</p>
<script type="math/tex; mode=display">
\begin{aligned}
    p(z^* | x^*, \mathcal{D}) =&\, \int p(z^* | x^*, z, x) p(z | \mathcal{D}) dz \\
                              =&\, \int \frac{p(z^*, z | x^*, x)}{p(z | x^*, x)} p(z | \mathcal{D}) dz \\
                              =&\, \int p(z^*, z | x^*, x)\frac{p(z | t, x)}{p(z | x)}  dz \\
                              =&\, \int p(z^*, z | x^*, x)\frac{p(z, t | x)}{p(z | x) p(t | x)}  dz \\
                              =&\, \int p(z^*, z | x^*, x)\frac{p(t | z, x)}{p(t | x)}  dz \\
                              =&\, \frac{1}{p(t)} \int p(z^*, z | x^*, x)p(t | z) dz,
\end{aligned}</script><p>where $t|z\sim\mathcal{N}(0, \sigma^2_\epsilon)$ due to a noise effect added to the prediction.</p>
<p>Since</p>
<script type="math/tex; mode=display">
z^*, z | x^*, x \sim \mathcal{GP}(0,K),</script><p>where</p>
<script type="math/tex; mode=display">
K = \left[
\begin{matrix}
    K_{\mathcal{D},\mathcal{D}} & K^T_{x^*, \mathcal{D}} \\
    K_{x^*, \mathcal{D}} & K_{x^*, x^*}
\end{matrix} \right],</script><p>the integral can be calculated analytically, resulting in </p>
<script type="math/tex; mode=display">
z* | \mathcal{D}, x^* \sim \mathcal{N}(\bar{\mu}, \bar{K}),</script><p>where</p>
<script type="math/tex; mode=display">
\bar{\mu} = K_{x^*, \mathcal{D}} \left(K_{\mathcal{D},\mathcal{D}} + \sigma^2_\epsilon \mathbb{I}_n \right)^{-1} t,</script><script type="math/tex; mode=display">
\bar{K} = K_{x^*, x^*} - K_{x^*, \mathcal{D}} \left(K_{\mathcal{D},\mathcal{D}} + \sigma^2_\epsilon \mathbb{I}_n \right)^{-1} K^T_{x^*, \mathcal{D}}.</script><p>Therefore, the prediction can be done with any decision function over $z$ <em>a posterior</em>.</p>
<blockquote>
<p>$\texttt{Note}:$ To achieve a high performance, various methods can be applied to optimize the parameters, e.g. cross-validation, gradiant ascent.</p>
</blockquote>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] Lee, J., Bahri, Y., Novak, R., Schoenholz, S. S., Pennington, J., &amp; Sohl-Dickstein, J. (2017). Deep neural networks as gaussian processes.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


		
    
		
			

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/Machine-Learning/Training-Trick/Noise-and-Tikhonov-Regularization/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="RemiC">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Remi's Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Machine-Learning/Training-Trick/Noise-and-Tikhonov-Regularization/" itemprop="url">Noise and Tikhonov Regularization</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-09-10T19:15:24+08:00">
                2018-09-10
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Machine Learning</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/Training-Trick/" itemprop="url" rel="index">
                    <span itemprop="name">Training Trick</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>This text refers to <a href="https://ieeexplore.ieee.org/document/6796505/" target="_blank" rel="noopener">Training with Noise is Equivalent to Tikhonov Regularization</a>.</p>
<h2 id="Preliminary"><a href="#Preliminary" class="headerlink" title="Preliminary"></a>Preliminary</h2><p>Consider a feed-forward neural network mapping input data $\mathbf{x}=(x_1,…,x_D)$ to output $f(\mathbf{x})=(f_1(\mathbf{x}),…,f_C(\mathbf{x}))$, associated with ground truth $\mathbf{t}=(t_1,…,t_C)$. A common choice of loss function is</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \mathcal{L} =&\, \frac{1}{2}\int\int \left\|f(\mathbf{x}) - \mathbf{t} \right\|^2 p(\mathbf{x}, \mathbf{t}) d\mathbf{x}d\mathbf{t} \\
                =&\, \frac{1}{2} \int\int \sum_{k=1}^C \left(f_k(\mathbf{x}) - t_k \right)^2 p(t_k | \mathbf{x})p(\mathbf{x})d\mathbf{x}dt_k.
\end{aligned}</script><blockquote>
<p>$\texttt{Note}:$ Especially, for a finit discrete dataset,</p>
<script type="math/tex; mode=display">
p(\mathbf{x}, \mathbf{t}) = \frac{1}{n}\sum_q (\mathbf{x} - \mathbf{x}^q)(\mathbf{t} - \mathbf{t}^q).</script><p>Then the loss function becomes</p>
<script type="math/tex; mode=display">
\mathcal{L} = \frac{1}{2n}\sum_q \left\|f(\mathbf{x}^q) - \mathbf{t}^q \right\|^2.</script></blockquote>
<h2 id="Tikhonov-Regularization"><a href="#Tikhonov-Regularization" class="headerlink" title="Tikhonov Regularization"></a>Tikhonov Regularization</h2><p>One common way to prevend model $f$ from overfitting is regularizing the original loss function as</p>
<script type="math/tex; mode=display">
\tilde{\mathcal{L}} = \mathcal{L} + \lambda \Omega(f),</script><p>where $\lambda$ is a hyper-parameter balance the bias and variance of the model. For the case of one input $x$ and one output $f(x)$, the class of Tikhonov regularizers takes the form as</p>
<script type="math/tex; mode=display">
\Omega(f) = \sum_{r=0}^R \int_a^b h_r(x) \left(\frac{d^rf}{dx^r} \right)^2 dx,</script><p>where $h_r(.)\ge 0$ for $r=0,…,R-1$ and $h_R(.)&gt;0$.</p>
<h2 id="Noise-Injection"><a href="#Noise-Injection" class="headerlink" title="Noise Injection"></a>Noise Injection</h2><p>Apart from regularized loss function, adding noise to the input data is another well-known approach. In this case, the loss function is</p>
<script type="math/tex; mode=display">
\tilde{\mathcal{L}} = \frac{1}{2}\int\int\int \sum_{k=1}^C \left(f_k(\mathbf{x} + \mathbf{n}) - t_k \right)^2 p(t_k | \mathbf{x})p(\mathbf{x})p(\mathbf{n}) d\mathbf{x}dt_kd\mathbf{n}.</script><p>Expand the model function $f$ <em>w.r.t</em> $\mathbf{n}$,</p>
<script type="math/tex; mode=display">
f_k(\mathbf{x} + \mathbf{n}) = f_k(\mathbf{x}) + \sum_{i=1}^D n_i\frac{\partial f_k}{\partial x_i} + \frac{1}{2}\sum_{i=1}^D\sum_{j=1}^D n_in_j \frac{\partial^2 f_k}{\partial{x_i}\partial{x_j}} + \mathcal{O}(\|\mathbf{n} \|^3).</script><p>The noise distribution is generally chosen to be null on average and uncorrelated between different input elements. Hence,</p>
<script type="math/tex; mode=display">
\int n_i p(\mathbf{n})d\mathbf{n} = 0,</script><script type="math/tex; mode=display">
\int n_i n_j p(\mathbf{n})d\mathbf{n} = \eta^2\delta_{ij},</script><p>where $\eta^2$ is the amplitude of the noise injected.</p>
<p>By using these two properties and assuming small noise, the loss function can be written as</p>
<script type="math/tex; mode=display">
\tilde{\mathcal{L}} = \mathcal{L} + \eta^2\mathcal{L}_r,</script><p>where</p>
<script type="math/tex; mode=display">
\mathcal{L}_r = \frac{1}{2}\int\int \sum_{k=1}^C\sum_{i=1}^D \left(\left(\frac{\partial f_k}{\partial x_i} \right)^2 + \left(f_k(\mathbf{x}) - t_k \right)\frac{\partial^2 f_k}{\partial x_i^2} \right) p(t_k | \mathbf{x})p(\mathbf{x})d\mathbf{x}dt_k.</script><blockquote>
<p>$\texttt{Note}:$ In fact,</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \tilde{\mathcal{L}} =&\, \frac{1}{2}\int \sum_{k=1}^C \left(f_k(\mathbf{x}) + \sum_{i=1}^D n_i\frac{\partial f_k}{\partial x_i} + \frac{1}{2}\sum_{i=1}^D\sum_{j=1}^D n_in_j \frac{\partial^2 f_k}{\partial{x_i}\partial{x_j}} - t_k \right)^2 p(t_k, \mathbf{x}, \mathbf{n}) d(t_k, \mathbf{x}, \mathbf{n}) \\
                        =&\, \frac{1}{2}\int \sum_{k=1}^C \left(f_k(\mathbf{x}) - t_k \right)^2 p(t_k, \mathbf{x}) d(t_k, \mathbf{x}) \\
                         &\,+ \frac{1}{2}\int \sum_{k=1}^C 2\left(f_k(\mathbf{x}) - t_k \right)\left(\sum_{i=1}^D n_i\frac{\partial f_k}{\partial x_i} + \frac{1}{2}\sum_{i=1}^D\sum_{j=1}^D n_in_j \frac{\partial^2 f_k}{\partial{x_i}\partial{x_j}} \right) p(t_k, \mathbf{x}, \mathbf{n}) d(t_k, \mathbf{x}, \mathbf{n}) \\
                         &\,+  \frac{1}{2}\int \sum_{k=1}^C \left(\sum_{i=1}^D n_i\frac{\partial f_k}{\partial x_i} + \frac{1}{2}\sum_{i=1}^D\sum_{j=1}^D n_in_j \frac{\partial^2 f_k}{\partial{x_i}\partial{x_j}} \right)^2 p(t_k, \mathbf{x}, \mathbf{n}) d(t_k, \mathbf{x}, \mathbf{n}) \\
                        =&\, \mathcal{L} \\
                         &\,+ \frac{1}{2}\int \sum_{k=1}^C \left(f_k(\mathbf{x}) - t_k \right)\sum_{i=1}^D\sum_{j=1}^D n_in_j \frac{\partial^2 f_k}{\partial{x_i}\partial{x_j}} p(t_k, \mathbf{x}, \mathbf{n}) d(t_k, \mathbf{x}, \mathbf{n}) \\
                         &\,+ \frac{1}{2}\int \sum_{k=1}^C \left(\sum_{i=1}^D n_i\frac{\partial f_k}{\partial x_i} + \frac{1}{2}\sum_{i=1}^D\sum_{j=1}^D n_in_j \frac{\partial^2 f_k}{\partial{x_i}\partial{x_j}} \right)^2 p(t_k, \mathbf{x}, \mathbf{n}) d(t_k, \mathbf{x}, \mathbf{n}) \\
                        =&\, \mathcal{L} \\
                         &\, + \frac{\eta^2}{2}\int \sum_{k=1}^C \left(f_k(\mathbf{x}) - t_k \right)\sum_{i=1}^D \frac{\partial^2 f_k}{\partial{x_i}\partial{x_j}} p(t_k, \mathbf{x}) d(t_k, \mathbf{x}) \\
                         &\, + \frac{\eta^2}{2} \int \sum_{k=1}^C \sum_{i=1}^D \left(\frac{\partial f_k}{\partial x_i} \right)^2 p(t_k, \mathbf{x}) d(t_k, \mathbf{x}) + \mathcal{O}(\|n\|^3) \\
                        =&\, \mathcal{L} + \eta^2\mathcal{L}_r,
\end{aligned}</script></blockquote>
<h2 id="Equivalence"><a href="#Equivalence" class="headerlink" title="Equivalence"></a>Equivalence</h2><p>To simplify the expressions, define</p>
<script type="math/tex; mode=display">
\langle t_k | \mathbf{x} \rangle = \int t_k p(t_k | \mathbf{x}) dt_k,</script><script type="math/tex; mode=display">
\langle t_k^2 | \mathbf{x} \rangle = \int t_k^2 p(t_k | \mathbf{x}) dt_k.</script><p>Then the original loss can be rewritten as</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \mathcal{L} =&\, \frac{1}{2}\sum_{k=1}^C\int \left(f_k(\mathbf{x}) - \langle t_k | \mathbf{x} \rangle \right)^2 p(\mathbf{x}) d\mathbf{x} \\
                 &\,+ \frac{1}{2}\sum_{k=1}^C\int \langle t_k^2 | \mathbf{x} \rangle - \langle t_k | \mathbf{x} \rangle^2 p(\mathbf{x}) d(\mathbf{x}).
\end{aligned}</script><p>The minimum is reached when $f_k(\mathbf{x})=\langle t_k | \mathbf{x} \rangle$. Therefore, the optimal for the total loss will have the form as</p>
<script type="math/tex; mode=display">
f^*_k(\mathbf{x}) = \langle t_k | \mathbf{x} \rangle + \mathcal{O}(\eta^2).</script><p>Note that the regularization term becomes</p>
<script type="math/tex; mode=display">
\mathcal{L}_r = \frac{1}{2}\int\sum_{k=1}^C\sum_{i=1}^D \left(\left(\frac{\partial f_k}{\partial x_i} \right)^2 + \left(f_k(\mathbf{x}) - \langle t_k | \mathbf{x} \rangle \right)\frac{\partial^2 f_k}{\partial x_i^2} \right)p(\mathbf{x})d\mathbf{x},</script><p>where the second term vanishes to the order of $\eta^2$. Given that the noise is small, indicating small $\eta^2$, the second term can be removed. Then the regularization term becomes</p>
<script type="math/tex; mode=display">
\mathcal{L}_r = \frac{1}{2}\int\sum_{k=1}^C\sum_{i=1}^D \left(\frac{\partial f_k}{\partial x_i} \right)^2 p(\mathbf{x})d\mathbf{x}.</script><blockquote>
<p>$\texttt{Note}:$ For the discrete dataset, the regularization can be written as</p>
<script type="math/tex; mode=display">
\mathcal{L}_r = \frac{1}{2}\sum_q\sum_{k=1}^C\sum_{i=1}^D \left(\frac{\partial f_k}{\partial x_i^q} \right)^2.</script></blockquote>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] Bishop, C. M. (1995). Training with noise is equivalent to tikhonov regularization. Neural Computation, 7(1), 108-116.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


		
    
		
			

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/Machine-Learning/Training-Trick/Use-of-Noise-in-Training/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="RemiC">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Remi's Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Machine-Learning/Training-Trick/Use-of-Noise-in-Training/" itemprop="url">Use of Noise in Training</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-08-07T15:50:41+08:00">
                2018-08-07
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Machine Learning</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/Training-Trick/" itemprop="url" rel="index">
                    <span itemprop="name">Training Trick</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>This text refers to the paper <a href="https://ieeexplore.ieee.org/document/155944/" target="_blank" rel="noopener">Noise injection into inputs in back-propagation learning</a>, mainly discussing about the use of noise in training networks.</p>
<h2 id="Noise-Sensitivity"><a href="#Noise-Sensitivity" class="headerlink" title="Noise Sensitivity"></a>Noise Sensitivity</h2><p>In literature of machine learning, generalization capacity is among the most important metrics. In short words, this metric refers to similar predictions for test samples that are not seen before but similar to certain ones are. Let $s_i$ be an input sample, $\tilde{s_i}$ a sample similar to the formal</p>
<script type="math/tex; mode=display">
\tilde{s_i} = s_i + d,</script><p>where $d$ is a small distance. The corresponding distance of outputs are hence</p>
<script type="math/tex; mode=display">
\delta y_i = f(\tilde{s_i}) - f(s_i) \approx \frac{\partial f}{\partial s}(s_i)d.</script><p>Assume that $d$ is a random variable independent of $s$ with the expectation and variance as</p>
<script type="math/tex; mode=display">
\mathbb{E}[d] = O,\;\; \mathbb{C}ov[d] = \sigma^2I_{N_I},</script><p>where $I_{N_I}\in M_{N_I,N_I}$ is the identity matrix and $N_I$ the dimension of input samples.</p>
<p>Define the sensitivity $R$ to the distance $d$ as the mean ratio of the variances of $|\delta y_i|$ and $|d|$:</p>
<script type="math/tex; mode=display">
\begin{aligned}
    R(w) =&\, \sum_i \frac{\mathbb{V}ar[|\delta y_i|]}{\mathbb{V}ar[|d|]} \\
         =&\, \sum_i \frac{\mathbb{E}[|\delta y_i|^2]}{\mathbb{E}[|d|^2]} \\
         =&\, \sum_i \frac{\mathbb{E}[\delta y_i^T \delta y_i]}{\mathbb{E}[d^Td]}.
\end{aligned}</script><p>Approximate this equation with the ones above,</p>
<script type="math/tex; mode=display">
\begin{aligned}
    R(w) \approx&\, \sum_i \frac{\mathbb{E}\left[d^T\frac{\partial f(s_i)}{\partial s}^T\cdot \frac{\partial f(s_i)}{\partial s}d\right]}{\mathbb{E}[d^Td]} \\
         =&\, \sum_i \frac{\mathbb{E}\left[\text{trace}\{\frac{\partial f(s_i)}{\partial s}d\cdot d^T\frac{\partial f(s_i)}{\partial s}^T \}\right]}{\mathbb{E}\left[\text{trace}\{dd^T \} \right]} \\
         =&\, \sum_i \frac{\sigma^2\mathbb{E}\left[\text{trace}\{\frac{\partial f(s_i)}{\partial s}\cdot \frac{\partial f(s_i)}{\partial s}^T \}\right]}{\sigma^2N_I} \\
         =&\, \sum_i \frac{\mathbb{E}\left[\frac{\partial f(s_i)}{\partial s}^T\cdot \frac{\partial f(s_i)}{\partial s} \right]}{N_I} \\
         =&\, \sum_i \frac{\left\|\frac{\partial f}{\partial s}(s_i) \right\|^2}{N_I}.
\end{aligned}</script><p>To make the model less sensitive to the disturbance of input pattern, $R(w)$ is preferred to be smaller, i.e. minimize the objective</p>
<script type="math/tex; mode=display">
\mathcal{L}(w) = \sum_i \left\|y_i - f(s_i) \right\|^2 + \frac{\tau}{N_I}\left\|\frac{\partial f}{\partial s}(s_i) \right\|^2,</script><p>where $\tau\in\mathbb{R}^*_+$ controls the balance.</p>
<p>This optimization problem is not difficult, but calculating $\frac{\partial R}{\partial w}$ could be avoided via an interesting alternative. By introducing a noise</p>
<script type="math/tex; mode=display">
n\in R^{N_I},\;\; \mathbb{E}[n] = O,\;\; \mathbb{C}ov[n] = \frac{\tau}{N_I} I_{N_I},</script><p>the objective can be approximated as</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \mathcal{L}(w) =&\, \sum_i \left\|y_i - f(s_i) \right\|^2 + \mathbb{E}\left[\left\|\frac{\partial f}{\partial s}(s_i)n \right\|^2 \right] \\
                   =&\, \sum_i \mathbb{E}\left[\left\|y_i - f(s_i)  + \frac{\partial f}{\partial s}(s_i)n \right\|^2 \right] \\
                   \approx&\, \sum_i \mathbb{E}\left[\left\|y_i - f(s_i + n) \right\|^2 \right].
\end{aligned}</script><p>The variance $\frac{\tau}{N_I} I_{N_I}$ can be viewed as a parameter controlling the regularization. A large variance fits the model to be robust to the noise, leading to a good generalization capacity.</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] K. Matsuoka. 1992. Noise injection into inputs in back-propagation learning. IEEE Transactions on Systems, Man, and Cybernetics 22, 3 (1992), 436–440.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


		
    
		
			

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/Deep-Compression/Bayesian-View/Keeping-Neural-Networks-Simple-by-MDL/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="RemiC">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Remi's Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Deep-Compression/Bayesian-View/Keeping-Neural-Networks-Simple-by-MDL/" itemprop="url">Keeping Neural Networks Simple by MDL</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-07-10T18:50:00+08:00">
                2018-07-10
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-Compression/" itemprop="url" rel="index">
                    <span itemprop="name">Deep Compression</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-Compression/Bayesian-View/" itemprop="url" rel="index">
                    <span itemprop="name">Bayesian View</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>This text refers to the paper <a href="https://dl.acm.org/citation.cfm?doid=168304.168306" target="_blank" rel="noopener">Keeping Neural Networks Simple by Minimizing the Description Length of the Weights</a> published on COLT 1993, which mainly proposes a view of MDL over simplifying neural networks.</p>
<h2 id="MDL"><a href="#MDL" class="headerlink" title="MDL"></a>MDL</h2><p>When fitting data models to some data, a more complex model often performs better on training data but may be overfitting. So it is in need of methods to decide when extra complexity of the model is not worth the improvement in the data-fit. Minimum Description Length (<em>MDL</em>) Principle is proposed in [2], asserting that the best model is the one that minimizes the combined cost of decribing the model and the misfit between the model and the data. For example, in a supervised classification task, the model cost is the number of bits describing the model, and the data misfit cost is the number of bits describing the descrepency between model output and the ground truth.</p>
<blockquote>
<p>$\texttt{Note}:$ The principle could be viewed in a simple communication model as</p>
<script type="math/tex; mode=display">
input\;\; X = x</script><script type="math/tex; mode=display">
sender (W = w, Y = y)\;\;\;\; \xrightarrow{\Delta y,\, w}\;\;\;\; receiver</script></blockquote>
<h3 id="Coding"><a href="#Coding" class="headerlink" title="Coding"></a>Coding</h3><p>In order to compute communication cost, the first question is how to define the number of bits in need. For simplification, data misfit cost is discussed as an example for illustration.</p>
<p>Clearly, if the data misfits are real numbers, an inifinite amount of information is needed to convey them. Hence, a simple quantization is included so that the real numbers within a width of $t$ will be degraded to one number.</p>
<p>After quantization, the misfits $\Delta y$ are further coded into bits with length $-\log\mathbb{P}(\Delta Y=\Delta y)$. For example, let the misfit follow a Gaussian centralized:</p>
<script type="math/tex; mode=display">
\Delta Y \sim \mathcal{N}(0,\sigma^2)\;\; \iff\;\; \hat{Y}|Y \sim \mathcal{N}(y,\sigma^2).</script><p>Therefore,</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \mathbb{P}(\Delta Y = \Delta y|Y = y) =&\, \mathbb{P}(\hat{Y} = \hat{y}, \hat{y} = y + \Delta y|Y = y) \\
                                          =&\, \int_{\hat{Y}\in\mathcal{B}(\hat{y},t)} \frac{1}{\sigma\sqrt{2\pi}}\exp\left(-\frac{(\hat{Y} - y)^2}{2\sigma^2} \right)d\hat{Y} \\
                       \approx&\, \frac{t}{\sigma\sqrt{2\pi}}\exp\left(-\frac{(\hat{y} - y)^2}{2\sigma^2} \right),
\end{aligned}</script><p>where the approximation is valid if $t\ll\sigma$. Then the misfit cost (on average), i.e. the number of descrepency bits, becomes</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \mathcal{C}^D =&\, \mathbb{E}_Y\left[-\log\mathbb{P}(\Delta Y = \Delta y|Y = y) \right] \\
                  \approx&\, -\frac{1}{N}\sum_{i=1}^N \left(\log t -\frac{(\hat{y_i} - y_i)^2}{2\sigma^2} \right) + \log\sigma,
\end{aligned}</script><p>where the approximation is induced by Monte Carlo Sampling.</p>
<h2 id="Bits-Back-Argument"><a href="#Bits-Back-Argument" class="headerlink" title="Bits-Back Argument"></a>Bits-Back Argument</h2><p>The sender trains the model with data so that it learns the posterior distribution of weights, $q$. However, for sending precise weights to the receiver, the sender may need some random bits (e.g. random seeds) to collapse $q$ to a number. But note that, since the receiver receives the misfits, weights and shares the input with the sender, it is able to train the model itself, which means the receiver can know $q$ as well. In other words, the knowledge of $q$ does mainly come from $w$ once it has received misfits. Furthermore, the information given by $w$ may be rebundant, leading to unnecessary cost. Hence, for computing the necessary cost, it suffers to substract the cost of sending $w$ by the unnecessary cost.</p>
<h3 id="Weight-Cost"><a href="#Weight-Cost" class="headerlink" title="Weight Cost"></a>Weight Cost</h3><p>Different from data, when model is fixed, weights are often preferred to be certain settings. This refers to, in fact, the prior of weight, $p(w)$. In this case, the sender and the receiver will share this knowledge. Given that, the sender can send $w$ by coding according to this prior (seen the section above). Hence, the cost of sending weights will be</p>
<script type="math/tex; mode=display">
\mathcal{C}^W = -\log\left(tp(w) \right) = -\log t - \log p(w).</script><h3 id="Random-Bits"><a href="#Random-Bits" class="headerlink" title="Random Bits"></a>Random Bits</h3><p>Actually, to sample $w$ from $q$, the sender needs some random bits (e.g. random seeds). On the other hand, the receiver can know these bits by computing inversely, i.e. from $w$ and $q$ to the random bits.</p>
<blockquote>
<p>$\texttt{Note}:$ In computer literature, there is no, as so far, real but <strong>pseudo</strong> random numbers. In most case, the “random” numbers is generated by certain iterative algorithm and based on a real random number, which is often given by hand, namely random seed.</p>
<p><a href="https://en.wikipedia.org/wiki/Random_seed" target="_blank" rel="noopener">&gt;GO TO WIKI&lt;</a></p>
</blockquote>
<p>However, these random bits are not necessary, because 1) they are not features of the model; 2) they can be generated on the receiver side as well. Therfore, we can conclude that the unncessary information is exactly the random bits. Given that these bits can be restored from $q$ and $w$, the cost of sending them will be the number of bits coded according to $q$:</p>
<script type="math/tex; mode=display">
\mathcal{C}^R = -\log\left(tq(w) \right) = -\log t - \log q(w).</script><h3 id="Substraction"><a href="#Substraction" class="headerlink" title="Substraction"></a>Substraction</h3><p>Therefore, by computing the expected value, the necessary cost to describe the model is</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \mathcal{C}^M =&\, \mathbb{E}_q\left[\mathcal{C}^W - \mathcal{C}^R \right] \\
                =&\, \int q(w) \left(\log q(w) - \log p(w) \right)dw \\
                =&\, -\int q(w) \log\frac{p(w)}{q(w)}dw \\
                =&\, KL(q(w)||p(w))
\end{aligned}</script><p>This process can be compared as a special transaction between the sender and the receiver:</p>
<script type="math/tex; mode=display">
input\;\; X = x,\;\; prior\;\; p(w)</script><script type="math/tex; mode=display">
sender (W \sim q, Y = y)\;\;\;\; \xrightarrow[w\,=\,g(r,\,q)]{\Delta y}\;\;\;\; receiver</script><script type="math/tex; mode=display">
sender (W \sim q, Y = y)\;\;\;\; \xleftarrow{r}\;\;\;\; receiver(W \sim q, Y = f(w,x) + \Delta y)</script><p>where $g(.)$ is some random number generation algorithm, $r$ random bits. </p>
<blockquote>
<p>$\texttt{Note}:$ The receiver sends random bits $r$ back to the sender, because they are not necessary for description of the model. Hence, this argument is named by “<em>bits back</em>“.</p>
</blockquote>
<h2 id="With-Bayesian-Inference"><a href="#With-Bayesian-Inference" class="headerlink" title="With Bayesian Inference"></a>With Bayesian Inference</h2><p>Combine the cost of data misfits and model description, the total cost is</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \mathcal{C} =&\, \mathcal{C}^D + \mathcal{C}^M \\
                =&\, \mathbb{E}_Y\left[-\log\mathbb{P}(\Delta Y|Y) \right] + KL(q(w)||p(w)).
\end{aligned}</script><p>To minimize the misfit term, it suffers that $\Delta Y = \hat{y} - y$ happens as frequently as possible, no matter how large it is. However, since it is always expected that $\Delta Y\rightarrow 0$, the first term can be further transformed:</p>
<script type="math/tex; mode=display">
\mathbb{E}_Y\left[-\log\mathbb{P}(\Delta Y|Y) \right] \xrightarrow{\Delta Y\, \rightarrow\, 0} \mathbb{E}_Y\left[-\log\mathbb{P}(\hat{Y} = Y|W,X) \right] \equiv \mathbb{E}_Y\left[-\log\mathbb{P}(Y|W = w,X) \right].</script><p>Hence,</p>
<script type="math/tex; mode=display">
\mathcal{C} = -\left(\mathbb{E}_Y\left[\log\mathbb{P}(Y|W = w,X) \right] - KL(q(w)||p(w)) \right).</script><p>To minimize the cost, it is equivalent to maximize</p>
<script type="math/tex; mode=display">
\mathcal{L} = \mathbb{E}_Y\left[\log\mathbb{P}(Y|W = w,X) \right] - KL(q(w)||p(w)),</script><p>which is exactly the <strong>evidence lower bound</strong> of Bayesian inference.</p>
<blockquote>
<p>$\texttt{Note}:$ In most case, the first term is approximated by Monte Carlo Sampling so that</p>
<script type="math/tex; mode=display">
\mathcal{L} \approx \frac{1}{N}\sum_{i=1}^N \log\mathbb{P}(\hat{Y} = y_i|W = w,X = x_i) - KL(q(w)||p(w))</script></blockquote>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] Hinton, G. E., &amp; van Camp, D. Keeping neural networks simple by minimising the description length of weights. 1993. In Proceedings of COLT-93 (pp. 5-13).</p>
<p>[2] Rissanen, J. (1986). Stochastic complexity and modeling. The annals of statistics, 1080-1100.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


		
    
		
			

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/Deep-Compression/Bayesian-View/Structured-Bayesian-Pruning-via-Log-Normal-Multiplicative-Noise/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="RemiC">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Remi's Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Deep-Compression/Bayesian-View/Structured-Bayesian-Pruning-via-Log-Normal-Multiplicative-Noise/" itemprop="url">Structured Bayesian Pruning via Log-Normal Multiplicative Noise</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-07-05T13:51:22+08:00">
                2018-07-05
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-Compression/" itemprop="url" rel="index">
                    <span itemprop="name">Deep Compression</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-Compression/Bayesian-View/" itemprop="url" rel="index">
                    <span itemprop="name">Bayesian View</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>This text refers to the paper <a href="https://arxiv.org/abs/1705.07283" target="_blank" rel="noopener">Structured Bayesian Pruning via Log-Normal Multiplicative Noise</a> published on NIPS 2017. The main novel point is utilizing <em>Log-Normal</em> distribution.</p>
<h2 id="Log-Normal-Multiplicative-Noise"><a href="#Log-Normal-Multiplicative-Noise" class="headerlink" title="Log-Normal Multiplicative Noise"></a>Log-Normal Multiplicative Noise</h2><p>Say, for a dropout layer, input $x$ and output $y$ are in $R^I$. To introduce noise, each element of $x$ is multiplied a <strong>POSITIVE</strong> noise:</p>
<script type="math/tex; mode=display">
y_i = x_i\cdot \theta_i\;\;\;\;\theta\sim p(\theta).</script><p>In order that sparsity is group-wise, $\theta$ is shared in group.</p>
<p>To do Bayesian inference for $\theta$, the improper log-uniform distribution is adopted as prior $p(\theta)$ in fully-fractorized way</p>
<script type="math/tex; mode=display">
p(\theta) = \prod_{i=1}^Ip(\theta_i) \;\;\;\; p(\theta_i) = LogU_\infty(\theta_i)\propto \frac{1}{\theta_i}</script><p>As for the variational posterior, </p>
<script type="math/tex; mode=display">
q_\phi(\theta)=\prod_{i=1}^I LogN(\theta_i|\mu_i,\sigma^2_i),</script><p>where</p>
<script type="math/tex; mode=display">
\theta_i \sim LogN(\theta_i|\mu_i,\sigma^2_i)\;\;\iff\;\; \log\theta_i \sim \mathcal{N}(\mu_i,\sigma^2_i).</script><p>The log-normal distribution is chosen for these reason:</p>
<ul>
<li>The log-uniform distribution is a specific case of the log-normal one. In fact,</li>
</ul>
<script type="math/tex; mode=display">
    q_\phi(\log\theta_i) = \frac{1}{\sigma\sqrt{2\pi}}\exp\left(-\frac{|\theta_i - \mu_i|^2}{2\sigma^2} \right)
                         \xrightarrow{\sigma\rightarrow+\infty} \frac{1}{\sigma\sqrt{2\pi}}
                         \propto \frac{1}{\sqrt{2\pi}}</script><ul>
<li>In the logarithmic space, the commonly used Gaussian posterior is asymetric and has different supports from log-uniform distribution.</li>
</ul>
<blockquote>
<p>$\texttt{Note}:$ Given that $\theta$ is defined positive at the beginning, there is no reason to discuss symetry while comparing log-uniform and Gaussian.</p>
</blockquote>
<ul>
<li><p>Log-normal noise is always non-negative, while Gaussian one is not. During training with the latter, the sign of output non-activated is arbitary, while during testing, it is always non-negative, because the noise equals $1$ and the input activated by most popular non-linearities (e.g. ReLU, Sigmoid, Softplus) is non-negative. This inconsistency can not be justified even though Gaussian dropout works well in some work.</p>
</li>
<li><p>$KL(LogN(\theta|\mu,\sigma^2)||LogU_{\infty}(\theta))$ is computable analytically.</p>
</li>
</ul>
<blockquote>
<p>$\texttt{Note}:$ $KL(LogN(\theta|\mu,\sigma^2)||LogU_{\infty}(\theta))=C-\log\sigma$, where $C=+\infty$.</p>
<script type="math/tex; mode=display">
\begin{aligned}
      KL(LogN(\theta|\mu,\sigma^2)||LogU_{\infty}(\theta)) =&\, -\int LogN(\theta|\mu,\sigma^2)\log\frac{LogU_{\infty}(\theta)}{LogN(\theta)}d\theta \\
=&\, -\int LogN(\theta|\mu,\sigma^2)\log\frac{1}{C\theta}d\theta - \mathcal{H}(LogN(\theta|\mu,\sigma^2)) \\
=&\, \log C + \int \frac{1}{\theta\sigma\sqrt{2\pi}}\exp\left(-\frac{(\log\theta-\mu)^2}{2\sigma^2} \right)\log\theta d\theta - \frac{1}{2} - \frac{1}{2}\log(2\pi\sigma^2) - \mu \\
=&\, C' + \int \exp(-u)\frac{1}{\sigma\sqrt{2\pi}}\exp\left(-\frac{(u-\mu)^2}{2\sigma^2} \right)u\exp(u)du - \log\sigma \\
=&\, C'' - \log\sigma,
\end{aligned}</script><p>where $C’’=\log C - \frac{1}{2}\left(1+\log(2\pi)\right)-\mu$. <br><br>This term is not infinity if and only if </p>
<script type="math/tex; mode=display">
\log\sigma = \mathcal{O}(\log C),</script><p>which means $\sigma\rightarrow+\infty$.</p>
</blockquote>
<p>Given the above $\texttt{Note}$, the lower bound is ill-posed. In fact, the lower bound</p>
<script type="math/tex; mode=display">
\mathcal{L} = \mathcal{L}^D(\mu,\sigma,w) - KL(q_\phi(\theta)||p(\theta))</script><p>tends to $-\infty$ hence can not be maximized, unless $\sigma\rightarrow+\infty$. However, this case indicates the degeneration of the posterior to the prior, which means the distribution trained is ignorant of all the information from the training set. Apparently, it is totally null. The reason for that is because the log-uniform is improper (non-normalized) and any probabilistic model will be then flawed.</p>
<h2 id="Truncated-Approximation"><a href="#Truncated-Approximation" class="headerlink" title="Truncated Approximation"></a>Truncated Approximation</h2><p>Consider the precision of <em>floating-point</em>, the smallest positive number is $1.2\times10^{-38}$. Therefore, complete mass of log-uniform is useless. To construct a practicable prior, a truncted approximation is proposed</p>
<script type="math/tex; mode=display">
LogU_{[a,b]}(\theta)\propto LogU_\infty(\theta)\cdot \mathbb{I}_{[a,b]}(\log\theta)</script><script type="math/tex; mode=display">
LogN_{[a,b]}(\theta|\mu,\sigma^2)\propto LogN(\theta|\mu,\sigma^2)\cdot \mathbb{I}_{[a,b]}(\log\theta)</script><p>The new KL term will be</p>
<script type="math/tex; mode=display">
KL(q_\phi(\theta)||p(\theta)) = \log\frac{b-a}{\sqrt{2\pi e\sigma^2}} - \log\left(\Phi(\beta - \Phi(\alpha)) \right) - \frac{\alpha\phi(\alpha) - \beta\phi(beta)}{2\left(\Phi(\beta) - \Phi(\alpha) \right)},</script><p>where $\phi(.)$ and $\Phi(.)$ are the density and CDF of standard Gaussian distribution, $\alpha=\frac{a-\mu}{\sigma}$ and $\beta=\frac{b-\mu}{\sigma}$.</p>
<blockquote>
<p>$\texttt{Note}:$ As for KL term with $\theta\in \left[e^a,e^b\right]$, in fact</p>
<script type="math/tex; mode=display">
\begin{aligned}
      KL(q_\phi(\theta)||p(\theta)) =&\, -\int q_\phi(\theta)\log\frac{p(\theta)}{q_\phi(\theta)}d\theta \\
                                             =&\, -\int e^uq_\phi(e^u)\log\frac{p(e^u)e^u}{q_\phi(e^u)e^u}du \;\;\;\; \left(u = \log\theta \right) \\
                                             =&\, -\int q_\phi(u)\log\frac{p(u)}{q_\phi(u)}du \\
                                             =&\, KL(q_\phi(u)||p(u)),
\end{aligned}</script><p>where $q_\phi(u)=\mathcal{tN}(u|\mu_u,\sigma^2_u,a,b)$ and $p(u)=\mathcal{U}(u|a,b)$.<br>Furthermore,</p>
<script type="math/tex; mode=display">
\begin{aligned}
    KL(q_\phi(u)||p(u)) =&\, -\int \mathcal{tN}(u|\mu_u,\sigma^2_u,a,b)\log\frac{\mathcal{U}(u|a,b)}{\mathcal{tN}(u|\mu_u,\sigma^2_u,a,b)}du \\
                                  =&\, -\int \mathcal{tN}(u|\mu_u,\sigma^2_u,a,b)\left(-\log(b-a) - \log\left(\mathcal{tN}(u|\mu_u,\sigma^2_u,a,b) \right) \right)du \\
                                  =&\, \int \mathcal{tN}(u|\mu_u,\sigma^2_u,a,b)\log(b-a)du - \mathcal{H}(\mathcal{tN}(u|\mu_u,\sigma^2_u,a,b)) \\
                                  =&\, \log(b-a) - \mathcal{H}(\mathcal{tN}(u|\mu_u,\sigma^2_u,a,b)).
\end{aligned}</script><p>Consider the entropy term,</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \mathcal{H}(\mathcal{tN}(u|\mu_u,\sigma^2_u,a,b)) =&\, -\int \mathcal{tN}(u|\mu_u,\sigma^2_u,a,b)\log(\mathcal{tN}(u|\mu_u,\sigma^2_u,a,b))du \\
                                                      =&\, \log(\sqrt{2\pi}\sigma Z) + \frac{\alpha\phi(\alpha) - \beta\phi(\beta)}{2Z}
\end{aligned}</script><p>where $\alpha=\frac{a-\mu}{\sigma}$, $\beta=\frac{b-\mu}{\sigma}$ and $Z=\Phi(\beta)-\Phi(\alpha)$.</p>
<p><a href="https://en.wikipedia.org/wiki/Truncated_normal_distribution" target="_blank" rel="noopener">&gt;GO TO WIKI&lt;</a></p>
</blockquote>
<h2 id="Thresholding"><a href="#Thresholding" class="headerlink" title="Thresholding"></a>Thresholding</h2><p>Different from Gaussian noise $\mathcal{N}(1,\alpha)$, log-normal noise does not have parameters like dropout rate $\alpha$, which could be used while thresholding for weight pruning. However, another quantity, Signal-to-Noise Ratio (<em>SNR</em>) is also usable:</p>
<script type="math/tex; mode=display">
\begin{aligned}
    SNR =&\, \frac{\mathbb{E}[\theta]}{\sqrt{\mathbb{V}ar[\theta]}} \\
        =&\, \frac{\left(\Phi(\sigma - \alpha) - \Phi(\sigma-\beta) \right) / \sqrt{\Phi(\beta - \Phi(\alpha))}}{\sqrt{\exp(\sigma^2) \left(\Phi(2\sigma - \alpha) - \Phi(2\sigma - \beta) \right) - \left(\Phi(\sigma - \alpha) - \Phi(\sigma - \beta) \right)^2}}.
\end{aligned}</script><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] Neklyudov, K., Molchanov, D., Ashukha, A., &amp; Vetrov, D. P. (2017). Structured bayesian pruning via log-normal multiplicative noise. In Advances in Neural Information Processing Systems (pp. 6775-6784).</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


		
    
		
			

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/Deep-Compression/Bayesian-View/Variational-Dropout/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="RemiC">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Remi's Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Deep-Compression/Bayesian-View/Variational-Dropout/" itemprop="url">Variational Dropout</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-06-30T18:50:36+08:00">
                2018-06-30
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-Compression/" itemprop="url" rel="index">
                    <span itemprop="name">Deep Compression</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-Compression/Bayesian-View/" itemprop="url" rel="index">
                    <span itemprop="name">Bayesian View</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>This text is mainly about dropout as a variational method, referring to the paper <a href="https://nlp.stanford.edu/pubs/sidaw13fast.pdf" target="_blank" rel="noopener">Fast Dropout Training</a>, <a href="https://arxiv.org/abs/1506.02557" target="_blank" rel="noopener">Variational Dropout and the Local Reparameterization Trick</a> and <a href="https://arxiv.org/abs/1701.05369" target="_blank" rel="noopener">Variational Dropout Sparsifies Deep Neural Networks</a>.</p>
<p>Say a fully-connected layer with input $A\in M_{K,L}$ and output inactivated $B\in M_{K,N}$, the dropout can be expressed as</p>
<script type="math/tex; mode=display">
B = (A \circ\xi)W,</script><p>where $\circ$ is Hadamard product, $\xi_{ij}\sim p(\xi_{ij})$ is a noise and $W\in M_{L,N}$ is weight matrix. Through this way, $W$ is less likely to overfit to the training data. Commonly, $p(\xi_{ij})$ includes a parameter named as <em>dropout rate</em>.</p>
<blockquote>
<p>$\texttt{Question}:$ Is this conclusion also valid for <em>CNN</em> kernels ?</p>
</blockquote>
<h2 id="Gaussian-Dropout"><a href="#Gaussian-Dropout" class="headerlink" title="Gaussian Dropout"></a>Gaussian Dropout</h2><p>Gaussian dropout refers to a Gaussian noise, $\xi\sim\mathcal{N}(1,\alpha)$ added to the training data. Compared with a binary dropout $\xi\sim\mathcal{B}(p)$, $\alpha=p/(1-p)$. Intuitionally, if $\alpha$ is large, the noise tends to be sampled uniformly from $\mathbb{R}$, which means even when the input feature is discriminant, the correspondant neuron performs the same as the Signal-Noise-Ratio (SNR) is null. Therefore, the larger $\alpha$ gets, the more possible the neuron gets dropped.</p>
<p>From the view of mathmatics, Gaussian dropout is an approximation (or limit) of binary dropout. Let $x$ be input, $z\sim\mathcal{B}(p)$ the dropout noise, $w$ the weights. Say it is a classification task and modeled by logistic regression</p>
<script type="math/tex; mode=display">
\mathbb{P}(y|x,w,z) = \sigma(w^TD_zx),</script><p>where $\sigma(.)$ is sigmoid function, $D_z$ a matrix diagonalized by $z$. It could be further written as $\sum_i^m w_iz_ix_i$. At training stage, weights are updated, though often in batches, as $x$ is fixed. In this case, the only random variable is $z$. According to Lyapunov central limit theorem,</p>
<script type="math/tex; mode=display">
\sum_i^m w_iz_ix_i\xrightarrow[m\rightarrow+\infty]{d}S\sim\mathcal{N}(\mu_S,\sigma^2_S),</script><p>where</p>
<script type="math/tex; mode=display">
\mu_S=(1-p)\sum_i^mw_ix_i,\;\sigma^2_S=p(1-p)\sum_i^mw^2_ix^2_i.</script><blockquote>
<p>$\texttt{Theorem}:$ <strong>Lyapunov Central Limit Theorem</strong> <br><br>Suppose $\{X_1,X_2,…,X_n\}$ is a sequence of independent variables, each with finite expected value $\mu_i$ and variance $\sigma^2_i$. Define</p>
<script type="math/tex; mode=display">
s^2_n = \sum_{i=1}^n\sigma^2_i.</script><p>If for some $\delta&gt;0$, <em>Lyapunov’s condition</em></p>
<script type="math/tex; mode=display">
\lim_{n\rightarrow+\infty}\frac{1}{s^{2+\delta}_n}\sum_{i=1}^n\mathbb{E}\left[|X_i - \mu_i|^{2+\delta} \right] = 0</script><p>is satisfied, then a sum of $\frac{X_i-\mu_i}{s_n}$ converges to a standard Gaussian random variable, as $n$ goes to infinity:</p>
<script type="math/tex; mode=display">
\frac{1}{s_n}\sum_{i=1}^n\left(X_i - \mu_i \right)\xrightarrow{d}\mathcal{N}(0,1).</script><p><a href="https://en.wikipedia.org/wiki/Central_limit_theorem" target="_blank" rel="noopener">&gt; GO TO WIKI &lt;</a></p>
</blockquote>
<p>For each training sample, the objective is maximizing the probability of predicting correctly. Therefore,</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \mathbb{E}_z[\log\mathbb{P}(y|\sum_i^mw_iz_ix_i)] \approx\,& \mathbb{E}_S[\log\mathbb{P}(y|S)] \\
    =\,& \mathbb{E}_{v:v_i\sim\mathcal{N}(\mu_i,\mu_i^2\alpha)}[\log\mathbb{P}(y|v^Tx)].
\end{aligned}</script><p>In fact, the equivalence is valid because $S$ can be reformed as a linear combination of Gaussian variables which are independent:</p>
<script type="math/tex; mode=display">
S = \sum_i^m x_iv_i.</script><blockquote>
<p>$\texttt{Note}:$ To justify the equivalence is valid, the combination and $S$ should have the same expectation and variance:</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \mathbb{E}\left[\sum_i^m x_iv_i\right] =& \sum_i^mx_i\mathbb{E}[v_i] \\
                                =& \sum_i^mx_i\mu_i.
\end{aligned}</script><p>Hence, it is necessary that $\mu_i=(1-p)w$.</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \mathbb{V}ar\left[\sum_i^m x_iv_i\right] =& \sum_i^mx^2_i\mathbb{V}ar\left[v_i \right] \\
                                             =& \sum_i^mx^2_i\sigma^2_i.
\end{aligned}</script><p>Hence, it is necessary that $\sigma^2_i=p(1-p)w^2$.</p>
<p>Given $\mu_i=(1-p)w$, then $\sigma^2_i=\mu_i^2\alpha$, with $\alpha=p/(1-p)$.</p>
</blockquote>
<p>The optimization can be therefore interpreted as inference of $v\sim\mathcal{N}(\mu_i,\mu_i^2\alpha)$ indexed by $\mu_i$ instead of $w$. In terms of variational inference, propose $q_\phi(v_i)=\mathcal{N}(v|\mu_i,\mu_i^2\alpha)$ as the variational posterior and $p(v)$ as prior, the evidence lower bound is hence</p>
<script type="math/tex; mode=display">
\mathcal{L}(\phi) = \mathbb{E}_{q_\phi}\left[\log\mathbb{P}(y|v^Tx) \right] - KL(q_\phi(v)||p(v)).</script><p>The first term can be approximated by unbiased Monte Carlo sampling as $\mathcal{L}^{SGVB}$ mentioned in [1]. The second term is regularization. It can be noted that when $\alpha$ is fixed, variational dropout should degrade to Gaussian dropout, which means the KL term is expected to be independent of $\mu_i$. This property is justified as long as the noise is sampled independently for each element of inputs.</p>
<p>In [1] and [2], another form of dropout is proposed. The noise is sampled for each weight parameter, instead of element of inputs. The obejective of this change is to retain the dependency among weights, which are ignored in the paper referred to in this text [3]. In this case, the improper log-uniform prior is the only choice satisfying the property mentioned above.</p>
<blockquote>
<p>$\texttt{Note}:$ In [1], it is supposed that $v=z\mu$ and $z\sim\mathcal{N}(1,\alpha)$, then the KL term becomes</p>
<script type="math/tex; mode=display">
\begin{aligned}
    KL\left(q_\phi(v)||p(v) \right) =&\, -\int \frac{1}{|\mu|\sqrt{2\pi\alpha}}\exp\left(-\frac{|v - \mu|^2}{2\alpha\mu^2} \right) \log\frac{p(v)}{\frac{1}{|\mu|\sqrt{2\pi\alpha}}\exp\left(-\frac{|v - \mu|^2}{2\alpha\mu^2} \right)}dv \\
                                    =&\, -\int \frac{1}{\sqrt{2\pi\alpha}}\exp\left(-\frac{|z - 1|^2}{2\alpha} \right) \log\frac{p(z\mu)}{\frac{1}{|\mu|\sqrt{2\pi\alpha}}\exp\left(-\frac{|z - 1|^2}{2\alpha} \right)}dz,
\end{aligned}</script><p>where $dv=|\mu|dz$.<br>Hence, it is necessary that $p(z\mu)\propto\frac{1}{|\mu|}$ so that KL term is independent of $\mu$. Therefore,</p>
<script type="math/tex; mode=display">
p(z) \propto \frac{1}{|z|}.</script></blockquote>
<p>However, KL term from the variational posterior to the prior is still intractable. Therfore, different approximations are given in [1] and [2]. And [2] proposed a form of approximation that is more robust for a larger scale of $\alpha$.</p>
<blockquote>
<p>$\texttt{Question}:$ According to <a href="https://arxiv.org/abs/1711.02989" target="_blank" rel="noopener">Variational Gaussian Dropout is not Bayesian</a>, variational Gaussian dropout is pseudo Bayesian inference.</p>
</blockquote>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] Kingma, D. P., Salimans, T., &amp; Welling, M. (2015). Variational dropout and the local reparameterization trick. In Advances in Neural Information Processing Systems (pp. 2575-2583).</p>
<p>[2] Molchanov, D., Ashukha, A., &amp; Vetrov, D. (2017). Variational dropout sparsifies deep neural networks. arXiv preprint arXiv:1701.05369.</p>
<p>[3] Wang, S., &amp; Manning, C. (2013, February). Fast dropout training. In international conference on machine learning (pp. 118-126).</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


		
    
		
			

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/Deep-Compression/Bayesian-View/Bayesian-Compression-for-Deep-Learning/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="RemiC">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Remi's Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Deep-Compression/Bayesian-View/Bayesian-Compression-for-Deep-Learning/" itemprop="url">Bayesian Compression for Deep Learning</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-06-28T20:46:23+08:00">
                2018-06-28
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-Compression/" itemprop="url" rel="index">
                    <span itemprop="name">Deep Compression</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-Compression/Bayesian-View/" itemprop="url" rel="index">
                    <span itemprop="name">Bayesian View</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>This text refers to the papar <a href="https://arxiv.org/abs/1705.08665" target="_blank" rel="noopener"><strong>Bayesian Compression for Deep Learning</strong></a> published on NIPS 2017. The main two novel points are</p>
<ul>
<li>hierarchical priors</li>
<li>encode weights via optimal fixed point precision</li>
</ul>
<h2 id="Hierarchical-Priors"><a href="#Hierarchical-Priors" class="headerlink" title="Hierarchical Priors"></a>Hierarchical Priors</h2><p>As mentioned in <a href="Deep-Compression/Bayesian-View/Principles-and-Possible-Methods">Principles and Possible Methods</a>, the evidence lower bound is commonly like</p>
<script type="math/tex; mode=display">
\mathcal{L}(\phi) = \mathbb{E}_{q_\phi}[\log\mathbb{P}(y|x,w)] - KL(q_\phi(w)||p(w)).</script><p>However, suppose weights $w$ is parameterized by $z$ as</p>
<script type="math/tex; mode=display">
z \sim p(z) \;\;\;\; w \sim \mathcal{N}(0,z^2),</script><p>then the lower bound can be re-constructed by approximate joint posterior $q_\phi(w,z)$.</p>
<blockquote>
<p>$\texttt{Note}:$ By applying mean-field theory, $q_\phi(w,z)=q_\phi(w)\cdot q_\phi(z)$, which is not included in this text.</p>
</blockquote>
<p>In this case, $z$ also becomes a paramater to infer. Then reform the evidence lower bound as</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \mathcal{L}(\phi) =& \mathbb{E}_{q_\phi(z,w)}[\log\mathbb{P}(y|x,w)] - KL(q_\phi(z,w)||p(z,w)) \\
                      =& \mathbb{E}_{q_\phi(z)q_\phi(w|z)}[\log\mathbb{P}(y|x,w)] + \int q_\phi(z,w)\log\frac{p(z,w)}{q_\phi(z,w)}d(z,w) \\
                      =& \mathbb{E}_{q_\phi(z)q_\phi(w|z)}[\log\mathbb{P}(y|x,w)] - \mathbb{E}_{q_\phi(z)}[KL(q_\phi(w|z)||p(w|z))] - KL(q_\phi(z)||p(z)).
\end{aligned}</script><p>In fact, the integration term in the second step could be further deducted as</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \int q_\phi(z,w)\log\frac{p(z,w)}{q_\phi(z,w)}d(z,w) =& \int q_\phi(w|z)q_\phi(z)\log\frac{p(w|z)p(z)}{q_\phi(w|z)q_\phi(z)}d(z,w) \\
          =& \int q_\phi(w|z) q_\phi(z)\left(\log\frac{p(w|z)}{q_\phi(w|z)} + \log\frac{p(z)}{q_\phi(z)}\right)dwdz \\
          =& \int q_\phi(z)\int q_\phi(w|z)\log\frac{p(w|z)}{q_\phi(w|z)}dwdz \\
           &+ \int q_\phi(w|z)\int q_\phi(z)\log\frac{p(z)}{q_\phi(z)}dzdw \\
          =& -\mathbb{E}_{q_\phi(z)}[KL(q_\phi(w|z)||p(w|z))] - \mathbb{E}_{q_\phi(w|z)}[KL(q_\phi(z)||p(z))] \\
          =& -\mathbb{E}_{q_\phi(z)}[KL(q_\phi(w|z)||p(w|z))] - KL(q_\phi(z)||p(z)).
\end{aligned}</script><p>It includes two KL-divergence terms. The former one concerns posterior of $w$ knowing $z$, while the latter one concerns prior of $z$. Furthermore, the former one is actually the prior of $w$ in the common case. In conclusion, after infering the prior of $z$, it seems possible to infer the “prior” of $w$, which is why this method is named after “<em>hierarchical</em>“.</p>
<p>In order to introduce sparsity to the model, several kinds of priors (of $z$) could be preferred.</p>
<h3 id="Log-uniform-Prior"><a href="#Log-uniform-Prior" class="headerlink" title="Log-uniform Prior"></a>Log-uniform Prior</h3><p>Improper log-uniform prior is in form as $p(z)\propto |z|^{-1}$. This prior is utilized in order that the KL-divergence from the posterior to the prior does not depend on the parameters to be optimized.</p>
<blockquote>
<p>$\texttt{Note}:$ In the posterior to be approximated, $w|z\sim \mathcal{N}(0,z^2)$. Hence, $p(w,z)\propto \frac{1}{|z|}\mathcal{N}(0,z^2)$.</p>
</blockquote>
<p>In the approximate posterior, $(z,w)$ follows a mixed Gaussian distribution as</p>
<script type="math/tex; mode=display">
\begin{aligned}
    z \sim &\, \mathcal{N}(\mu_z,\mu_z^2\alpha) \\
    w|z \sim &\, \mathcal{N}(z\mu,z^2\sigma^2),
\end{aligned}</script><p>where it is implicitly supposed $w=z\varepsilon$ with $\varepsilon\sim\mathcal{N}(\mu,\sigma^2)$ and $z\sim\mu_z\mathcal{N}(1,\alpha)$ with $\alpha$ interpreted as <em>dropout rate</em>. Eventually, the posterior is</p>
<script type="math/tex; mode=display">
q_\phi(z,w) = \mathcal{N}(\mu_z,\mu_z^2\alpha)\cdot \mathcal{N}(z\mu,z^2\sigma^2).</script><blockquote>
<p>$\texttt{Note}:$ The variance of $w$ indicates if it could be pruned. In fact,</p>
<script type="math/tex; mode=display">
   \begin{aligned}
          \mathbb{V}ar_{q_\phi}[w] =& \mathbb{V}ar_{q_\phi}[z\varepsilon] \\    
                                   =& \left(\mathbb{V}ar_{q_\phi}[z] + \mathbb{E}_{q_\phi}^2[z] \right)\left(\mathbb{V}ar[\varepsilon] + \mathbb{E}^2[\varepsilon] \right) - \mathbb{E}_{q_\phi}^2[z]\mathbb{E}^2[\varepsilon] \\
                                   =& \left(\mu_z^2\alpha + \mu_z^2 \right)\left(\sigma^2 + \mu^2 \right) - \mu_z^2\mu^2 \\
                                   =& \mu_z^2\left(\sigma^2 + \mu^2 \right)\alpha + \mu_z^2\sigma^2 \\
                                     \propto&\,\alpha,
   \end{aligned}</script><p>which means when $\sigma^2$ is fixed, the larger the variance is, the more unnecessary $w$ is.<br>$\texttt{Question}:$ What if the variance is large due to $\sigma^2$ ?</p>
</blockquote>
<p>Therefore, it is legal to further simplify $\mathcal{L}$:</p>
<ul>
<li>$KL(q_\phi(w|z)||p(w|z))$ is independent of $z$. In fact,</li>
</ul>
<script type="math/tex; mode=display">
\begin{aligned}
    KL(q_\phi(w|z)||p(w|z)) =& -\int \frac{1}{|z\sigma|\sqrt{2\pi}}\exp\left(-\frac{|w-z\mu |^2}{2z^2\sigma^2} \right)\log\frac{\frac{1}{|z|\sqrt{2\pi}}\exp\left(-\frac{|w |^2}{2z^2} \right)}{\frac{1}{|z\sigma|\sqrt{2\pi}}\exp\left(-\frac{|w-z\mu |^2}{2z^2\sigma^2} \right)}dw \\
                                     =& -\int \frac{1}{|z\sigma|\sqrt{2\pi}}\exp\left(-\frac{|w-z\mu |^2}{2z^2\sigma^2} \right)\cdot \left(\frac{|w-z\mu |^2}{2z^2\sigma^2}-\frac{|w |^2}{2z^2} + \log\sigma \right)dw \\
                                     =& -\frac{1}{2z^2\sigma^2}\left(\mathbb{V}ar[\mathcal{N}(z\mu,z^2\sigma^2)] - 2z\mu\mathbb{E}[\mathcal{N}(z\mu,z^2\sigma^2)] + z^2\mu^2 \right) \\
                                      &+ \frac{1}{2z^2}\mathbb{V}ar[\mathcal{N}(z\mu,z^2\sigma^2)] - \log\sigma \\
                                     =& \frac{1}{2}\left(\log\frac{1}{\sigma^2} - \frac{z^2\sigma^2-2z^2\mu^2+z^2\mu^2}{z^2\sigma^2} + \frac{z^2\sigma^2}{z^2} \right) \\
                                     =& \frac{1}{2}\left(\log\frac{1}{\sigma^2} - 1 + \frac{\mu^2}{\sigma^2} + \sigma^2  \right)
\end{aligned}</script><blockquote>
<p>$\texttt{Note}:$ This independence is still valid even though $w|z$ follows <em>a prior</em> a non-centered law.</p>
</blockquote>
<ul>
<li>$-KL(q_\phi(z)||p(z))=k_1\sigma(k_2+k_3\log\alpha)-0.5m(-\log\alpha)-k_1$. In fact,</li>
</ul>
<script type="math/tex; mode=display">
\begin{aligned}
    -KL(q_\phi(z)||p(z)) =& \int q_\phi(z)\log\frac{p(z)}{q_\phi(z)}dz \\
                                  =& \int \frac{1}{\mu_z\sqrt{2\pi\alpha}}\exp\left(-\frac{|z-\mu_z|^2}{2\mu_z^2\alpha} \right)\log\frac{\frac{C}{|z|}+K}{\frac{1}{\mu_z\sqrt{2\pi\alpha}}\exp\left(-\frac{|z-\mu_z|^2}{2\mu_z^2\alpha} \right)}dz \\
                                  \approx& k_1\sigma(k_2+k_3\log\alpha) - 0.5m(-\log\alpha) + C', 
\end{aligned}</script><p>where $\sigma(x)=(1+\exp(-x))^{-1}$ and $m(x)=\log(1+\exp(x))$. Additionally, it is assumed that when $\alpha$ tends to inifinity, which means the corresponding $w$ should be dropouted, $KL(q_\phi(z)||p(z))$ should be close to zero because the log-uniform prior also indicates the preference of null $w$. Given that, a feasible choice for $C’$ is $-k_1$, which makes the KL-divergence tend to be zero when $\alpha$ tends to infinity.</p>
<blockquote>
<p>$\texttt{Note}:$ Since $p(z)\propto \frac{1}{|z|}$, it is possible to recover the distribution of $w$:</p>
<script type="math/tex; mode=display">
p(w) \propto \int \frac{1}{|z|}\cdot \frac{1}{|z|\sqrt{2\pi}}\exp\left(-\frac{|w|^2}{2z^2} \right)dz = \frac{1}{|w|}.</script><p>It follows, therefore, the log-uniform law as well, which means a small $w$ is preferred.</p>
</blockquote>
<p>Another interesting point is how to assign a dropout rate to a group of weights (neurons or <em>CNN</em> kernels). Say, for exemple, an MLP of two hidden layers $A$ and $B$. One choice is to let a group of neurons share one $z$ so that the posterior and the approximate one can be written as</p>
<script type="math/tex; mode=display">
    p(z,w) \propto\, \prod_i^A\frac{1}{|z_i|}\prod_{i,j}^{A,B}\mathcal{N}(w_{ij}|0,z_i^2)</script><script type="math/tex; mode=display">
    q_\phi(z,w) = \prod_i^A\mathcal{N}(z_i|\mu_{z_i},\mu_{z_i}^2\alpha_i)\prod_{i,j}^{A,B}\mathcal{N}(w_{ij}|z_i\mu_{ij},z_i^2\sigma_{ij}^2)</script><p>The whole training process can be summarized as</p>
<blockquote>
<p><strong>Input</strong>: $X$<br><strong>Output</strong>: $W$<br><strong>Init</strong>: $\phi = \{\mu,\mu_z,\alpha,\sigma^2\}$<br><strong>For</strong> epoch:<br>&nbsp;&nbsp;&nbsp;&nbsp;<strong>For</strong> $x$ <strong>in</strong> $X$:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Sample $z=\mu_z \mathcal{N}(1,\alpha)$<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Sample $y= xz\mathcal{N}(\mu,\sigma^2)$<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Update $\phi$ by gradient of $\mathcal{L}$<br>Dropout the group with $\alpha$ larger than certain threshold</p>
</blockquote>
<h3 id="Half-Cauchy-Prior"><a href="#Half-Cauchy-Prior" class="headerlink" title="Half-Cauchy Prior"></a>Half-Cauchy Prior</h3><p>Proper half-Cauchy Prior is is form as $\mathcal{C}^+(0,s)=2(s\pi(1+(z/s)^2))^{-1}$, which induces a horseshoe prior. The hierarchy is expressed as</p>
<script type="math/tex; mode=display">
s\sim \mathcal{C}^+(0,\tau_0),\;\; \tilde{z}_i\sim\mathcal{C}^+(0,1),\;\; \tilde{w}_{ij}\sim\mathcal{N}(0,1),\;\; w_{ij}=\tilde{w}_{ij}\tilde{z}_is.</script><p>The rest is similar to the section above. Details can be referred in the paper.</p>
<h2 id="Weights-Encoding"><a href="#Weights-Encoding" class="headerlink" title="Weights Encoding"></a>Weights Encoding</h2><p>// TODO</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] Kingma, D. P., Salimans, T., &amp; Welling, M. (2015). Variational dropout and the local reparameterization trick. In Advances in Neural Information Processing Systems (pp. 2575-2583).</p>
<p>[2] Louizos, C., Ullrich, K., &amp; Welling, M. (2017). Bayesian compression for deep learning. In Advances in Neural Information Processing Systems (pp. 3290-3300).</p>
<p>[3] Molchanov, D., Ashukha, A., &amp; Vetrov, D. (2017). Variational dropout sparsifies deep neural networks. arXiv preprint arXiv:1701.05369.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


		
    
		
			

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/Deep-Compression/Bayesian-View/Principles-and-Possible-Methods/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="RemiC">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Remi's Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Deep-Compression/Bayesian-View/Principles-and-Possible-Methods/" itemprop="url">Principles and Possible Methods</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-06-27T13:54:31+08:00">
                2018-06-27
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-Compression/" itemprop="url" rel="index">
                    <span itemprop="name">Deep Compression</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-Compression/Bayesian-View/" itemprop="url" rel="index">
                    <span itemprop="name">Bayesian View</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>This text is mainly about principles of certain Baysian-based deep compression methods, references of whom are given at the bottom.</p>
<h2 id="Target"><a href="#Target" class="headerlink" title="Target"></a>Target</h2><p>Given a deep neural network structure $S$ and a dataset $D$ specific for certain tasks, the parameters $w$ of the network is determined by network structure and dataset. The general training target is seeking for parameters fitting well the very task, or more precisely, the posterior probability of $w$ knowing $S$ and $D$, denoted as $\mathbb{P}(w|S,D)$. Mathematically, the posterior is accessible via </p>
<script type="math/tex; mode=display">
\begin{aligned}
    \mathbb{P}(w|S,D) =& \frac{\mathbb{P}(w,S,D)}{\mathbb{P}(S,D)} \\
                      =& \frac{\mathbb{P}(w,S,D)}{\int\mathbb{P}(w,S,D)dw}.
\end{aligned}</script><p>However, the closed form of the integration term is intractable in practice. Hence, the target problem is commonly trasferred to the one seeking for an approximative solution parameterized as</p>
<script type="math/tex; mode=display">
q_\phi(w) \approx p(w|S,D).</script><blockquote>
<p>$\texttt{Note}:$ $w$ is considered as a real random variable with a continuous probability density function, denoted as $p$.<br>The Baysian’s Rule will be hence extended to be</p>
<script type="math/tex; mode=display">
p(w|S,D) = \frac{\mathbb{P}(S,D|w)\cdot p(w)}{\mathbb{P}(S,D)}.</script><p><a href="https://en.wikipedia.org/wiki/Bayes%27_theorem" target="_blank" rel="noopener">&gt;GO TO WIKI&lt;</a></p>
</blockquote>
<p>Adopted as a metric, KL-divergence is often viewed as the objective to minimize</p>
<script type="math/tex; mode=display">
KL(q_\phi(w)||p(w|S,D)) = -\int q_\phi(w)\log\frac{p(w|S,D)}{q_\phi(w)}dw.</script><p>Suppose $\{x,y\}\in D$ specific for a classification task. Then regardless of $S$, the target KL-divergence can be further deducted:</p>
<script type="math/tex; mode=display">
\begin{aligned}
    KL(q_\phi(w)||p(w|S,D)) =& -\int q_\phi(w)\log\mathbb{P}(y|x,w)dw + KL(q_\phi(w)||p(w)) + \log\mathbb{P}(y|x) \\
                                     =& -\mathcal{L}(q_\phi(w),p(w|D)) + \log\mathbb{P}(y|x),
\end{aligned}</script><p>where </p>
<script type="math/tex; mode=display">
\mathcal{L}(q_\phi(w),p(w|D)) = \mathbb{E}_{q_\phi}[\log\mathbb{P}(y|x,w)] - KL(q_\phi(w)||p(w)).</script><p>The first term, denoted as $\mathcal{L}^D(w)$, indicates how well $w$ fits the task. The second term, denoted as $R(w)$, indicates how well $w$ coordinates with its prior distribution, which is commonly viewed as regularization.</p>
<blockquote>
<p>$\texttt{Note}:$ $L^1$ penalty refers to Laplacian distribution as the prior of $w$, whereas $L^2$ refers to Gaussian ditribution.</p>
</blockquote>
<p>Given that $\log\mathbb{P}(y|x)$ is fixed, the original target (minimize KL-divergence) is equivalent to maximizing $\mathcal{L}$, which is referred as evidence lower bound in Bayesian literature.</p>
<h2 id="Gradient-based-Methods"><a href="#Gradient-based-Methods" class="headerlink" title="Gradient-based Methods"></a>Gradient-based Methods</h2><p>Thanks to promising computation capacity of CPU/GPU, gradient-based methods are widely preferred in deep learning problem. In this case, gradient-based methods is also feasible, while facing three main problems: differentiability, bias and variance.</p>
<h3 id="Differentiability"><a href="#Differentiability" class="headerlink" title="Differentiability"></a>Differentiability</h3><p>The partial gradient $\frac{\partial\mathcal{L}}{\partial q_\phi}$ is intractable unless $w$ is differentiable with regard to $\phi$. (Here, it is assumed that $\mathcal{L}$ is differentiable with regard to $w$.) The most common way to enssure this property is assigning</p>
<script type="math/tex; mode=display">
\begin{aligned}
    w =& \mu + \sqrt{\phi}\cdot\varepsilon \\
    \varepsilon \sim& \mathcal{N}(0,1).
\end{aligned}</script><h3 id="Bias"><a href="#Bias" class="headerlink" title="Bias"></a>Bias</h3><p>In general deep learning case, dataset is divided into relatively small batches during training process. It is also feasible if $\mathcal{L}$ has an unbiased estimation. One solution could be</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \mathcal{L} \approx \hat{\mathcal{L}} =& \frac{N}{M}\sum_{m=1}^M \mathcal{L}(q_\phi(w),p(w|x_m,y_m)) \\
                                           =& \frac{N}{M}\sum_{m=1}^M \mathcal{L}_m.
\end{aligned}</script><h3 id="Variance"><a href="#Variance" class="headerlink" title="Variance"></a>Variance</h3><p>The optimization could not converge if the variance of $\hat{\mathcal{L}}$ is too large, which can be reformulated as</p>
<script type="math/tex; mode=display">
\mathbb{V}ar[{\hat{\mathcal{L}}}] = N^2\left(\frac{1}{M}\mathbb{V}ar[\hat{\mathcal{L}}_m] + \frac{M-1}{M}\mathbb{C}ov[\hat{\mathcal{L}}_m, \hat{\mathcal{L}}_n] \right),</script><p>where the second term does not degrade to zero if the covariance is large enough. Therefore, applying local reparameterization trick is preferred here. The main idea is, in each update iteration, resampling $w$ independently according to $q_\phi$, leading to $i.i.d.$ samples.</p>
<h2 id="Compression"><a href="#Compression" class="headerlink" title="Compression"></a>Compression</h2><p>As long as a good approximation $q_\phi(w)$ is reached, it is possible to prune certain parameters or neurons if their posteriors tend to be negligible. There are several interesting ways as discussed below.</p>
<h3 id="Prior"><a href="#Prior" class="headerlink" title="Prior"></a>Prior</h3><ul>
<li>LASSO</li>
<li>log-uniform</li>
<li>spike-and-slab</li>
<li>half-cauchy</li>
</ul>
<h3 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h3><ul>
<li>Gaussian dropout</li>
<li>As a Bayesian approximation</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] Kingma, D. P., Salimans, T., &amp; Welling, M. (2015). Variational dropout and the local reparameterization trick. In Advances in Neural Information Processing Systems (pp. 2575-2583).</p>
<p>[2] Louizos, C., Ullrich, K., &amp; Welling, M. (2017). Bayesian compression for deep learning. In Advances in Neural Information Processing Systems (pp. 3290-3300).</p>
<p>[3] Gal, Y., &amp; Ghahramani, Z. (2016, June). Dropout as a Bayesian approximation: Representing model uncertainty in deep learning. In international conference on machine learning (pp. 1050-1059).</p>
<p>[4] Achterhold, J., Koehler, J. M., Schmeink, A., &amp; Genewein, T. (2018). Variational Network Quantization. In International Conference on Learning Representations.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


		
    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">RemiC</p>
              <p class="site-description motion-element" itemprop="description">I'm description.</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">11</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">7</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">16</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/remicongee" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">RemiC</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
  


  

  

</body>
</html>
