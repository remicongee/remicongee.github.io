<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="I&apos;m description.">
<meta property="og:type" content="website">
<meta property="og:title" content="Remi&#39;s Hexo">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Remi&#39;s Hexo">
<meta property="og:description" content="I&apos;m description.">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Remi&#39;s Hexo">
<meta name="twitter:description" content="I&apos;m description.">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>

<script>
    (function(){
        if(''){
            if (prompt('Password required') !== ''){
                alert('Wrong!');
                history.back();
            }
        }
    })();
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title>Remi's Hexo</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Remi's Hexo</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
		
			

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/Machine-Learning/Training-Trick/Gaussian-Process-Regression/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="RemiC">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Remi's Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Machine-Learning/Training-Trick/Gaussian-Process-Regression/" itemprop="url">Gaussian Process Regression</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-12-31T22:41:13+08:00">
                2018-12-31
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Machine Learning</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/Training-Trick/" itemprop="url" rel="index">
                    <span itemprop="name">Training Trick</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>This text refers to the Gaussian process regression (GPR), a method predicting the posterior distribution of functions.</p>
<h2 id="View-on-Probability"><a href="#View-on-Probability" class="headerlink" title="View on Probability"></a>View on Probability</h2><p>Say for a regression task, note $D=\{x_i,y_i\}$ the training set of size $N$, $f(.)$ the function to fit, $x^*$ a test point. Knowing the training set $D$, a distribution of $f(.)$ on $x^*$ is supposed to be solved or approached, which can be written as</p>
<script type="math/tex; mode=display">
p(y^* | x^*, D) = \frac{p\left((x^*,y^*), D \right)}{p(x^*, D)},</script><p>where $y^*=f(x^*)$. Note that $\left(x_1,…,x_N,x^*\right)$ is not random variable, hence the density can be further simplified as</p>
<script type="math/tex; mode=display">
p(y^* | x^*, D) = \frac{p(y^*, y_1,..., y_N)}{p(y_1,...,y_N)}.</script><p>The density $p(y^*, y_1,…, y_N)$ indicates a <em>prior</em> joint distribution, as well as $p(y_1,…,y_N)$. Given that, to predict $y^*$, it is necessary to first determinate these distributions.</p>
<h2 id="Gaussian-Process"><a href="#Gaussian-Process" class="headerlink" title="Gaussian Process"></a>Gaussian Process</h2><p>Following the idea of the previous section, the <em>prior</em> joint distributions are supposed to be normal in GPR, hence form Gaussian process (GP):</p>
<script type="math/tex; mode=display">
y_1,..., y_N \sim \mathcal{GP}\left(\overrightarrow{0}, \Sigma\right),</script><p>where $\Sigma_{ij}=k(y_i,y_j)$ is covariance matrix. When concerning $y^*$, a new covariance matrix can be defined as</p>
<script type="math/tex; mode=display">
\left(
\begin{matrix}
    \Sigma & k_* \\
    k_*^T & k_{**}
\end{matrix}
\right),</script><p>where $k_*$ is the covariance of the test point and training set and $k_{**}$ the variance.</p>
<blockquote>
<p>$\texttt{Note}:$ The distribution is proposed <em>a priori</em>, and since no more knowlegde is acquired other than the points, it is reasonable to suppose that the expectation is null.</p>
</blockquote>
<p>The problem left is how to compute the covariance $k(.,.)$, where it should be noted that $\Sigma$ must be positive definite. One choice is Mercer kernel, which is declared in <a href="https://en.wikipedia.org/wiki/Mercer%27s_theorem" target="_blank" rel="noopener">Mercer Theorem</a> and referred as kernel function in SVM. For instance, by adopting the squared exponential kernel, the covariance can be computed as</p>
<script type="math/tex; mode=display">
k(y_i, y_j) = \exp\left(-\lambda \|x_i - x_j \|^2 \right),</script><p>which indicates a kind of similarity between $y_i$ and $y_j$ (or $x_i$ and $x_j$).</p>
<h2 id="Regression"><a href="#Regression" class="headerlink" title="Regression"></a>Regression</h2><p>Now determinate the <em>posterior</em> distribution of $y^*$ via the GP defined above:</p>
<script type="math/tex; mode=display">
y^* | x^*, D \sim \mathcal{N}(\mu^*, \sigma^*),</script><p>where</p>
<script type="math/tex; mode=display">
\mu^* = k_*^T\Sigma^{-1}\overrightarrow{y},\;\;\sigma^* = -k_*^T\Sigma^{-1}k_* + k_{**},</script><p>with $\overrightarrow{y}=\left(y_1,…,y_N\right)^T$.</p>
<p>In this case, one may directly output $y^*=\mu^*$ as the prediction for regression task. For further study on the function $f(.)$, the distribution over this function is also available by sampling enough points and plotting the curve (if possible). Normally, variance is large when the point to predict is far from training set.</p>
<blockquote>
<p>$\texttt{Note}:$</p>
<script type="math/tex; mode=display">
\begin{aligned}
  p(y^* | x^*, D) =&\, \frac{p(y^*, y_1,..., y_N)}{p(y_1,...,y_N)} \\
                  \propto&\, \frac{\exp\left(-\frac{1}{2}\overrightarrow{y'}^T{\Sigma'}^{-1}\overrightarrow{y'}^T \right)}{\exp\left(-\frac{1}{2}\overrightarrow{y}^T\Sigma^{-1}\overrightarrow{y} \right)} \\
                  \propto&\, \exp\left(-\frac{1}{2}\left(B{y^*}^2 + 2 A^T\overrightarrow{y}y^* \right) \right),
\end{aligned}</script><p>where</p>
<script type="math/tex; mode=display">
{\Sigma'}^{-1} = \left(
\begin{matrix}
    C & A \\
    A^T & B
\end{matrix}
\right),</script><p>and</p>
<script type="math/tex; mode=display">
A = \frac{-\Sigma^{-1}k_*}{k_{**} - k_*^T\Sigma^{-1}k_*},\;\; B = \frac{1}{k_{**} - k_*^T\Sigma^{-1}k_*}.</script><p>Thus, the posterior distribution is Gaussian as</p>
<script type="math/tex; mode=display">
y^* | x^*, D \sim \mathcal{N}(\mu^*, \sigma^*),</script><p>where the expectation and variance are known:</p>
<script type="math/tex; mode=display">
\mu^* = -B^{-1}A^T\overrightarrow{y},\;\; \sigma^* = B^{-1}.</script></blockquote>
<h2 id="Ridge-Regression"><a href="#Ridge-Regression" class="headerlink" title="Ridge Regression"></a>Ridge Regression</h2><p>The ridge regression is actually the simplest case of Gaussian process. Before discussing this relationship, consider first a noisy model $f(.)+\epsilon$, with $\epsilon\sim\mathcal{N}(0,\sigma_\epsilon^2)$. Supposing the noise is independent among points, the posterior for test points can be updated as</p>
<script type="math/tex; mode=display">
y^* | x^*, D, \sigma_\epsilon^2 \sim \mathcal{N}(\mu^*, \sigma^*),</script><script type="math/tex; mode=display">
\mu^* = k_*^T\Sigma_n^{-1}\overrightarrow{y},\;\;\sigma^* = -k_*^T\Sigma_n^{-1}k_* + k_{**},</script><p>where</p>
<script type="math/tex; mode=display">
\Sigma_n = \Sigma + \sigma_\epsilon^2 I_N.</script><p>This noise modeling is a kind of regularization, which is well used in ridge regression:</p>
<script type="math/tex; mode=display">
\hat{\theta} = \arg\min_W \sum_{i=1}^N\|y_i - x_i\theta \|^2 + \beta\|\theta \|^2,\;\;\beta\gt 0,</script><p>where the function to fit is supposed to be linear as $f(x)=x\theta$. Given this convex problem, a closed-form solution can be computed as</p>
<script type="math/tex; mode=display">
\hat{\theta} = X^T\left(XX^T + \beta I_N \right)\overrightarrow{y},\;\; X = \left(x_1;...;x_N \right).</script><p>Thus the prediction becomes</p>
<script type="math/tex; mode=display">
y^* = x^* \hat{\theta} = x^*X^T\left(XX^T + \beta I_N \right)\overrightarrow{y}.</script><p>Since the dot product is also a kind of kernel, by noting</p>
<script type="math/tex; mode=display">
k_*^T = x^* X^T,\;\;\Sigma = XX^T,</script><p>the prediction is reformed as a noisy GPR:</p>
<script type="math/tex; mode=display">
y^* = k_*^T\left(\Sigma + \sigma_\epsilon^2 I_N \right)\overrightarrow{y},\;\;\beta = \sigma_\epsilon^2.</script><blockquote>
<p>$\texttt{Note}:$ The dot product indicates a similarity when the vectors are normalized, otherwise, it explodes for largely normed ones. Given that, to adopt ridge regression, it would be better to preprocess the data by normalization.</p>
</blockquote>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


		
    
		
			

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/Machine-Learning/Training-Trick/Bayesian-Optimization/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="RemiC">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Remi's Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Machine-Learning/Training-Trick/Bayesian-Optimization/" itemprop="url">Bayesian Optimization</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-12-31T22:21:15+08:00">
                2018-12-31
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Machine Learning</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/Training-Trick/" itemprop="url" rel="index">
                    <span itemprop="name">Training Trick</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>This text refers to the <a href="https://en.wikipedia.org/wiki/Bayesian_optimization" target="_blank" rel="noopener">Bayesian Optimization</a>, a method using Gaussian process to find the optimum.</p>
<h2 id="Bayesian-Optimization"><a href="#Bayesian-Optimization" class="headerlink" title="Bayesian Optimization"></a>Bayesian Optimization</h2><p>As seen in <a href="Machine-Learning/Training-Trick/Gaussian-Process-Rregression">Gaussian Process Regression (GPR)</a>, any function can be fitted via GPR, which is also useful in optimization field. Consider an objective function $f(.)$ to optimize (maximize/minimize) with its form unknown, it is feasible to fit the function first then search for the solution, but this process is quite costly since the regression part requires a lot of sampling points. To this end, two strategies are possible, which corresponds different kinds of <em>acquisition function</em>,</p>
<ul>
<li>Explore: Sample the most discriminative points so that the objective can be represented as soon as possible.</li>
<li>Exploit: Sample towards the optimum so that a local minimum/maximum can be fast approched.</li>
<li>Mix: Find a compromise between explore and exploit.</li>
</ul>
<blockquote>
<p>$\texttt{Note}:$ Both strategies depend on the posterior knowledge knowing the previous sampling results.</p>
</blockquote>
<h3 id="POI"><a href="#POI" class="headerlink" title="POI"></a>POI</h3><p>Probability of improvement (POI) is an exploring acquistion function, which in form as</p>
<script type="math/tex; mode=display">
PI(x) = p(f(x) \ge f(x^+)) = \Phi\left(\frac{\mu(x) - f(x^+)}{\sigma(x)} \right),</script><p>where $x^+$ is a local optimum, $\Phi(.)$ is normal cumulative distribution function (CDF), or maximum probability of improvement (MPI). The next sampling point is the one maximizing $PI(x)$. To avoid a local convergence, a tunable parameter $\varepsilon$ is often included:</p>
<script type="math/tex; mode=display">
PI(x) = p(f(x) \ge f(x^+) + \varepsilon) = \Phi\left(\frac{\mu(x) - f(x^+) - \varepsilon}{\sigma(x)} \right).</script><h3 id="EI"><a href="#EI" class="headerlink" title="EI"></a>EI</h3><p>Expected improvement (EI) does not only consider the probability of increasing/decreasing the objective, but also the magnitude. One choice for the improvement function is</p>
<script type="math/tex; mode=display">
I(x) = \max\{0, f(x) - f(x^+) \},</script><p>with the next sampling point defined as</p>
<script type="math/tex; mode=display">
\hat{x} = \arg\max_x \mathbb{E}\left[I(x) | D_t \right],</script><p>where $D_t$ is the points sampled until the current moment. Now compute EI,</p>
<script type="math/tex; mode=display">
\begin{aligned}
    EI(x) =&\, \mathbb{E}\left[I(x) | D_t \right] \\ 
          =&\, \int_0^{+\infty} I p(I) dI \\
          =&\, \int_0^{+\infty} I \frac{1}{\sqrt{2\pi}\sigma(x)} \exp\left(-\frac{\left(\mu(x) - f(x^+) - I \right)^2}{2\sigma^2(x)} \right)dI \\
          =&\, \sigma(x)\left(\frac{\mu(x) - f(x^+)}{\sigma(x)}\Phi\left(\frac{\mu(x) - f(x^+)}{\sigma(x)} \right) + \phi\left(\frac{\mu(x) - f(x^+)}{\sigma(x)} \right) \right),
\end{aligned}</script><p>where $\phi(.)$ is normal probability density function (PDF). Or more rigorously,</p>
<script type="math/tex; mode=display">
EI(x) = \left\{
\begin{aligned}
    &\, \left(\mu(x) - f(x^+) \right)\Phi(Z) + \sigma(x)\phi(Z),\;\; \sigma(x)\lt 0 \\
    &\, 0,\;\; \sigma(x) = 0
\end{aligned}
\right.</script><script type="math/tex; mode=display">
Z = \frac{\mu(x) - f(x^+)}{\sigma(x)}.</script><p>A trade-off for exploring can be included as well as in POI:</p>
<script type="math/tex; mode=display">
EI(x) = \left\{
\begin{aligned}
    &\, \left(\mu(x) - f(x^+) - \varepsilon \right)\Phi(Z) + \sigma(x)\phi(Z),\;\; \sigma(x)\lt 0 \\
    &\, 0,\;\; \sigma(x) = 0
\end{aligned}
\right.</script><script type="math/tex; mode=display">
Z = \frac{\mu(x) - f(x^+) - \varepsilon}{\sigma(x)}.</script><h3 id="LCB"><a href="#LCB" class="headerlink" title="LCB"></a>LCB</h3><p>// TODO</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] Brochu, E., Cora, V. M., &amp; De Freitas, N. (2010). A tutorial on Bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning. arXiv preprint arXiv:1012.2599.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


		
    
		
			

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/Computer-Vision/Object-Detection/YOLO/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="RemiC">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Remi's Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Computer-Vision/Object-Detection/YOLO/" itemprop="url">YOLO</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-12-25T17:30:42+08:00">
                2018-12-25
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Computer-Vision/" itemprop="url" rel="index">
                    <span itemprop="name">Computer Vision</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Computer-Vision/Object-Detection/" itemprop="url" rel="index">
                    <span itemprop="name">Object Detection</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>This text refers to the paper <strong>You Only Look Once: Unified, Real-Time Object Detection</strong> <a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Redmon_You_Only_Look_CVPR_2016_paper.pdf" target="_blank" rel="noopener">[1]</a>, which proposes to detect objects by solving a designed regression problem. The YOLO contains only a single network as in the unified framework, instead of multi-part components, such as RPN.</p>
<h2 id="Grid"><a href="#Grid" class="headerlink" title="Grid"></a>Grid</h2><p>To avoid region proposal based methods, the bounding-box coordinates should be directly learned from features. For CNN features that keep location information, each point or vector across channels represents certain property of a region mapped to the original image. This property varies from the objective function designed. For instance, in Faster R-CNN <a href="Computer-Vision/Object-Detection/Faster-R-CNN">[2]</a>, features are assigned to be whether to contain objects, corresponding class if positive. Similarly, YOLO does bounding-box coordinates, corresponding class and confidence. Thus if the final features form a $S\times S$ map, each point or vector across channels maps to a grid of the original image, which is divided into $S\times S$ grids. In this case, each grid is supposed to predict the property expected. Particularly, the author doubles this prediction and select the most “confident” one as result. Then say $C$ classes, $(x,y,w,h)$ the coordinates, the channel number of the final features is $2\times5+C$.</p>
<blockquote>
<p>$\texttt{Notes}:$ The last $C$ channels consist the conditioned distribution of classification, $\mathbb{P}(\texttt{class}|\texttt{object})$, i.e. the probability of $\texttt{class}$ knowing the existance of $\texttt{object}$.</p>
</blockquote>
<h2 id="Confidence"><a href="#Confidence" class="headerlink" title="Confidence"></a>Confidence</h2><p>The confidence indicates how confident the grid admits the existance of an object, designed as $\mathbb{P}(\texttt{object})\cdot \texttt{IOU}^\texttt{T}_\texttt{P}$, where $\mathbb{P}(\texttt{object})$ is the probability of existance of $\texttt{object}$ and $\texttt{IOU}^\texttt{T}_\texttt{P}$ is the intersection over union between ground truth and bounding-box prediction computed as</p>
<script type="math/tex; mode=display">
\texttt{IOU}^\texttt{T}_\texttt{P} = \frac{\texttt{Area of overlap}}{\texttt{Area of union}}.</script><p>The confidence becomes null when there is no object. At training time, it should be equal to $\texttt{IOU}^\texttt{T}_\texttt{P}$. At test time, the author multiplies the conditional class probabilities and the individual box conﬁdence predictions:</p>
<script type="math/tex; mode=display">
\mathbb{P}(\texttt{class}|\texttt{object})\cdot\mathbb{P}(\texttt{object})\cdot \texttt{IOU}^\texttt{T}_\texttt{P} = \mathbb{P}(\texttt{class})\cdot\texttt{IOU}^\texttt{T}_\texttt{P}.</script><h2 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h2><p>To this point, there remains a problem when training: how to match prediction and ground truth, because each grid does not predict which object is concerned. Given that, the author proposes to make the grid containing the center of an object responsible for its prediction. But it is still confusing since each grid predicts multiple (two) bounding-boxes. The author then matches the one of the highest $\texttt{IOU}$ with the ground truth.</p>
<p>However, this kind of design supposes <em>a priori</em> that each grid contains at most the center of one object, which may lead to a poor recall ratio for small and close objects.</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] Redmon, J., Divvala, S., Girshick, R., &amp; Farhadi, A. (2016). You only look once: Unified, real-time object detection. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 779-788).</p>
<p>[2] Ren, S., He, K., Girshick, R., &amp; Sun, J. (2015). Faster r-cnn: Towards real-time object detection with region proposal networks. In Advances in neural information processing systems (pp. 91-99).</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


		
    
		
			

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/Computer-Vision/Object-Detection/Faster-R-CNN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="RemiC">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Remi's Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Computer-Vision/Object-Detection/Faster-R-CNN/" itemprop="url">Faster R-CNN</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-12-18T16:54:31+08:00">
                2018-12-18
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Computer-Vision/" itemprop="url" rel="index">
                    <span itemprop="name">Computer Vision</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Computer-Vision/Object-Detection/" itemprop="url" rel="index">
                    <span itemprop="name">Object Detection</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>This text refers to the paper Faster R-CNN <a href="http://papers.nips.cc/paper/5638-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks" target="_blank" rel="noopener">[1]</a>, which embeds region proposing in the CNN, namely region proposal network (RPN), thus allowing real-time detection.</p>
<h2 id="Region-Proposal-Network"><a href="#Region-Proposal-Network" class="headerlink" title="Region Proposal Network"></a>Region Proposal Network</h2><p>In the previous studies on object detection as R-CNN and Fast R-CNN, region proposals are generated by the algorithms (e.g. selective search) independent of the CNN used, which incites promising but costly results. However, this computation complexity is not necessary due to the repetition of feature extracting. To this end, one natural solution is embedding the region proposing in the CNN. Faster R-CNN implements this idea by filtering region proposals that containing foreground based on the feature maps given by the CNN.</p>
<h3 id="To-Feature-Maps"><a href="#To-Feature-Maps" class="headerlink" title="To Feature Maps"></a>To Feature Maps</h3><p>The feature maps computed by a fully convolutional network keep the relative location relationships, region features are extracted into a channel-dimensioned vector and stacked in the order as the original image. For instance, say an image of size $H\times W$ maps to a feature map of size $h\times w\times c$, generally each region grid of size $\lceil H/h\rceil\times\lceil W/w\rceil$ maps to a feature vector of size $1\times1\times c$ in the feature maps. Therefore, by supposing that containing objects is a property of the corresponding region and available in the feature maps, each feature vector should be further operated for a classification result (foreground or background).</p>
<h3 id="Multi-scale-Proposals"><a href="#Multi-scale-Proposals" class="headerlink" title="Multi-scale Proposals"></a>Multi-scale Proposals</h3><p>Based on the idea mentioned above, only regions of size $\lceil H/h\rceil\times\lceil W/w\rceil$ can be proposed, which raises at least two problems:</p>
<ul>
<li>Given the depth of CNN, this size is normally too large as a bounding-box.</li>
<li>Considering that obejcts may appear in any scale or direction, the scale and shape should vary for different cases.</li>
</ul>
<p>The author thus proposes a multi-scale solution. For the object in the region of the original image, it is expected to be contained in 9 different bounding-boxes, with shapes $[1:1,1:2,2:1]$ and scales $[128^2,256^2,512^2]$. In this case, the feature vectors are no longer used to predict whether the corresponding region contains objects, but moreover to define in which proposal an object exists. These multi-scale proposals are named <em>anchors</em> in Fast R-CNN.</p>
<h3 id="Fine-Convolution"><a href="#Fine-Convolution" class="headerlink" title="Fine Convolution"></a>Fine Convolution</h3><p>Since the existance of object is inferred from the feature vector, a $1\times1$ convolutional layer is stacked afterward. The problem is how to set the number of filters, i.e. the number of output channels. To generalize the situation, say there are $k$ anchors for each feature vector, then classification of foreground or background requires $2k$-demensioned vector, which are coupled and further passed to a Softmax function. Given that, there should be $2k$ filters in this $1\times1$ convolutional layer.</p>
<blockquote>
<p>$\texttt{Note}:$ Starting from the feature maps of the fully CNN, Fast R-CNN adds a $3\times3$ convolutional layer without channel number changed, followed by a $1\times1\times18$ convolutional layer. To further computed Softmax result, the $18$-channeled feature maps should be reshaped into $9\times h\times w$ $2$-dimensioned vector. The cross-entropy loss is included for training this part.</p>
</blockquote>
<h3 id="Regression"><a href="#Regression" class="headerlink" title="Regression"></a>Regression</h3><p>Filtering region proposals containing objects is not enough, to generate rather accurate proposals, a bounding-box regression is used for those filtered. The regression is similar to that of R-CNN or Fast R-CNN, where the coarse coordinates are tuned based on certain parameters computed from feature maps extracted from the fully CNN. Another similar regression will be conducted by the final detector.</p>
<h2 id="Detector"><a href="#Detector" class="headerlink" title="Detector"></a>Detector</h2><p>For detection, a Fast R-CNN structure is stacked afterward. Refer to the <a href="Computer-Vision/Object-Detection/Fast-R-CNN">Fast R-CNN</a> for more details.</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] Ren, S., He, K., Girshick, R., &amp; Sun, J. (2015). Faster r-cnn: Towards real-time object detection with region proposal networks. In Advances in neural information processing systems (pp. 91-99).</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


		
    
		
			

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/Computer-Vision/Object-Detection/Fast-R-CNN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="RemiC">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Remi's Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Computer-Vision/Object-Detection/Fast-R-CNN/" itemprop="url">Fast R-CNN</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-12-18T14:04:50+08:00">
                2018-12-18
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Computer-Vision/" itemprop="url" rel="index">
                    <span itemprop="name">Computer Vision</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Computer-Vision/Object-Detection/" itemprop="url" rel="index">
                    <span itemprop="name">Object Detection</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>This text refers to the paper Fast R-CNN <a href="https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Girshick_Fast_R-CNN_ICCV_2015_paper.html" target="_blank" rel="noopener">[1]</a>,which improves the <a href="Computer-Vision/Object-Detection/R-CNN">R-CNN</a> in that region proposals of the same image share feature maps.</p>
<h2 id="Feature-Sharing"><a href="#Feature-Sharing" class="headerlink" title="Feature Sharing"></a>Feature Sharing</h2><p>Still using selective search for region proposals, fast R-CNN does not crops regions and has it enter the CNN model, but instead, allows sharing feature maps afterward. In fact, fully CNN model normally extracts feature maps with location relationships kept. For instance, one pixel of the origin image can be simply mapped to the output feature maps via a simple dilation. Thus, the region proposals occupy the same regions of feature maps as they do in the original image. Given that, compared with R-CNN, this model must save much computation cost for feature extraction part.</p>
<h2 id="RoI-Pooling"><a href="#RoI-Pooling" class="headerlink" title="RoI Pooling"></a>RoI Pooling</h2><p>One challenge is that shapes of region proposals vary from time to time, and hence the fully-connected (FC) layers can not be adopted directly. To this end, the author proposes region of interest (RoI) pooling layer, embedded between CNN and FC. This pooling layer fixes the spatial extent, e.g. $(H, W)$, and vary the sliding window by dividing the $(h, w)$ RoI window into an $H\times W$ grid of sub-window of approximate size $h/H\times w/W$ and then max-pooling the values in each sub-window into the corresponding output grid cell.</p>
<blockquote>
<p>$\texttt{Note}:$ RoI pooling is actually a special case of spatial pyramid pooling used in SPPNet <a href="https://arxiv.org/abs/1406.4729" target="_blank" rel="noopener">[2]</a>.</p>
</blockquote>
<h2 id="Multi-task-Training"><a href="#Multi-task-Training" class="headerlink" title="Multi-task Training"></a>Multi-task Training</h2><p>Aside classifer, another barnch of FC is aligned, for bounding box regression, after a feature vector extracted. Instead of using multiple SVMs, here Softmax is utilized for classification:</p>
<script type="math/tex; mode=display">
\mathcal{L}_c(u) = -\log p_u,</script><p>cooperating with a regression loss as</p>
<script type="math/tex; mode=display">
\mathcal{L}_l(t^u, v) = \sum_{*\in\{x, y, w, h\}} f(t^u_* - v_*),</script><p>where</p>
<script type="math/tex; mode=display">
f(x) = \left\{
\begin{aligned}
    &\,0.5x^2,\;\;\text{if}\;|x| \lt 1 \\
    &\,|x| - 0.5,\;\;\text{otherwise}
\end{aligned}
\right.</script><p>$t^u$ is the ground truth of bouding box for class $u$.</p>
<blockquote>
<p>$\texttt{Note}:$ The metric $f(.)$ is a smooth version of $l_1$ norm, which is easy to compute gradient and meanwhile not sensitive to the outliers as $l_2$ norm is.</p>
</blockquote>
<p>Therefore, the result loss function is a linear combination of these sub two above:</p>
<script type="math/tex; mode=display">
\mathcal{L}(u, t^u, v) = \mathcal{L}_c(u) + \lambda[u\ge1]\mathcal{L}_l(t^u, v),</script><p>where $\lambda$ controls the balance.</p>
<h2 id="Fast-Detection"><a href="#Fast-Detection" class="headerlink" title="Fast Detection"></a>Fast Detection</h2><p>At test-time, an image is passed to the model, along with its region proposals $(\sim2000)$. The output is a class posterior probability distribution $p$ and a set of predicted boundind-box. For each proposal, a confidence is assigned to each class $k$ as $\mathbb{P}(k)$. A greedy non-maximum suppression is then adopted as R-CNN.</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] Girshick, R. (2015). Fast r-cnn. In Proceedings of the IEEE international conference on computer vision (pp. 1440-1448).</p>
<p>[2] He, K., Zhang, X., Ren, S., &amp; Sun, J. (2014, September). Spatial pyramid pooling in deep convolutional networks for visual recognition. In European conference on computer vision (pp. 346-361). Springer, Cham.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


		
    
		
			

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/Computer-Vision/Object-Detection/R-CNN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="RemiC">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Remi's Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Computer-Vision/Object-Detection/R-CNN/" itemprop="url">R-CNN</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-12-16T01:01:32+08:00">
                2018-12-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Computer-Vision/" itemprop="url" rel="index">
                    <span itemprop="name">Computer Vision</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Computer-Vision/Object-Detection/" itemprop="url" rel="index">
                    <span itemprop="name">Object Detection</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>This text refers to the paper Rich Feature Hierarchical for Accurate Object Detection and Semantic Segmentation <a href="https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Girshick_Rich_Feature_Hierarchies_2014_CVPR_paper.pdf" target="_blank" rel="noopener">[1]</a>, which proposes to detect objects via feature maps extracted by fully convolutional neural network (CNN), based on the <a href="Computer-Vision/Object-Detection/Selective-Search">selective search</a> algorithm for region proposals.</p>
<h2 id="Feature-Extraction"><a href="#Feature-Extraction" class="headerlink" title="Feature Extraction"></a>Feature Extraction</h2><p>R-CNN extracts feature maps of all region proposals from a CNN ended with a pooling layer. Given that the input size of CNN is fixed and region proposals vary from sizes, the author proposes to warp the proposals to the size of the input by a simple dilation. The region proposals here are given by selective search.</p>
<h2 id="Detector"><a href="#Detector" class="headerlink" title="Detector"></a>Detector</h2><h3 id="Classifier"><a href="#Classifier" class="headerlink" title="Classifier"></a>Classifier</h3><p>An SVM is set for each class, including background. When the feature vector of certain proposal enters SVMs, it is equally assigned a score, which is further used to rank proposals. Given all score regions, a greedy non-maximum suppression that rejects a region if it has an intersection-over-union (IoU) overlap with a higher scoring selected region larger than a <em>learned</em> threshold.</p>
<blockquote>
<p>$\texttt{Question}:$ How to learn this threshold?</p>
</blockquote>
<h3 id="Bounding-box-Regressor"><a href="#Bounding-box-Regressor" class="headerlink" title="Bounding-box Regressor"></a>Bounding-box Regressor</h3><p>To predict a more accurate bounding-box, a regression is stacked, trained for mapping proposals’ CNN features to locations and scales. Note $\{\left(P^i,G^i\right)\}_{i=1,…,N}$ the training samples, $P^i=\left(P^i_x,P^i_y,P^i_w,P^i_h \right)$ the proposal, $G^i=\left(G^i_x,G^i_y,G^i_w,G^i_h \right)$ the ground truth. The bounding-box regressed is thus</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \hat{G}_x =&\, P_w d_x(P) + P_x \\
    \hat{G}_y =&\, P_h d_y(P) + P_y \\
    \hat{G}_w =&\, P_w \exp(d_w(P)) \\
    \hat{G}_h =&\, P_h \exp(d_h(P)),
\end{aligned}</script><p>where $d_*(.)$ is a linear function operating on the CNN feature maps.</p>
<blockquote>
<p>$\texttt{Note}:$ For regression from $P_<em>$ to $\hat{G}_</em>$, the scale multiplier $P_w$ or $P_h$ is reasonable if the base units are supposed to be coherent across the equality.</p>
</blockquote>
<p>Note $W_<em>$ the weight of $d_</em>(.)$, its optimal solution is</p>
<script type="math/tex; mode=display">
\hat{W}_* = \arg_{W_*}\min \sum_{i=1}^N \left(t^i_* - W_*^T P^i \right)^2 + \lambda \|W_* \|^2,</script><p>where $\lambda$ controls the regularization, which is found to be important.</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] Girshick, R., Donahue, J., Darrell, T., &amp; Malik, J. (2014). Rich feature hierarchies for accurate object detection and semantic segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 580-587).</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


		
    
		
			

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/Computer-Vision/Object-Detection/Selective-Search/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="RemiC">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Remi's Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Computer-Vision/Object-Detection/Selective-Search/" itemprop="url">Selective Search</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-12-15T22:56:36+08:00">
                2018-12-15
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Computer-Vision/" itemprop="url" rel="index">
                    <span itemprop="name">Computer Vision</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Computer-Vision/Object-Detection/" itemprop="url" rel="index">
                    <span itemprop="name">Object Detection</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>This text refers to the paper Selective Search for Object Recognition <a href="https://staff.fnwi.uva.nl/th.gevers/pub/GeversIJCV2013.pdf" target="_blank" rel="noopener">[1]</a>, which propose a unified framework for object recognition/detection. The most important contribution, which will be discussed here, is a diversified sampling strategy for region proposal, namely selective search. It combines the strength of both exhaustive search and segmentation and is still widely used in object detection field.</p>
<h2 id="Region-Proposal"><a href="#Region-Proposal" class="headerlink" title="Region Proposal"></a>Region Proposal</h2><p>For detecting or recognizing a certain object in an image, it includes not only classification knowledge but also geometry information, i.e. location and scale. A straight solution is thus traversing all possible locations and scales and outputting the ones classified to the object required. These locations and scales are called <em>region proposal</em>, commonly in form of rectangle with a corner, length and width defined. However, given the huge visual search space, this kind of exhaustive search becomes computationally expensive. This is why the previous studies generally adopt coarse grid search, but still blind and costly, which forces to equip weak feature extractors and classifers to make up computation complexity.</p>
<h2 id="Reviews"><a href="#Reviews" class="headerlink" title="Reviews"></a>Reviews</h2><p>Although exhaustive search is costly, it holds several advantages which should be kept:</p>
<ul>
<li>Class-independence, which ensures a unified and general framework.</li>
<li>Not leaky, which returns all location and scale possibilities.</li>
<li>…</li>
</ul>
<p>Note that the huge search space arises because the locations and scales are sampled without any visual knowledge. Segmentaion is one method to provide a coarse but reliable proposals, which enables the sampling strategy not blind any more. But a class-independent segmentation may lead to a excessively fine proposals, and thus requires a strong algorithm forming good regions.</p>
<h2 id="Selective-Search"><a href="#Selective-Search" class="headerlink" title="Selective Search"></a>Selective Search</h2><p>Selective search is a region sampling strategy which combines the strength of exhaustive seach and segmentation. It initalize with a segmentation result and form good regions based on regions’ hierarchical relationships, without class knowledge. A fine to coarse “pyramid” can be thus generated via the greedy algorithm, where on each level a set of regions are proposed. The final region proposal contains about 2000 regions, which is much less than that exhaustive search but still covers reliable locations and scales. Details are discussed below.</p>
<h3 id="Hierarchical-Grouping"><a href="#Hierarchical-Grouping" class="headerlink" title="Hierarchical Grouping"></a>Hierarchical Grouping</h3><p>The objects in visual field as images are normally included in a hierarchical relationships. For instance, on a table there may be a bowl of eggs, and recognition of the table should upstream from the eggs. From this point, the author starts from rather fine segmentation results [2], then use a greedy algorithm to iteratively group pairs of neighbouring regions together based on a similarity ranked, i.e. the most similar pair of neighbouring regions are merged for each iteration. The similarity here is computed by a function proposed by the author, which combines various standards as described below.</p>
<h3 id="Diversification-for-Similarity"><a href="#Diversification-for-Similarity" class="headerlink" title="Diversification for Similarity"></a>Diversification for Similarity</h3><p>The author propose to compute the final similarity between neghbouring regions $(r_i, r_j)$ by summing up four weighted sub-similarity functions $s_*(.,.)$:</p>
<ul>
<li>Colour</li>
</ul>
<script type="math/tex; mode=display">
s_c(r_i, r_j) = \sum_{k=1}^n \min(c_i^k, c_j^k),</script><p>where $c_i^k$ denotes the colour normalized of $r_i$ in $k$-th colour bin.</p>
<ul>
<li>Texture</li>
</ul>
<script type="math/tex; mode=display">
s_t(r_i, r_j) = \sum_{k=1}^n \min(t_i^k, t_j^k),</script><p>where $t_i^k$ denotes the texture histogram value of $r_i$ in $k$-th histogram bin.</p>
<ul>
<li>Size</li>
</ul>
<script type="math/tex; mode=display">
s_s(r_i, r_j) = 1 - \frac{size(r_i) + size(r_j)}{size(im)},</script><p>which requires the regions left to be in similar sizes and will be updated by $size(r_t)=size(r_i)+size(r_j)$.</p>
<ul>
<li>Fitness</li>
</ul>
<script type="math/tex; mode=display">
s_f(r_i, r_j) = 1 - \frac{B_{ij} - size(r_i) - size(r_j)}{size(im)},</script><p>where $B_{ij}$ is the tight bounding box containing $r_i$ and $r_j$, encouraging to merge regions with large parts touched.</p>
<p>Finally, the similarity is</p>
<script type="math/tex; mode=display">
s(r_i, r_j) = \sum_{*\in E} a_* s_*(r_i, r_j),\;\; E = \{c, t, s, f \},</script><p>where $a_*\in\{0,1 \}$ indicates whether to use the corresponding similarity.</p>
<h2 id="Combining-Locations"><a href="#Combining-Locations" class="headerlink" title="Combining Locations"></a>Combining Locations</h2><p>Once region proposals are given by the selective search, it should be noted that they are not equi-possible to be an object and those not likely tend to be removed for computation efficiency. To this end, the authot assigns for each region $r_i$ a value $v_i=\delta\cdot i$ and rank based on this all the regions, where $\delta$ is a random number to prevent over emphasize on large regions. The regions with the largest $v$ will be retained, and the others are filtered by thresholding.</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] Uijlings, J. R., Van De Sande, K. E., Gevers, T., &amp; Smeulders, A. W. (2013). Selective search for object recognition. International journal of computer vision, 104(2), 154-171.</p>
<p>[2] Felzenszwalb, P. F., &amp; Huttenlocher, D. P. (2004). Efficient graph-based image segmentation. International journal of computer vision, 59(2), 167-181.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


		
    
		
			

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/Machine-Learning/Basic-Method/On-Gradients-of-Stochastic-Neurons/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="RemiC">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Remi's Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Machine-Learning/Basic-Method/On-Gradients-of-Stochastic-Neurons/" itemprop="url">On Gradients of Stochastic Neurons</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-12-06T21:06:26+08:00">
                2018-12-06
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Machine Learning</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/Basic-Method/" itemprop="url" rel="index">
                    <span itemprop="name">Basic Method</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>This text mainly refers to the paper <a href="https://arxiv.org/abs/1308.3432" target="_blank" rel="noopener">Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation</a> [1]. Regardless of Stochastic Times Smooth (STS) units and Straight-Through Estimator (STE), the technique detail of an unbiased estimator of gradient for stochastic binary neurons is discussed in this text.</p>
<h2 id="Stochastic-Binary-Neurons"><a href="#Stochastic-Binary-Neurons" class="headerlink" title="Stochastic Binary Neurons"></a>Stochastic Binary Neurons</h2><p>Considering hard non-linearity as activation function in neural networks, the gradients are normaly incomputable, but can be estimated with the help of stochaistic pertubation, which is actually a random noise multiplied on neurons, e.g. dropout. These kind of neurons are referred as stochastic neurons in this text, and become more insteresting in binary case, i.e. the output activated of neurons is either 0 or 1, namely stochastic binary neurons. One may ask for the strategy to binarize the outputs, which is proposed to be based on a sigmoid probability. For illustration, say a fully-connected layer with input $x$, weight $W$, bias $b$ and output activated $h$, then</p>
<script type="math/tex; mode=display">
h_i = f(a_i, z_i) = \mathbb{I}_{z_i \lt \sigma(a_i)},\;\; a_i = b_i + \sum_j W_{ij}x_j,</script><p>where $z_i\sim \mathcal{U}[0,1]$ is uniform and $\sigma(u)=1/(1+\exp(-u))$ is sigmoid function.</p>
<h2 id="Unbiased-Estimator-for-Gradient"><a href="#Unbiased-Estimator-for-Gradient" class="headerlink" title="Unbiased Estimator for Gradient"></a>Unbiased Estimator for Gradient</h2><p>Let $\mathcal{L}$ be the objective function, then computing directly the gradient of $\mathcal{L}$ with regard to parameters are intractable. However, an unbiases estimator is still feasible. Note that accordint to the chain rule, i.e.</p>
<script type="math/tex; mode=display">
\frac{\partial\mathcal{L}}{\partial W_{ij}} = \frac{\partial\mathcal{L}}{\partial a_i}\cdot \frac{\partial a_i}{\partial W_{ij}},</script><p>the first term on the right is the only one in need to estimate, whose expectation is thus in need if the estimation is supposed to be unbiased. </p>
<p>Additionally, among advances of recent network designs, dropout is commonly included, which is stochastic as well as $z$. In this case, these random parameters should also be considered during the estimation for gradient. Note that this dropout noise does not require updates and is viewed as fixed once sampled when forwarding. Therefore, the expectation is conditionned on the random parameters if they influence $a$. For clarity, let $\Gamma=\{z_i\}\bigcup\ c_i\bigcup c_{-i}$ be the set of all random variables divided according to whether they influence $a_i$ as $c_i$ does. Note $\mathcal{L}=\mathcal{L}(h_i,c_i,c_{-i})$.</p>
<p>Now compute the expectation of $L$ conditioned on $c_i$,</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \mathbb{E}\left[\mathcal{L} | c_i \right] =&\, \mathbb{E}_{c_{-i}}\left[\mathbb{E}_{z_i}\left[L | c_i \right] \right] \\
                                    =&\, \mathbb{E}_{c_{-i}}\left[\mathbb{E}_{z_i}\left[h_i\mathcal{L}\left(1, c_i, c_{-i} \right) + (1 - h_i)\mathcal{L}\left(0, c_i, c_{-i} \right) \right] \right] \\
                                    =&\, \mathbb{E}_{c_{-i}}\left[\mathbb{P}\left(h_i=1 | a_i \right)\mathcal{L}\left(1, c_i, c_{-i} \right) + \mathbb{P}\left(h_i=0 | a_i \right)\mathcal{L}\left(0, c_i, c_{-i} \right) \right] \\
                                    =&\, \mathbb{E}_{c_{-i}}\left[\sigma(a_i)\mathcal{L}\left(1, c_i, c_{-i} \right) + \left(1 - \sigma(a_i) \right)\mathcal{L}\left(0, c_i, c_{-i} \right) \right].
\end{aligned}</script><p>Further derive the average gradient,</p>
<script type="math/tex; mode=display">
\begin{aligned}
    g_i = \mathbb{E}\left[\frac{\partial\mathcal{L}}{\partial a_i} | c_i \right] =&\, \frac{\partial\mathbb{E}\left[\mathcal{L} | c_i\right]}{\partial a_i} \\
                                                                     =&\, \mathbb{E}_{c_{-i}}\left[\sigma'(a_i)\mathcal{L}\left(1, c_i, c_{-i} \right) - \sigma'(a_i)\mathcal{L}\left(0, c_i, c_{-i} \right) \right] \\
                                                                     =&\, \mathbb{E}_{c_{-i}}\left[\sigma(a_i)\left(1 - \sigma(a_i) \right)\left(\mathcal{L}\left(1, c_i, c_{-i} \right) - \mathcal{L}\left(0, c_i, c_{-i} \right) \right) \right].
\end{aligned}</script><p>Now consider the estimator</p>
<script type="math/tex; mode=display">
\hat{g}_i = \left(h_i - \sigma(a_i) \right)\mathcal{L}(h_i, c_i, c_{-i}) = h_i\left(1 - \sigma(a_i) \right)\mathcal{L}(1, c_i, c_{-i}) - \sigma(a_i)(1 - h_i)\mathcal{L}(0, c_i, c_{-i}),</script><p>whose expectation is</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \mathbb{E}[\hat{g}_i | c_i] =&\, \mathbb{E}_{c_{-i}, z_i}\left[h_i\left(1 - \sigma(a_i) \right)\mathcal{L}(1, c_i, c_{-i}) - \sigma(a_i)(1 - h_i)\mathcal{L}(0, c_i, c_{-i})\right] \\
                                =&\, \mathbb{E}_{c_{-i}}\left[\sigma(a_i)\left(1 - \sigma(a_i) \right)\mathcal{L}(1, c_i, c_{-i}) - \sigma(a_i)(1 - \sigma(a_i))\mathcal{L}(0, c_i, c_{-i}) \right] \\
                                =&\, \mathbb{E}_{c_{-i}}\left[\sigma(a_i)\left(1 - \sigma(a_i) \right)\left(\mathcal{L}(1, c_i, c_{-i}) - \mathcal{L}(0, c_i, c_{-i}) \right) \right],
\end{aligned}</script><p>which is the same as that of the gradient. Thus $\hat{g}_i$ is an unbiased estimator for gradient.</p>
<h2 id="Low-Variance-Choice"><a href="#Low-Variance-Choice" class="headerlink" title="Low Variance Choice"></a>Low Variance Choice</h2><p>The very estimator is actually a special case of <a href="https://link.springer.com/article/10.1007/BF00992696" target="_blank" rel="noopener">policy gradient</a> [2] widely used in reinforcement learning. Consider the binarization as a random action sampled from $\mathcal{B}(\sigma(a_i))$, the objective $\mathcal{L}$ as reward $R$, and suppose trajectory $\tau$ to be unitary. The common choice for optimization is policy gradient method,</p>
<script type="math/tex; mode=display">
\frac{\partial\mathbb{E}_\tau[R]}{\partial a_i} = \mathbb{E}_\tau\left[R\cdot \frac{\partial \log p_{a_i}(h_i)}{\partial a_i} \right].</script><blockquote>
<p>$\texttt{Proof}:$<br>Suppose $p_{a_i}(h_i)$ is derivable on $0$ with regard to $a_i$, then</p>
<script type="math/tex; mode=display">
\frac{\partial \log p_{a_i}(h_i)}{\partial a_i} = \frac{1}{p_{a_i}(h_i)}\frac{\partial p_{a_i}(h_i)}{\partial a_i}.</script><p>After discretization, </p>
<script type="math/tex; mode=display">
\begin{aligned}
   \mathbb{E}_\tau\left[R\cdot \frac{\partial \log p_{a_i}(h_i)}{\partial a_i} \right] =&\, R_1\cdot \mathbb{P}\left(h_i=1 | a_i \right) \frac{1}{\mathbb{P}\left(h_i=1 | a_i \right)}\frac{\partial \mathbb{P}\left(h_i=1 | a_i \right)}{\partial a_i} \\
+&\, R_0\cdot \mathbb{P}\left(h_i=0 | a_i \right)\frac{1}{\mathbb{P}\left(h_i=0 | a_i \right)}\frac{\partial \mathbb{P}\left(h_i=0 | a_i \right)}{\partial a_i} \\
=&\, R_1\cdot \frac{\partial \mathbb{P}\left(h_i=1 | a_i \right)}{\partial a_i} + R_0\cdot \frac{\partial \mathbb{P}\left(h_i=0 | a_i \right)}{\partial a_i} \\
=&\, \frac{\partial}{\partial a_i}\left(R_1\cdot \mathbb{P}\left(h_i=1 | a_i \right) + R_0\cdot \mathbb{P}\left(h_i=0 | a_i \right) \right) \\
=&\, \frac{\partial\mathbb{E}_{h_i}[R]}{\partial a_i} \\
=&\, \frac{\partial\mathbb{E}_\tau[R]}{\partial a_i}.
\end{aligned}</script></blockquote>
<p>Given that, it is natural to extract $R\cdot \partial_{a_i} \log p_{a_i}(h_i)$ for gradient estimator, which in this case, is</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \mathcal{L}\cdot \frac{\partial \log \mathbb{P}(h_i | a_i)}{\partial a_i} =&\, h_i\mathcal{L}\cdot \left(1 + \exp(-a_i) \right) \frac{\exp(-a_i)}{\left(1 + \exp(-a_i) \right)^2} \\
                                                                              +&\, (1 - h_i)\mathcal{L}\cdot \left(1 + \exp(a_i) \right) \frac{-\exp(a_i)}{\left(1 + \exp(a_i) \right)^2}  \\
                                                                              =&\, h_i\mathcal{L}\cdot \left(1 - \sigma(a_i) \right) - (1 - h_i)\mathcal{L} \cdot \sigma(a_i) \\
                                                                              =&\, h_i\mathcal{L} - \sigma(a_i)\mathcal{L} - h_i\mathcal{L}\cdot \sigma(a_i) + h_i\mathcal{L}\cdot \sigma(a_i) \\
                                                                              =&\, \left(h_i - \sigma(a_i) \right)\mathcal{L},
\end{aligned}</script><p>which is exactly the estimator proposed.</p>
<p>Furthermore, in reinforcement learning, normaly a baseline is assigned for reward so that the gradient is of low variance. Similarly, this baseline is also necessary in the estimator, denoted by $\bar{\mathcal{L}}_i$. Then reformulate the estimator</p>
<script type="math/tex; mode=display">
\hat{g}_i = \left(h_i - \sigma(a_i) \right)\left(\mathcal{L} - \bar{\mathcal{L}}_i \right).</script><p>To minmize its variance, which is</p>
<script type="math/tex; mode=display">
\mathbb{V}ar\left[\hat{g}_i \right] = \mathbb{V}ar\left[\left(h_i - \sigma(a_i) \right)\mathcal{L} \right] - \Delta,</script><p>where</p>
<script type="math/tex; mode=display">
\Delta = \mathbb{E}\left[\left(h_i - \sigma(a_i) \right)^2\left(\mathcal{L}^2 - \left(\mathcal{L} - \bar{\mathcal{L}}_i\right)^2 \right) \right]</script><p>should be maximized by minimizing $\mathbb{E}\left[\left(h_i - \sigma(a_i) \right)^2\left(\mathcal{L} - \bar{\mathcal{L}}_i\right)^2 \right]$. Then by derivating with regrad to $\bar{\mathcal{L}}_i$,</p>
<script type="math/tex; mode=display">
\mathbb{E}\left[\left(h_i - \sigma(a_i) \right)^2\left(\mathcal{L} - \bar{\mathcal{L}}_i\right) \right] = 0,</script><p>thus</p>
<script type="math/tex; mode=display">
\bar{\mathcal{L}}_i = \frac{\mathbb{E}\left[\left(h_i - \sigma(a_i) \right)^2\mathcal{L} \right]}{\mathbb{E}\left[\left(h_i - \sigma(a_i) \right)^2 \right]}.</script><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] Bengio, Y., Léonard, N., &amp; Courville, A. (2013). Estimating or propagating gradients through stochastic neurons for conditional computation. arXiv preprint arXiv:1308.3432.</p>
<p>[2] Williams, R. J. (1992). Simple statistical gradient-following algorithms for connectionist reinforcement learning. Machine learning, 8(3-4), 229-256.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


		
    
		
			

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/Machine-Learning/Basic-Method/Deep-Neural-Networks-as-Gaussian-Processes/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="RemiC">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Remi's Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Machine-Learning/Basic-Method/Deep-Neural-Networks-as-Gaussian-Processes/" itemprop="url">Deep Neural Networks as Gaussian Processes</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-09-24T18:57:22+08:00">
                2018-09-24
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Machine Learning</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/Basic-Method/" itemprop="url" rel="index">
                    <span itemprop="name">Basic Method</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>This text refers to the paper <a href="https://arxiv.org/abs/1711.00165" target="_blank" rel="noopener">DEEP NEURAL NETWORKS AS GAUSSIAN PROCESSES</a> published at ICLR 2018, mainly revealing the equivalence between infinitely wide deep neural networks (NN) and Gaussian processes (GP).</p>
<h2 id="Notation"><a href="#Notation" class="headerlink" title="Notation"></a>Notation</h2><ul>
<li><p>$L$: depth of NN</p>
</li>
<li><p>$N_l$: width of layer $l$</p>
</li>
<li><p>$\phi$: activation function (nonlinearities)</p>
</li>
<li><p>$x^l_i$: $i$-th post-nonlinearity of $l$-th layer</p>
</li>
<li><p>$z^l_i$: $i$-th post-affine of $l$-th layer</p>
</li>
<li><p>$x^\alpha$: input data $\alpha$ in $\mathbb{R}^D$</p>
</li>
<li><p>$W^l_{ij}$: weight element of $l$-th layer</p>
</li>
<li><p>$b^l_i$: bias element of $l$-th layer</p>
</li>
<li><p>$\mathcal{GP}(\mu, K)$: Gaussian process with expectation $\mu(.)$ and covariance $K(.,.)$</p>
</li>
</ul>
<h2 id="GP-and-Single-layer-NN"><a href="#GP-and-Single-layer-NN" class="headerlink" title="GP and Single-layer NN"></a>GP and Single-layer NN</h2><p>As for a single-layer NN, the $i$-th output is computed as</p>
<script type="math/tex; mode=display">
z^1_i(x) = b^1_i + \sum_{j=1}^{N_1} W^1_{ij}x^1_j(x),\;\;\;\; x^1_j(x) = \phi\left(b^0_j + \sum_{k=1}^D W^0_{jk}x_k \right).</script><p>According to the Central Limit Theorem, when $N_1\rightarrow\infty$, $z^1_i(x)$ will be Gaussian distributed. Given that, $\{z^1_i(x^{\alpha=1}),…,z^1_i(x^{\alpha=k}) \}$ will have a joint multivariate Gaussian distribution, i.e. $z^1_i\sim\mathcal{GP}(\mu^1,K^1)$.</p>
<blockquote>
<p>$\texttt{Note}:$ The expectation and the covariance are independent of $i$, because <em>a priori</em> there is no knowledge that the output varies from the position of neurons. The same for $\sigma^2_b$ and $\sigma^2_w$.</p>
</blockquote>
<p>Moreover, because the expectation of parameters ($W$ and $b$) is null <em>a priori</em>, $\mu^1$ is then null as well and</p>
<script type="math/tex; mode=display">
\begin{aligned}
    K^1(x, x') =&\, \mathbb{E}\left[z^1_i(x) z^1_i(x') \right] \\
               =&\, \sigma^2_b + \sigma^2_w \mathbb{E}\left[x^1_i(x) x^1_i(x') \right] \\
               =&\, \sigma^2_b + \sigma^2_w \mathbb{C}(x, x'),
\end{aligned}</script><p>where $\mathbb{C}(x,x’)$ is an integral against $W^0$ and $b^0$, as seen in <a href="http://www.cs.toronto.edu/~radford/bnn.book.html" target="_blank" rel="noopener">Bayesian Learning for Neural Networks</a>.</p>
<h2 id="GP-and-Deep-NN"><a href="#GP-and-Deep-NN" class="headerlink" title="GP and Deep NN"></a>GP and Deep NN</h2><p>Generalize the post-nonlinearity and the post-affine in a deep NN as</p>
<script type="math/tex; mode=display">
z^l_i(x) = b^l_i + \sum_{j=1}^{N_1} W^l_{ij}x^l_j(x),\;\;\;\; x^l_j(x) = \phi\left(z^{l-1}_j(x) \right).</script><p>Similar with the single-layer case, $z^l_i\sim\mathcal{GP}(0,K^l)$, with</p>
<script type="math/tex; mode=display">
\begin{aligned}
    K^l(x, x') =&\, \mathbb{E}\left[z^l_i(x) z^l_i(x') \right] \\
               =&\, \sigma^2_b + \sigma^2_w \mathbb{E}\left[x^l_i(x) x^l_i(x') \right] \\
               =&\, \sigma^2_b + \sigma^2_w \mathbb{E}_{z^{l-1}_i\sim \mathcal{GP}(0, K^{l-1})}\left[\phi(z^{l-1}_i(x) z^{l-1}_i(x')) \right].
\end{aligned}</script><p>As the joint Gaussian distribution is described with $K^l(x,x)$, $K^l(x,x’)$ and $K^l(x’,x’)$, the covariance can be rewritten as</p>
<script type="math/tex; mode=display">
K^l(x, x') = \sigma^2_b + \sigma^2_w F_\phi \left(K^{l-1}(x, x), K^{l-1}(x, x'), K^{l-1}(x', x') \right).</script><p>For the beginning of this iterative series of GP, note $W_{ij}^0$, $b^0_j$ and $K^0$, and then</p>
<script type="math/tex; mode=display">
K^0(x, x') = \mathbb{E}\left[z^0_j(x) z^0_j(x') \right] = \sigma^2_b + \sigma^2_w \cdot \frac{\langle x, x' \rangle}{N^D}.</script><p>Therefore, the each layer (with infinity of neurons) of the deep NN is equivalent to a Gaussian Process.</p>
<h2 id="Bayesian-Training"><a href="#Bayesian-Training" class="headerlink" title="Bayesian Training"></a>Bayesian Training</h2><p>Given a dataset $\mathcal{D}=\{(x^1,t^1),…,(x^n,t^n) \}$, the model $z(.)$ is supposed to make prediction for a test sample $x^*$. In Bayesian training process, the prediction is over a distribution as</p>
<script type="math/tex; mode=display">
\begin{aligned}
    p(z^* | x^*, \mathcal{D}) =&\, \int p(z^* | x^*, z, x) p(z | \mathcal{D}) dz \\
                              =&\, \int \frac{p(z^*, z | x^*, x)}{p(z | x^*, x)} p(z | \mathcal{D}) dz \\
                              =&\, \int p(z^*, z | x^*, x)\frac{p(z | t, x)}{p(z | x)}  dz \\
                              =&\, \int p(z^*, z | x^*, x)\frac{p(z, t | x)}{p(z | x) p(t | x)}  dz \\
                              =&\, \int p(z^*, z | x^*, x)\frac{p(t | z, x)}{p(t | x)}  dz \\
                              =&\, \frac{1}{p(t)} \int p(z^*, z | x^*, x)p(t | z) dz,
\end{aligned}</script><p>where $t|z\sim\mathcal{N}(0, \sigma^2_\epsilon)$ due to a noise effect added to the prediction.</p>
<p>Since</p>
<script type="math/tex; mode=display">
z^*, z | x^*, x \sim \mathcal{GP}(0,K),</script><p>where</p>
<script type="math/tex; mode=display">
K = \left[
\begin{matrix}
    K_{\mathcal{D},\mathcal{D}} & K^T_{x^*, \mathcal{D}} \\
    K_{x^*, \mathcal{D}} & K_{x^*, x^*}
\end{matrix} \right],</script><p>the integral can be calculated analytically, resulting in </p>
<script type="math/tex; mode=display">
z* | \mathcal{D}, x^* \sim \mathcal{N}(\bar{\mu}, \bar{K}),</script><p>where</p>
<script type="math/tex; mode=display">
\bar{\mu} = K_{x^*, \mathcal{D}} \left(K_{\mathcal{D},\mathcal{D}} + \sigma^2_\epsilon \mathbb{I}_n \right)^{-1} t,</script><script type="math/tex; mode=display">
\bar{K} = K_{x^*, x^*} - K_{x^*, \mathcal{D}} \left(K_{\mathcal{D},\mathcal{D}} + \sigma^2_\epsilon \mathbb{I}_n \right)^{-1} K^T_{x^*, \mathcal{D}}.</script><p>Therefore, the prediction can be done with any decision function over $z$ <em>a posterior</em>.</p>
<blockquote>
<p>$\texttt{Note}:$ To achieve a high performance, various methods can be applied to optimize the parameters, e.g. cross-validation, gradiant ascent.</p>
</blockquote>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] Lee, J., Bahri, Y., Novak, R., Schoenholz, S. S., Pennington, J., &amp; Sohl-Dickstein, J. (2017). Deep neural networks as gaussian processes.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


		
    
		
			

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/Machine-Learning/Training-Trick/Noise-and-Tikhonov-Regularization/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="RemiC">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Remi's Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Machine-Learning/Training-Trick/Noise-and-Tikhonov-Regularization/" itemprop="url">Noise and Tikhonov Regularization</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-09-10T19:15:24+08:00">
                2018-09-10
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Machine Learning</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/Training-Trick/" itemprop="url" rel="index">
                    <span itemprop="name">Training Trick</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>This text refers to <a href="https://ieeexplore.ieee.org/document/6796505/" target="_blank" rel="noopener">Training with Noise is Equivalent to Tikhonov Regularization</a>.</p>
<h2 id="Preliminary"><a href="#Preliminary" class="headerlink" title="Preliminary"></a>Preliminary</h2><p>Consider a feed-forward neural network mapping input data $\mathbf{x}=(x_1,…,x_D)$ to output $f(\mathbf{x})=(f_1(\mathbf{x}),…,f_C(\mathbf{x}))$, associated with ground truth $\mathbf{t}=(t_1,…,t_C)$. A common choice of loss function is</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \mathcal{L} =&\, \frac{1}{2}\int\int \left\|f(\mathbf{x}) - \mathbf{t} \right\|^2 p(\mathbf{x}, \mathbf{t}) d\mathbf{x}d\mathbf{t} \\
                =&\, \frac{1}{2} \int\int \sum_{k=1}^C \left(f_k(\mathbf{x}) - t_k \right)^2 p(t_k | \mathbf{x})p(\mathbf{x})d\mathbf{x}dt_k.
\end{aligned}</script><blockquote>
<p>$\texttt{Note}:$ Especially, for a finit discrete dataset,</p>
<script type="math/tex; mode=display">
p(\mathbf{x}, \mathbf{t}) = \frac{1}{n}\sum_q (\mathbf{x} - \mathbf{x}^q)(\mathbf{t} - \mathbf{t}^q).</script><p>Then the loss function becomes</p>
<script type="math/tex; mode=display">
\mathcal{L} = \frac{1}{2n}\sum_q \left\|f(\mathbf{x}^q) - \mathbf{t}^q \right\|^2.</script></blockquote>
<h2 id="Tikhonov-Regularization"><a href="#Tikhonov-Regularization" class="headerlink" title="Tikhonov Regularization"></a>Tikhonov Regularization</h2><p>One common way to prevend model $f$ from overfitting is regularizing the original loss function as</p>
<script type="math/tex; mode=display">
\tilde{\mathcal{L}} = \mathcal{L} + \lambda \Omega(f),</script><p>where $\lambda$ is a hyper-parameter balance the bias and variance of the model. For the case of one input $x$ and one output $f(x)$, the class of Tikhonov regularizers takes the form as</p>
<script type="math/tex; mode=display">
\Omega(f) = \sum_{r=0}^R \int_a^b h_r(x) \left(\frac{d^rf}{dx^r} \right)^2 dx,</script><p>where $h_r(.)\ge 0$ for $r=0,…,R-1$ and $h_R(.)&gt;0$.</p>
<h2 id="Noise-Injection"><a href="#Noise-Injection" class="headerlink" title="Noise Injection"></a>Noise Injection</h2><p>Apart from regularized loss function, adding noise to the input data is another well-known approach. In this case, the loss function is</p>
<script type="math/tex; mode=display">
\tilde{\mathcal{L}} = \frac{1}{2}\int\int\int \sum_{k=1}^C \left(f_k(\mathbf{x} + \mathbf{n}) - t_k \right)^2 p(t_k | \mathbf{x})p(\mathbf{x})p(\mathbf{n}) d\mathbf{x}dt_kd\mathbf{n}.</script><p>Expand the model function $f$ <em>w.r.t</em> $\mathbf{n}$,</p>
<script type="math/tex; mode=display">
f_k(\mathbf{x} + \mathbf{n}) = f_k(\mathbf{x}) + \sum_{i=1}^D n_i\frac{\partial f_k}{\partial x_i} + \frac{1}{2}\sum_{i=1}^D\sum_{j=1}^D n_in_j \frac{\partial^2 f_k}{\partial{x_i}\partial{x_j}} + \mathcal{O}(\|\mathbf{n} \|^3).</script><p>The noise distribution is generally chosen to be null on average and uncorrelated between different input elements. Hence,</p>
<script type="math/tex; mode=display">
\int n_i p(\mathbf{n})d\mathbf{n} = 0,</script><script type="math/tex; mode=display">
\int n_i n_j p(\mathbf{n})d\mathbf{n} = \eta^2\delta_{ij},</script><p>where $\eta^2$ is the amplitude of the noise injected.</p>
<p>By using these two properties and assuming small noise, the loss function can be written as</p>
<script type="math/tex; mode=display">
\tilde{\mathcal{L}} = \mathcal{L} + \eta^2\mathcal{L}_r,</script><p>where</p>
<script type="math/tex; mode=display">
\mathcal{L}_r = \frac{1}{2}\int\int \sum_{k=1}^C\sum_{i=1}^D \left(\left(\frac{\partial f_k}{\partial x_i} \right)^2 + \left(f_k(\mathbf{x}) - t_k \right)\frac{\partial^2 f_k}{\partial x_i^2} \right) p(t_k | \mathbf{x})p(\mathbf{x})d\mathbf{x}dt_k.</script><blockquote>
<p>$\texttt{Note}:$ In fact,</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \tilde{\mathcal{L}} =&\, \frac{1}{2}\int \sum_{k=1}^C \left(f_k(\mathbf{x}) + \sum_{i=1}^D n_i\frac{\partial f_k}{\partial x_i} + \frac{1}{2}\sum_{i=1}^D\sum_{j=1}^D n_in_j \frac{\partial^2 f_k}{\partial{x_i}\partial{x_j}} - t_k \right)^2 p(t_k, \mathbf{x}, \mathbf{n}) d(t_k, \mathbf{x}, \mathbf{n}) \\
                        =&\, \frac{1}{2}\int \sum_{k=1}^C \left(f_k(\mathbf{x}) - t_k \right)^2 p(t_k, \mathbf{x}) d(t_k, \mathbf{x}) \\
                         &\,+ \frac{1}{2}\int \sum_{k=1}^C 2\left(f_k(\mathbf{x}) - t_k \right)\left(\sum_{i=1}^D n_i\frac{\partial f_k}{\partial x_i} + \frac{1}{2}\sum_{i=1}^D\sum_{j=1}^D n_in_j \frac{\partial^2 f_k}{\partial{x_i}\partial{x_j}} \right) p(t_k, \mathbf{x}, \mathbf{n}) d(t_k, \mathbf{x}, \mathbf{n}) \\
                         &\,+  \frac{1}{2}\int \sum_{k=1}^C \left(\sum_{i=1}^D n_i\frac{\partial f_k}{\partial x_i} + \frac{1}{2}\sum_{i=1}^D\sum_{j=1}^D n_in_j \frac{\partial^2 f_k}{\partial{x_i}\partial{x_j}} \right)^2 p(t_k, \mathbf{x}, \mathbf{n}) d(t_k, \mathbf{x}, \mathbf{n}) \\
                        =&\, \mathcal{L} \\
                         &\,+ \frac{1}{2}\int \sum_{k=1}^C \left(f_k(\mathbf{x}) - t_k \right)\sum_{i=1}^D\sum_{j=1}^D n_in_j \frac{\partial^2 f_k}{\partial{x_i}\partial{x_j}} p(t_k, \mathbf{x}, \mathbf{n}) d(t_k, \mathbf{x}, \mathbf{n}) \\
                         &\,+ \frac{1}{2}\int \sum_{k=1}^C \left(\sum_{i=1}^D n_i\frac{\partial f_k}{\partial x_i} + \frac{1}{2}\sum_{i=1}^D\sum_{j=1}^D n_in_j \frac{\partial^2 f_k}{\partial{x_i}\partial{x_j}} \right)^2 p(t_k, \mathbf{x}, \mathbf{n}) d(t_k, \mathbf{x}, \mathbf{n}) \\
                        =&\, \mathcal{L} \\
                         &\, + \frac{\eta^2}{2}\int \sum_{k=1}^C \left(f_k(\mathbf{x}) - t_k \right)\sum_{i=1}^D \frac{\partial^2 f_k}{\partial{x_i}\partial{x_j}} p(t_k, \mathbf{x}) d(t_k, \mathbf{x}) \\
                         &\, + \frac{\eta^2}{2} \int \sum_{k=1}^C \sum_{i=1}^D \left(\frac{\partial f_k}{\partial x_i} \right)^2 p(t_k, \mathbf{x}) d(t_k, \mathbf{x}) + \mathcal{O}(\|n\|^3) \\
                        =&\, \mathcal{L} + \eta^2\mathcal{L}_r,
\end{aligned}</script></blockquote>
<h2 id="Equivalence"><a href="#Equivalence" class="headerlink" title="Equivalence"></a>Equivalence</h2><p>To simplify the expressions, define</p>
<script type="math/tex; mode=display">
\langle t_k | \mathbf{x} \rangle = \int t_k p(t_k | \mathbf{x}) dt_k,</script><script type="math/tex; mode=display">
\langle t_k^2 | \mathbf{x} \rangle = \int t_k^2 p(t_k | \mathbf{x}) dt_k.</script><p>Then the original loss can be rewritten as</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \mathcal{L} =&\, \frac{1}{2}\sum_{k=1}^C\int \left(f_k(\mathbf{x}) - \langle t_k | \mathbf{x} \rangle \right)^2 p(\mathbf{x}) d\mathbf{x} \\
                 &\,+ \frac{1}{2}\sum_{k=1}^C\int \langle t_k^2 | \mathbf{x} \rangle - \langle t_k | \mathbf{x} \rangle^2 p(\mathbf{x}) d(\mathbf{x}).
\end{aligned}</script><p>The minimum is reached when $f_k(\mathbf{x})=\langle t_k | \mathbf{x} \rangle$. Therefore, the optimal for the total loss will have the form as</p>
<script type="math/tex; mode=display">
f^*_k(\mathbf{x}) = \langle t_k | \mathbf{x} \rangle + \mathcal{O}(\eta^2).</script><p>Note that the regularization term becomes</p>
<script type="math/tex; mode=display">
\mathcal{L}_r = \frac{1}{2}\int\sum_{k=1}^C\sum_{i=1}^D \left(\left(\frac{\partial f_k}{\partial x_i} \right)^2 + \left(f_k(\mathbf{x}) - \langle t_k | \mathbf{x} \rangle \right)\frac{\partial^2 f_k}{\partial x_i^2} \right)p(\mathbf{x})d\mathbf{x},</script><p>where the second term vanishes to the order of $\eta^2$. Given that the noise is small, indicating small $\eta^2$, the second term can be removed. Then the regularization term becomes</p>
<script type="math/tex; mode=display">
\mathcal{L}_r = \frac{1}{2}\int\sum_{k=1}^C\sum_{i=1}^D \left(\frac{\partial f_k}{\partial x_i} \right)^2 p(\mathbf{x})d\mathbf{x}.</script><blockquote>
<p>$\texttt{Note}:$ For the discrete dataset, the regularization can be written as</p>
<script type="math/tex; mode=display">
\mathcal{L}_r = \frac{1}{2}\sum_q\sum_{k=1}^C\sum_{i=1}^D \left(\frac{\partial f_k}{\partial x_i^q} \right)^2.</script></blockquote>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] Bishop, C. M. (1995). Training with noise is equivalent to tikhonov regularization. Neural Computation, 7(1), 108-116.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


		
    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">RemiC</p>
              <p class="site-description motion-element" itemprop="description">I'm description.</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">17</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">7</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">20</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/remicongee" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">RemiC</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
  


  

  

</body>
</html>
