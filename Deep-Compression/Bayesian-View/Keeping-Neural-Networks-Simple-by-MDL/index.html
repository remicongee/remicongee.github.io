<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="MDL,Bits-Back Argument," />










<meta name="description" content="OverviewThis text refers to the paper Keeping Neural Networks Simple by Minimizing the Description Length of the Weights published on COLT 1993, which mainly proposes a view of MDL over simplifying ne">
<meta name="keywords" content="MDL,Bits-Back Argument">
<meta property="og:type" content="article">
<meta property="og:title" content="Keeping Neural Networks Simple by MDL">
<meta property="og:url" content="http://yoursite.com/Deep-Compression/Bayesian-View/Keeping-Neural-Networks-Simple-by-MDL/index.html">
<meta property="og:site_name" content="Remi&#39;s Hexo">
<meta property="og:description" content="OverviewThis text refers to the paper Keeping Neural Networks Simple by Minimizing the Description Length of the Weights published on COLT 1993, which mainly proposes a view of MDL over simplifying ne">
<meta property="og:locale" content="default">
<meta property="og:updated_time" content="2018-07-27T11:29:27.520Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Keeping Neural Networks Simple by MDL">
<meta name="twitter:description" content="OverviewThis text refers to the paper Keeping Neural Networks Simple by Minimizing the Description Length of the Weights published on COLT 1993, which mainly proposes a view of MDL over simplifying ne">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>

<script>
    (function(){
        if(''){
            if (prompt('Password required') !== ''){
                alert('Wrong!');
                history.back();
            }
        }
    })();
</script>



  <link rel="canonical" href="http://yoursite.com/Deep-Compression/Bayesian-View/Keeping-Neural-Networks-Simple-by-MDL/"/>





  <title>Keeping Neural Networks Simple by MDL | Remi's Hexo</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Remi's Hexo</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/Deep-Compression/Bayesian-View/Keeping-Neural-Networks-Simple-by-MDL/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="RemiC">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Remi's Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Keeping Neural Networks Simple by MDL</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-07-10T18:50:00+08:00">
                2018-07-10
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-Compression/" itemprop="url" rel="index">
                    <span itemprop="name">Deep Compression</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-Compression/Bayesian-View/" itemprop="url" rel="index">
                    <span itemprop="name">Bayesian View</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>This text refers to the paper <a href="https://dl.acm.org/citation.cfm?doid=168304.168306" target="_blank" rel="noopener">Keeping Neural Networks Simple by Minimizing the Description Length of the Weights</a> published on COLT 1993, which mainly proposes a view of MDL over simplifying neural networks.</p>
<h2 id="MDL"><a href="#MDL" class="headerlink" title="MDL"></a>MDL</h2><p>When fitting data models to some data, a more complex model often performs better on training data but may be overfitting. So it is in need of methods to decide when extra complexity of the model is not worth the improvement in the data-fit. Minimum Description Length (<em>MDL</em>) Principle is proposed in [2], asserting that the best model is the one that minimizes the combined cost of decribing the model and the misfit between the model and the data. For example, in a supervised classification task, the model cost is the number of bits describing the model, and the data misfit cost is the number of bits describing the descrepency between model output and the ground truth.</p>
<blockquote>
<p>$\texttt{Note}:$ The principle could be viewed in a simple communication model as</p>
<script type="math/tex; mode=display">
input\;\; X = x</script><script type="math/tex; mode=display">
sender (W = w, Y = y)\;\;\;\; \xrightarrow{\Delta y,\, w}\;\;\;\; receiver</script></blockquote>
<h3 id="Coding"><a href="#Coding" class="headerlink" title="Coding"></a>Coding</h3><p>In order to compute communication cost, the first question is how to define the number of bits in need. For simplification, data misfit cost is discussed as an example for illustration.</p>
<p>Clearly, if the data misfits are real numbers, an inifinite amount of information is needed to convey them. Hence, a simple quantization is included so that the real numbers within a width of $t$ will be degraded to one number.</p>
<p>After quantization, the misfits $\Delta y$ are further coded into bits with length $-\log\mathbb{P}(\Delta Y=\Delta y)$. For example, let the misfit follow a Gaussian centralized:</p>
<script type="math/tex; mode=display">
\Delta Y \sim \mathcal{N}(0,\sigma^2)\;\; \iff\;\; \hat{Y}|Y \sim \mathcal{N}(y,\sigma^2).</script><p>Therefore,</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \mathbb{P}(\Delta Y = \Delta y|Y = y) =&\, \mathbb{P}(\hat{Y} = \hat{y}, \hat{y} = y + \Delta y|Y = y) \\
                                          =&\, \int_{\hat{Y}\in\mathcal{B}(\hat{y},t)} \frac{1}{\sigma\sqrt{2\pi}}\exp\left(-\frac{(\hat{Y} - y)^2}{2\sigma^2} \right)d\hat{Y} \\
                       \approx&\, \frac{t}{\sigma\sqrt{2\pi}}\exp\left(-\frac{(\hat{y} - y)^2}{2\sigma^2} \right),
\end{aligned}</script><p>where the approximation is valid if $t\ll\sigma$. Then the misfit cost (on average), i.e. the number of descrepency bits, becomes</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \mathcal{C}^D =&\, \mathbb{E}_Y\left[-\log\mathbb{P}(\Delta Y = \Delta y|Y = y) \right] \\
                  \approx&\, -\frac{1}{N}\sum_{i=1}^N \left(\log t -\frac{(\hat{y_i} - y_i)^2}{2\sigma^2} \right) + \log\sigma,
\end{aligned}</script><p>where the approximation is induced by Monte Carlo Sampling.</p>
<h2 id="Bits-Back-Argument"><a href="#Bits-Back-Argument" class="headerlink" title="Bits-Back Argument"></a>Bits-Back Argument</h2><p>The sender trains the model with data so that it learns the posterior distribution of weights, $q$. However, for sending precise weights to the receiver, the sender may need some random bits (e.g. random seeds) to collapse $q$ to a number. But note that, since the receiver receives the misfits, weights and shares the input with the sender, it is able to train the model itself, which means the receiver can know $q$ as well. In other words, the knowledge of $q$ does mainly come from $w$ once it has received misfits. Furthermore, the information given by $w$ may be rebundant, leading to unnecessary cost. Hence, for computing the necessary cost, it suffers to substract the cost of sending $w$ by the unnecessary cost.</p>
<h3 id="Weight-Cost"><a href="#Weight-Cost" class="headerlink" title="Weight Cost"></a>Weight Cost</h3><p>Different from data, when model is fixed, weights are often preferred to be certain settings. This refers to, in fact, the prior of weight, $p(w)$. In this case, the sender and the receiver will share this knowledge. Given that, the sender can send $w$ by coding according to this prior (seen the section above). Hence, the cost of sending weights will be</p>
<script type="math/tex; mode=display">
\mathcal{C}^W = -\log\left(tp(w) \right) = -\log t - \log p(w).</script><h3 id="Random-Bits"><a href="#Random-Bits" class="headerlink" title="Random Bits"></a>Random Bits</h3><p>Actually, to sample $w$ from $q$, the sender needs some random bits (e.g. random seeds). On the other hand, the receiver can know these bits by computing inversely, i.e. from $w$ and $q$ to the random bits.</p>
<blockquote>
<p>$\texttt{Note}:$ In computer literature, there is no, as so far, real but <strong>pseudo</strong> random numbers. In most case, the “random” numbers is generated by certain iterative algorithm and based on a real random number, which is often given by hand, namely random seed.</p>
<p><a href="https://en.wikipedia.org/wiki/Random_seed" target="_blank" rel="noopener">&gt;GO TO WIKI&lt;</a></p>
</blockquote>
<p>However, these random bits are not necessary, because 1) they are not features of the model; 2) they can be generated on the receiver side as well. Therfore, we can conclude that the unncessary information is exactly the random bits. Given that these bits can be restored from $q$ and $w$, the cost of sending them will be the number of bits coded according to $q$:</p>
<script type="math/tex; mode=display">
\mathcal{C}^R = -\log\left(tq(w) \right) = -\log t - \log q(w).</script><h3 id="Substraction"><a href="#Substraction" class="headerlink" title="Substraction"></a>Substraction</h3><p>Therefore, by computing the expected value, the necessary cost to describe the model is</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \mathcal{C}^M =&\, \mathbb{E}_q\left[\mathcal{C}^W - \mathcal{C}^R \right] \\
                =&\, \int q(w) \left(\log q(w) - \log p(w) \right)dw \\
                =&\, -\int q(w) \log\frac{p(w)}{q(w)}dw \\
                =&\, KL(q(w)||p(w))
\end{aligned}</script><p>This process can be compared as a special transaction between the sender and the receiver:</p>
<script type="math/tex; mode=display">
input\;\; X = x,\;\; prior\;\; p(w)</script><script type="math/tex; mode=display">
sender (W \sim q, Y = y)\;\;\;\; \xrightarrow[w\,=\,g(r,\,q)]{\Delta y}\;\;\;\; receiver</script><script type="math/tex; mode=display">
sender (W \sim q, Y = y)\;\;\;\; \xleftarrow{r}\;\;\;\; receiver(W \sim q, Y = f(w,x) + \Delta y)</script><p>where $g(.)$ is some random number generation algorithm, $r$ random bits. </p>
<blockquote>
<p>$\texttt{Note}:$ The receiver sends random bits $r$ back to the sender, because they are not necessary for description of the model. Hence, this argument is named by “<em>bits back</em>“.</p>
</blockquote>
<h2 id="With-Bayesian-Inference"><a href="#With-Bayesian-Inference" class="headerlink" title="With Bayesian Inference"></a>With Bayesian Inference</h2><p>Combine the cost of data misfits and model description, the total cost is</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \mathcal{C} =&\, \mathcal{C}^D + \mathcal{C}^M \\
                =&\, \mathbb{E}_Y\left[-\log\mathbb{P}(\Delta Y|Y) \right] + KL(q(w)||p(w)).
\end{aligned}</script><p>To minimize the misfit term, it suffers that $\Delta Y = \hat{y} - y$ happens as frequently as possible, no matter how large it is. However, since it is always expected that $\Delta Y\rightarrow 0$, the first term can be further transformed:</p>
<script type="math/tex; mode=display">
\mathbb{E}_Y\left[-\log\mathbb{P}(\Delta Y|Y) \right] \xrightarrow{\Delta Y\, \rightarrow\, 0} \mathbb{E}_Y\left[-\log\mathbb{P}(\hat{Y} = Y|W,X) \right] \equiv \mathbb{E}_Y\left[-\log\mathbb{P}(Y|W = w,X) \right].</script><p>Hence,</p>
<script type="math/tex; mode=display">
\mathcal{C} = -\left(\mathbb{E}_Y\left[\log\mathbb{P}(Y|W = w,X) \right] - KL(q(w)||p(w)) \right).</script><p>To minimize the cost, it is equivalent to maximize</p>
<script type="math/tex; mode=display">
\mathcal{L} = \mathbb{E}_Y\left[\log\mathbb{P}(Y|W = w,X) \right] - KL(q(w)||p(w)),</script><p>which is exactly the <strong>evidence lower bound</strong> of Bayesian inference.</p>
<blockquote>
<p>$\texttt{Note}:$ In most case, the first term is approximated by Monte Carlo Sampling so that</p>
<script type="math/tex; mode=display">
\mathcal{L} \approx \frac{1}{N}\sum_{i=1}^N \log\mathbb{P}(\hat{Y} = y_i|W = w,X = x_i) - KL(q(w)||p(w))</script></blockquote>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] Hinton, G. E., &amp; van Camp, D. Keeping neural networks simple by minimising the description length of weights. 1993. In Proceedings of COLT-93 (pp. 5-13).</p>
<p>[2] Rissanen, J. (1986). Stochastic complexity and modeling. The annals of statistics, 1080-1100.</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/MDL/" rel="tag"># MDL</a>
          
            <a href="/tags/Bits-Back-Argument/" rel="tag"># Bits-Back Argument</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/Deep-Compression/Bayesian-View/Structured-Bayesian-Pruning-via-Log-Normal-Multiplicative-Noise/" rel="next" title="Structured Bayesian Pruning via Log-Normal Multiplicative Noise">
                <i class="fa fa-chevron-left"></i> Structured Bayesian Pruning via Log-Normal Multiplicative Noise
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/Machine-Learning/Training-Trick/Use-of-Noise-in-Training/" rel="prev" title="Use of Noise in Training">
                Use of Noise in Training <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">RemiC</p>
              <p class="site-description motion-element" itemprop="description">I'm description.</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">11</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">7</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">16</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/remicongee" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Overview"><span class="nav-number">1.</span> <span class="nav-text">Overview</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#MDL"><span class="nav-number">2.</span> <span class="nav-text">MDL</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Coding"><span class="nav-number">2.1.</span> <span class="nav-text">Coding</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Bits-Back-Argument"><span class="nav-number">3.</span> <span class="nav-text">Bits-Back Argument</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Weight-Cost"><span class="nav-number">3.1.</span> <span class="nav-text">Weight Cost</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Random-Bits"><span class="nav-number">3.2.</span> <span class="nav-text">Random Bits</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Substraction"><span class="nav-number">3.3.</span> <span class="nav-text">Substraction</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#With-Bayesian-Inference"><span class="nav-number">4.</span> <span class="nav-text">With Bayesian Inference</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Reference"><span class="nav-number">5.</span> <span class="nav-text">Reference</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">RemiC</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
  


  

  

</body>
</html>
