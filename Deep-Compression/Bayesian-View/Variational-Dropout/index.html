<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Gaussian Dropout,Network Sparsity," />










<meta name="description" content="OverviewThis text is mainly about dropout as a variational method, referring to the paper Fast Dropout Training, Variational Dropout and the Local Reparameterization Trick and Variational Dropout Spar">
<meta name="keywords" content="Gaussian Dropout,Network Sparsity">
<meta property="og:type" content="article">
<meta property="og:title" content="Variational Dropout">
<meta property="og:url" content="http://yoursite.com/Deep-Compression/Bayesian-View/Variational-Dropout/index.html">
<meta property="og:site_name" content="Remi&#39;s Hexo">
<meta property="og:description" content="OverviewThis text is mainly about dropout as a variational method, referring to the paper Fast Dropout Training, Variational Dropout and the Local Reparameterization Trick and Variational Dropout Spar">
<meta property="og:locale" content="default">
<meta property="og:updated_time" content="2018-07-27T00:59:12.115Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Variational Dropout">
<meta name="twitter:description" content="OverviewThis text is mainly about dropout as a variational method, referring to the paper Fast Dropout Training, Variational Dropout and the Local Reparameterization Trick and Variational Dropout Spar">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>

<script>
    (function(){
        if(''){
            if (prompt('Password required') !== ''){
                alert('Wrong!');
                history.back();
            }
        }
    })();
</script>



  <link rel="canonical" href="http://yoursite.com/Deep-Compression/Bayesian-View/Variational-Dropout/"/>





  <title>Variational Dropout | Remi's Hexo</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Remi's Hexo</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/Deep-Compression/Bayesian-View/Variational-Dropout/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="RemiC">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Remi's Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Variational Dropout</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-06-30T18:50:36+08:00">
                2018-06-30
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-Compression/" itemprop="url" rel="index">
                    <span itemprop="name">Deep Compression</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-Compression/Bayesian-View/" itemprop="url" rel="index">
                    <span itemprop="name">Bayesian View</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>This text is mainly about dropout as a variational method, referring to the paper <a href="https://nlp.stanford.edu/pubs/sidaw13fast.pdf" target="_blank" rel="noopener">Fast Dropout Training</a>, <a href="https://arxiv.org/abs/1506.02557" target="_blank" rel="noopener">Variational Dropout and the Local Reparameterization Trick</a> and <a href="https://arxiv.org/abs/1701.05369" target="_blank" rel="noopener">Variational Dropout Sparsifies Deep Neural Networks</a>.</p>
<p>Say a fully-connected layer with input $A\in M_{K,L}$ and output inactivated $B\in M_{K,N}$, the dropout can be expressed as</p>
<script type="math/tex; mode=display">
B = (A \circ\xi)W,</script><p>where $\circ$ is Hadamard product, $\xi_{ij}\sim p(\xi_{ij})$ is a noise and $W\in M_{L,N}$ is weight matrix. Through this way, $W$ is less likely to overfit to the training data. Commonly, $p(\xi_{ij})$ includes a parameter named as <em>dropout rate</em>.</p>
<blockquote>
<p>$\texttt{Question}:$ Is this conclusion also valid for <em>CNN</em> kernels ?</p>
</blockquote>
<h2 id="Gaussian-Dropout"><a href="#Gaussian-Dropout" class="headerlink" title="Gaussian Dropout"></a>Gaussian Dropout</h2><p>Gaussian dropout refers to a Gaussian noise, $\xi\sim\mathcal{N}(1,\alpha)$ added to the training data. Compared with a binary dropout $\xi\sim\mathcal{B}(p)$, $\alpha=p/(1-p)$. Intuitionally, if $\alpha$ is large, the noise tends to be sampled uniformly from $\mathbb{R}$, which means even when the input feature is discriminant, the correspondant neuron performs the same as the Signal-Noise-Ratio (SNR) is null. Therefore, the larger $\alpha$ gets, the more possible the neuron gets dropped.</p>
<p>From the view of mathmatics, Gaussian dropout is an approximation (or limit) of binary dropout. Let $x$ be input, $z\sim\mathcal{B}(p)$ the dropout noise, $w$ the weights. Say it is a classification task and modeled by logistic regression</p>
<script type="math/tex; mode=display">
\mathbb{P}(y|x,w,z) = \sigma(w^TD_zx),</script><p>where $\sigma(.)$ is sigmoid function, $D_z$ a matrix diagonalized by $z$. It could be further written as $\sum_i^m w_iz_ix_i$. At training stage, weights are updated, though often in batches, as $x$ is fixed. In this case, the only random variable is $z$. According to Lyapunov central limit theorem,</p>
<script type="math/tex; mode=display">
\sum_i^m w_iz_ix_i\xrightarrow[m\rightarrow+\infty]{d}S\sim\mathcal{N}(\mu_S,\sigma^2_S),</script><p>where</p>
<script type="math/tex; mode=display">
\mu_S=(1-p)\sum_i^mw_ix_i,\;\sigma^2_S=p(1-p)\sum_i^mw^2_ix^2_i.</script><blockquote>
<p>$\texttt{Theorem}:$ <strong>Lyapunov Central Limit Theorem</strong> <br><br>Suppose $\{X_1,X_2,…,X_n\}$ is a sequence of independent variables, each with finite expected value $\mu_i$ and variance $\sigma^2_i$. Define</p>
<script type="math/tex; mode=display">
s^2_n = \sum_{i=1}^n\sigma^2_i.</script><p>If for some $\delta&gt;0$, <em>Lyapunov’s condition</em></p>
<script type="math/tex; mode=display">
\lim_{n\rightarrow+\infty}\frac{1}{s^{2+\delta}_n}\sum_{i=1}^n\mathbb{E}\left[|X_i - \mu_i|^{2+\delta} \right] = 0</script><p>is satisfied, then a sum of $\frac{X_i-\mu_i}{s_n}$ converges to a standard Gaussian random variable, as $n$ goes to infinity:</p>
<script type="math/tex; mode=display">
\frac{1}{s_n}\sum_{i=1}^n\left(X_i - \mu_i \right)\xrightarrow{d}\mathcal{N}(0,1).</script><p><a href="https://en.wikipedia.org/wiki/Central_limit_theorem" target="_blank" rel="noopener">&gt; GO TO WIKI &lt;</a></p>
</blockquote>
<p>For each training sample, the objective is maximizing the probability of predicting correctly. Therefore,</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \mathbb{E}_z[\log\mathbb{P}(y|\sum_i^mw_iz_ix_i)] \approx\,& \mathbb{E}_S[\log\mathbb{P}(y|S)] \\
    =\,& \mathbb{E}_{v:v_i\sim\mathcal{N}(\mu_i,\mu_i^2\alpha)}[\log\mathbb{P}(y|v^Tx)].
\end{aligned}</script><p>In fact, the equivalence is valid because $S$ can be reformed as a linear combination of Gaussian variables which are independent:</p>
<script type="math/tex; mode=display">
S = \sum_i^m x_iv_i.</script><blockquote>
<p>$\texttt{Note}:$ To justify the equivalence is valid, the combination and $S$ should have the same expectation and variance:</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \mathbb{E}\left[\sum_i^m x_iv_i\right] =& \sum_i^mx_i\mathbb{E}[v_i] \\
                                =& \sum_i^mx_i\mu_i.
\end{aligned}</script><p>Hence, it is necessary that $\mu_i=(1-p)w$.</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \mathbb{V}ar\left[\sum_i^m x_iv_i\right] =& \sum_i^mx^2_i\mathbb{V}ar\left[v_i \right] \\
                                             =& \sum_i^mx^2_i\sigma^2_i.
\end{aligned}</script><p>Hence, it is necessary that $\sigma^2_i=p(1-p)w^2$.</p>
<p>Given $\mu_i=(1-p)w$, then $\sigma^2_i=\mu_i^2\alpha$, with $\alpha=p/(1-p)$.</p>
</blockquote>
<p>The optimization can be therefore interpreted as inference of $v\sim\mathcal{N}(\mu_i,\mu_i^2\alpha)$ indexed by $\mu_i$ instead of $w$. In terms of variational inference, propose $q_\phi(v_i)=\mathcal{N}(v|\mu_i,\mu_i^2\alpha)$ as the variational posterior and $p(v)$ as prior, the evidence lower bound is hence</p>
<script type="math/tex; mode=display">
\mathcal{L}(\phi) = \mathbb{E}_{q_\phi}\left[\log\mathbb{P}(y|v^Tx) \right] - KL(q_\phi(v)||p(v)).</script><p>The first term can be approximated by unbiased Monte Carlo sampling as $\mathcal{L}^{SGVB}$ mentioned in [1]. The second term is regularization. It can be noted that when $\alpha$ is fixed, variational dropout should degrade to Gaussian dropout, which means the KL term is expected to be independent of $\mu_i$. This property is justified as long as the noise is sampled independently for each element of inputs.</p>
<p>In [1] and [2], another form of dropout is proposed. The noise is sampled for each weight parameter, instead of element of inputs. The obejective of this change is to retain the dependency among weights, which are ignored in the paper referred to in this text [3]. In this case, the improper log-uniform prior is the only choice satisfying the property mentioned above.</p>
<blockquote>
<p>$\texttt{Note}:$ In [1], it is supposed that $v=z\mu$ and $z\sim\mathcal{N}(1,\alpha)$, then the KL term becomes</p>
<script type="math/tex; mode=display">
\begin{aligned}
    KL\left(q_\phi(v)||p(v) \right) =&\, -\int \frac{1}{|\mu|\sqrt{2\pi\alpha}}\exp\left(-\frac{|v - \mu|^2}{2\alpha\mu^2} \right) \log\frac{p(v)}{\frac{1}{|\mu|\sqrt{2\pi\alpha}}\exp\left(-\frac{|v - \mu|^2}{2\alpha\mu^2} \right)}dv \\
                                    =&\, -\int \frac{1}{\sqrt{2\pi\alpha}}\exp\left(-\frac{|z - 1|^2}{2\alpha} \right) \log\frac{p(z\mu)}{\frac{1}{|\mu|\sqrt{2\pi\alpha}}\exp\left(-\frac{|z - 1|^2}{2\alpha} \right)}dz,
\end{aligned}</script><p>where $dv=|\mu|dz$.<br>Hence, it is necessary that $p(z\mu)\propto\frac{1}{|\mu|}$ so that KL term is independent of $\mu$. Therefore,</p>
<script type="math/tex; mode=display">
p(z) \propto \frac{1}{|z|}.</script></blockquote>
<p>However, KL term from the variational posterior to the prior is still intractable. Therfore, different approximations are given in [1] and [2]. And [2] proposed a form of approximation that is more robust for a larger scale of $\alpha$.</p>
<blockquote>
<p>$\texttt{Question}:$ According to <a href="https://arxiv.org/abs/1711.02989" target="_blank" rel="noopener">Variational Gaussian Dropout is not Bayesian</a>, variational Gaussian dropout is pseudo Bayesian inference.</p>
</blockquote>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] Kingma, D. P., Salimans, T., &amp; Welling, M. (2015). Variational dropout and the local reparameterization trick. In Advances in Neural Information Processing Systems (pp. 2575-2583).</p>
<p>[2] Molchanov, D., Ashukha, A., &amp; Vetrov, D. (2017). Variational dropout sparsifies deep neural networks. arXiv preprint arXiv:1701.05369.</p>
<p>[3] Wang, S., &amp; Manning, C. (2013, February). Fast dropout training. In international conference on machine learning (pp. 118-126).</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Gaussian-Dropout/" rel="tag"># Gaussian Dropout</a>
          
            <a href="/tags/Network-Sparsity/" rel="tag"># Network Sparsity</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/Deep-Compression/Bayesian-View/Bayesian-Compression-for-Deep-Learning/" rel="next" title="Bayesian Compression for Deep Learning">
                <i class="fa fa-chevron-left"></i> Bayesian Compression for Deep Learning
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/Deep-Compression/Bayesian-View/Structured-Bayesian-Pruning-via-Log-Normal-Multiplicative-Noise/" rel="prev" title="Structured Bayesian Pruning via Log-Normal Multiplicative Noise">
                Structured Bayesian Pruning via Log-Normal Multiplicative Noise <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">RemiC</p>
              <p class="site-description motion-element" itemprop="description">I'm description.</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">8</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">6</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">11</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/remicongee" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Overview"><span class="nav-number">1.</span> <span class="nav-text">Overview</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Gaussian-Dropout"><span class="nav-number">2.</span> <span class="nav-text">Gaussian Dropout</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Reference"><span class="nav-number">3.</span> <span class="nav-text">Reference</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">RemiC</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
  


  

  

</body>
</html>
