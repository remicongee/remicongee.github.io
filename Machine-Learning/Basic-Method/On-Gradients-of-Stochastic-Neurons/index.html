<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Stochastic Neurons,Hard Non-linearity," />










<meta name="description" content="OverviewThis text mainly refers to the paper Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation [1]. Regardless of Stochastic Times Smooth (STS) units and Strai">
<meta name="keywords" content="Stochastic Neurons,Hard Non-linearity">
<meta property="og:type" content="article">
<meta property="og:title" content="On Gradients of Stochastic Neurons">
<meta property="og:url" content="http://yoursite.com/Machine-Learning/Basic-Method/On-Gradients-of-Stochastic-Neurons/index.html">
<meta property="og:site_name" content="Remi&#39;s Hexo">
<meta property="og:description" content="OverviewThis text mainly refers to the paper Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation [1]. Regardless of Stochastic Times Smooth (STS) units and Strai">
<meta property="og:locale" content="default">
<meta property="og:updated_time" content="2018-12-11T10:40:40.872Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="On Gradients of Stochastic Neurons">
<meta name="twitter:description" content="OverviewThis text mainly refers to the paper Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation [1]. Regardless of Stochastic Times Smooth (STS) units and Strai">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>

<script>
    (function(){
        if(''){
            if (prompt('Password required') !== ''){
                alert('Wrong!');
                history.back();
            }
        }
    })();
</script>



  <link rel="canonical" href="http://yoursite.com/Machine-Learning/Basic-Method/On-Gradients-of-Stochastic-Neurons/"/>





  <title>On Gradients of Stochastic Neurons | Remi's Hexo</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Remi's Hexo</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/Machine-Learning/Basic-Method/On-Gradients-of-Stochastic-Neurons/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="RemiC">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Remi's Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">On Gradients of Stochastic Neurons</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-12-06T21:06:26+08:00">
                2018-12-06
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Machine Learning</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/Basic-Method/" itemprop="url" rel="index">
                    <span itemprop="name">Basic Method</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>This text mainly refers to the paper <a href="https://arxiv.org/abs/1308.3432" target="_blank" rel="noopener">Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation</a> [1]. Regardless of Stochastic Times Smooth (STS) units and Straight-Through Estimator (STE), the technique detail of an unbiased estimator of gradient for stochastic binary neurons is discussed in this text.</p>
<h2 id="Stochastic-Binary-Neurons"><a href="#Stochastic-Binary-Neurons" class="headerlink" title="Stochastic Binary Neurons"></a>Stochastic Binary Neurons</h2><p>Considering hard non-linearity as activation function in neural networks, the gradients are normaly incomputable, but can be estimated with the help of stochaistic pertubation, which is actually a random noise multiplied on neurons, e.g. dropout. These kind of neurons are referred as stochastic neurons in this text, and become more insteresting in binary case, i.e. the output activated of neurons is either 0 or 1, namely stochastic binary neurons. One may ask for the strategy to binarize the outputs, which is proposed to be based on a sigmoid probability. For illustration, say a fully-connected layer with input $x$, weight $W$, bias $b$ and output activated $h$, then</p>
<script type="math/tex; mode=display">
h_i = f(a_i, z_i) = \mathbb{I}_{z_i \lt \sigma(a_i)},\;\; a_i = b_i + \sum_j W_{ij}x_j,</script><p>where $z_i\sim \mathcal{U}[0,1]$ is uniform and $\sigma(u)=1/(1+\exp(-u))$ is sigmoid function.</p>
<h2 id="Unbiased-Estimator-for-Gradient"><a href="#Unbiased-Estimator-for-Gradient" class="headerlink" title="Unbiased Estimator for Gradient"></a>Unbiased Estimator for Gradient</h2><p>Let $\mathcal{L}$ be the objective function, then computing directly the gradient of $\mathcal{L}$ with regard to parameters are intractable. However, an unbiases estimator is still feasible. Note that accordint to the chain rule, i.e.</p>
<script type="math/tex; mode=display">
\frac{\partial\mathcal{L}}{\partial W_{ij}} = \frac{\partial\mathcal{L}}{\partial a_i}\cdot \frac{\partial a_i}{\partial W_{ij}},</script><p>the first term on the right is the only one in need to estimate, whose expectation is thus in need if the estimation is supposed to be unbiased. </p>
<p>Additionally, among advances of recent network designs, dropout is commonly included, which is stochastic as well as $z$. In this case, these random parameters should also be considered during the estimation for gradient. Note that this dropout noise does not require updates and is viewed as fixed once sampled when forwarding. Therefore, the expectation is conditionned on the random parameters if they influence $a$. For clarity, let $\Gamma=\{z_i\}\bigcup\ c_i\bigcup c_{-i}$ be the set of all random variables divided according to whether they influence $a_i$ as $c_i$ does. Note $\mathcal{L}=\mathcal{L}(h_i,c_i,c_{-i})$.</p>
<p>Now compute the expectation of $L$ conditioned on $c_i$,</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \mathbb{E}\left[\mathcal{L} | c_i \right] =&\, \mathbb{E}_{c_{-i}}\left[\mathbb{E}_{z_i}\left[L | c_i \right] \right] \\
                                    =&\, \mathbb{E}_{c_{-i}}\left[\mathbb{E}_{z_i}\left[h_i\mathcal{L}\left(1, c_i, c_{-i} \right) + (1 - h_i)\mathcal{L}\left(0, c_i, c_{-i} \right) \right] \right] \\
                                    =&\, \mathbb{E}_{c_{-i}}\left[\mathbb{P}\left(h_i=1 | a_i \right)\mathcal{L}\left(1, c_i, c_{-i} \right) + \mathbb{P}\left(h_i=0 | a_i \right)\mathcal{L}\left(0, c_i, c_{-i} \right) \right] \\
                                    =&\, \mathbb{E}_{c_{-i}}\left[\sigma(a_i)\mathcal{L}\left(1, c_i, c_{-i} \right) + \left(1 - \sigma(a_i) \right)\mathcal{L}\left(0, c_i, c_{-i} \right) \right].
\end{aligned}</script><p>Further derive the average gradient,</p>
<script type="math/tex; mode=display">
\begin{aligned}
    g_i = \mathbb{E}\left[\frac{\partial\mathcal{L}}{\partial a_i} | c_i \right] =&\, \frac{\partial\mathbb{E}\left[\mathcal{L} | c_i\right]}{\partial a_i} \\
                                                                     =&\, \mathbb{E}_{c_{-i}}\left[\sigma'(a_i)\mathcal{L}\left(1, c_i, c_{-i} \right) - \sigma'(a_i)\mathcal{L}\left(0, c_i, c_{-i} \right) \right] \\
                                                                     =&\, \mathbb{E}_{c_{-i}}\left[\sigma(a_i)\left(1 - \sigma(a_i) \right)\left(\mathcal{L}\left(1, c_i, c_{-i} \right) - \mathcal{L}\left(0, c_i, c_{-i} \right) \right) \right].
\end{aligned}</script><p>Now consider the estimator</p>
<script type="math/tex; mode=display">
\hat{g}_i = \left(h_i - \sigma(a_i) \right)\mathcal{L}(h_i, c_i, c_{-i}) = h_i\left(1 - \sigma(a_i) \right)\mathcal{L}(1, c_i, c_{-i}) - \sigma(a_i)(1 - h_i)\mathcal{L}(0, c_i, c_{-i}),</script><p>whose expectation is</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \mathbb{E}[\hat{g}_i | c_i] =&\, \mathbb{E}_{c_{-i}, z_i}\left[h_i\left(1 - \sigma(a_i) \right)\mathcal{L}(1, c_i, c_{-i}) - \sigma(a_i)(1 - h_i)\mathcal{L}(0, c_i, c_{-i})\right] \\
                                =&\, \mathbb{E}_{c_{-i}}\left[\sigma(a_i)\left(1 - \sigma(a_i) \right)\mathcal{L}(1, c_i, c_{-i}) - \sigma(a_i)(1 - \sigma(a_i))\mathcal{L}(0, c_i, c_{-i}) \right] \\
                                =&\, \mathbb{E}_{c_{-i}}\left[\sigma(a_i)\left(1 - \sigma(a_i) \right)\left(\mathcal{L}(1, c_i, c_{-i}) - \mathcal{L}(0, c_i, c_{-i}) \right) \right],
\end{aligned}</script><p>which is the same as that of the gradient. Thus $\hat{g}_i$ is an unbiased estimator for gradient.</p>
<h2 id="Low-Variance-Choice"><a href="#Low-Variance-Choice" class="headerlink" title="Low Variance Choice"></a>Low Variance Choice</h2><p>The very estimator is actually a special case of <a href="https://link.springer.com/article/10.1007/BF00992696" target="_blank" rel="noopener">policy gradient</a> [2] widely used in reinforcement learning. Consider the binarization as a random action sampled from $\mathcal{B}(\sigma(a_i))$, the objective $\mathcal{L}$ as reward $R$, and suppose trajectory $\tau$ to be unitary. The common choice for optimization is policy gradient method,</p>
<script type="math/tex; mode=display">
\frac{\partial\mathbb{E}_\tau[R]}{\partial a_i} = \mathbb{E}_\tau\left[R\cdot \frac{\partial \log p_{a_i}(h_i)}{\partial a_i} \right].</script><blockquote>
<p>$\texttt{Proof}:$<br>Suppose $p_{a_i}(h_i)$ is derivable on $0$ with regard to $a_i$, then</p>
<script type="math/tex; mode=display">
\frac{\partial \log p_{a_i}(h_i)}{\partial a_i} = \frac{1}{p_{a_i}(h_i)}\frac{\partial p_{a_i}(h_i)}{\partial a_i}.</script><p>After discretization, </p>
<script type="math/tex; mode=display">
\begin{aligned}
   \mathbb{E}_\tau\left[R\cdot \frac{\partial \log p_{a_i}(h_i)}{\partial a_i} \right] =&\, R_1\cdot \mathbb{P}\left(h_i=1 | a_i \right) \frac{1}{\mathbb{P}\left(h_i=1 | a_i \right)}\frac{\partial \mathbb{P}\left(h_i=1 | a_i \right)}{\partial a_i} \\
+&\, R_0\cdot \mathbb{P}\left(h_i=0 | a_i \right)\frac{1}{\mathbb{P}\left(h_i=0 | a_i \right)}\frac{\partial \mathbb{P}\left(h_i=0 | a_i \right)}{\partial a_i} \\
=&\, R_1\cdot \frac{\partial \mathbb{P}\left(h_i=1 | a_i \right)}{\partial a_i} + R_0\cdot \frac{\partial \mathbb{P}\left(h_i=0 | a_i \right)}{\partial a_i} \\
=&\, \frac{\partial}{\partial a_i}\left(R_1\cdot \mathbb{P}\left(h_i=1 | a_i \right) + R_0\cdot \mathbb{P}\left(h_i=0 | a_i \right) \right) \\
=&\, \frac{\partial\mathbb{E}_{h_i}[R]}{\partial a_i} \\
=&\, \frac{\partial\mathbb{E}_\tau[R]}{\partial a_i}.
\end{aligned}</script></blockquote>
<p>Given that, it is natural to extract $R\cdot \partial_{a_i} \log p_{a_i}(h_i)$ for gradient estimator, which in this case, is</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \mathcal{L}\cdot \frac{\partial \log \mathbb{P}(h_i | a_i)}{\partial a_i} =&\, h_i\mathcal{L}\cdot \left(1 + \exp(-a_i) \right) \frac{\exp(-a_i)}{\left(1 + \exp(-a_i) \right)^2} \\
                                                                              +&\, (1 - h_i)\mathcal{L}\cdot \left(1 + \exp(a_i) \right) \frac{-\exp(a_i)}{\left(1 + \exp(a_i) \right)^2}  \\
                                                                              =&\, h_i\mathcal{L}\cdot \left(1 - \sigma(a_i) \right) - (1 - h_i)\mathcal{L} \cdot \sigma(a_i) \\
                                                                              =&\, h_i\mathcal{L} - \sigma(a_i)\mathcal{L} - h_i\mathcal{L}\cdot \sigma(a_i) + h_i\mathcal{L}\cdot \sigma(a_i) \\
                                                                              =&\, \left(h_i - \sigma(a_i) \right)\mathcal{L},
\end{aligned}</script><p>which is exactly the estimator proposed.</p>
<p>Furthermore, in reinforcement learning, normaly a baseline is assigned for reward so that the gradient is of low variance. Similarly, this baseline is also necessary in the estimator, denoted by $\bar{\mathcal{L}}_i$. Then reformulate the estimator</p>
<script type="math/tex; mode=display">
\hat{g}_i = \left(h_i - \sigma(a_i) \right)\left(\mathcal{L} - \bar{\mathcal{L}}_i \right).</script><p>To minmize its variance, which is</p>
<script type="math/tex; mode=display">
\mathbb{V}ar\left[\hat{g}_i \right] = \mathbb{V}ar\left[\left(h_i - \sigma(a_i) \right)\mathcal{L} \right] - \Delta,</script><p>where</p>
<script type="math/tex; mode=display">
\Delta = \mathbb{E}\left[\left(h_i - \sigma(a_i) \right)^2\left(\mathcal{L}^2 - \left(\mathcal{L} - \bar{\mathcal{L}}_i\right)^2 \right) \right]</script><p>should be maximized by minimizing $\mathbb{E}\left[\left(h_i - \sigma(a_i) \right)^2\left(\mathcal{L} - \bar{\mathcal{L}}_i\right)^2 \right]$. Then by derivating with regrad to $\bar{\mathcal{L}}_i$,</p>
<script type="math/tex; mode=display">
\mathbb{E}\left[\left(h_i - \sigma(a_i) \right)^2\left(\mathcal{L} - \bar{\mathcal{L}}_i\right) \right] = 0,</script><p>thus</p>
<script type="math/tex; mode=display">
\bar{\mathcal{L}}_i = \frac{\mathbb{E}\left[\left(h_i - \sigma(a_i) \right)^2\mathcal{L} \right]}{\mathbb{E}\left[\left(h_i - \sigma(a_i) \right)^2 \right]}.</script><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] Bengio, Y., Léonard, N., &amp; Courville, A. (2013). Estimating or propagating gradients through stochastic neurons for conditional computation. arXiv preprint arXiv:1308.3432.</p>
<p>[2] Williams, R. J. (1992). Simple statistical gradient-following algorithms for connectionist reinforcement learning. Machine learning, 8(3-4), 229-256.</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Stochastic-Neurons/" rel="tag"># Stochastic Neurons</a>
          
            <a href="/tags/Hard-Non-linearity/" rel="tag"># Hard Non-linearity</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/Machine-Learning/Basic-Method/Deep-Neural-Networks-as-Gaussian-Processes/" rel="next" title="Deep Neural Networks as Gaussian Processes">
                <i class="fa fa-chevron-left"></i> Deep Neural Networks as Gaussian Processes
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/Computer-Vision/Object-Detection/Selective-Search/" rel="prev" title="Selective Search">
                Selective Search <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">RemiC</p>
              <p class="site-description motion-element" itemprop="description">I'm description.</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">13</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">7</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">18</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/remicongee" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Overview"><span class="nav-number">1.</span> <span class="nav-text">Overview</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Stochastic-Binary-Neurons"><span class="nav-number">2.</span> <span class="nav-text">Stochastic Binary Neurons</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Unbiased-Estimator-for-Gradient"><span class="nav-number">3.</span> <span class="nav-text">Unbiased Estimator for Gradient</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Low-Variance-Choice"><span class="nav-number">4.</span> <span class="nav-text">Low Variance Choice</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Reference"><span class="nav-number">5.</span> <span class="nav-text">Reference</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">RemiC</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
  


  

  

</body>
</html>
